{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2871f06a",
   "metadata": {},
   "source": [
    "# LeNet-5 手写数字识别 (PyTorch + TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4befbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77264c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 全局超参数与配置 ===\n",
    "# 训练参数\n",
    "BATCH_SIZE = 64          # 批大小\n",
    "LEARNING_RATE = 0.01     # 初始学习率\n",
    "MOMENTUM = 0.9           # 优化器动量\n",
    "EPOCHS = 5               # 训练总轮数\n",
    "\n",
    "# 设备配置\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"当前运行设备: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57c1b1",
   "metadata": {},
   "source": [
    "## 计算公式与关键参数速览（LeNet-5 相关）\n",
    "- 卷积输出尺寸（单维度，高或宽相同计算）\n",
    "  - 公式：$H_{out} = \\left\\lfloor \\frac{H_{in} + 2P - D\\cdot(K-1) - 1}{S} + 1 \\right\\rfloor$\n",
    "  - 符号：$K$=kernel_size，$S$=stride，$P$=padding，$D$=dilation。\n",
    "- 池化输出尺寸（平均/最大池化同理）\n",
    "  - 公式：$H_{out} = \\left\\lfloor \\frac{H_{in} + 2P - (K-1) - 1}{S} + 1 \\right\\rfloor$\n",
    "- 参数量（Parameter Count）估算\n",
    "  - Conv2d：$\\text{params} = C_{out} \\times \\left(\\frac{C_{in}}{\\text{groups}} \\times K_h \\times K_w\\right) + (\\text{bias? } C_{out}:0)$\n",
    "  - Linear：$\\text{params} = \\text{in\\_features} \\times \\text{out\\_features} + (\\text{bias? } \\text{out\\_features}:0)$\n",
    "- 交叉熵损失 CrossEntropyLoss（训练单元使用）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9892b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2,\n",
    "                         ceil_mode=False, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2,\n",
    "                         ceil_mode=False, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84), #全连接层\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 形状：Batchs×1×32×32\n",
    "        x = self.features(x)   # 经过卷积/池化后：Batchs×120×1×1\n",
    "        x = x.view(x.size(0), -1)  # 展平为：Batchs×120（保留批维度N(x.size(0))，合并其余维度）\n",
    "        x = self.classifier(x)  # 全连接分类：N×10\n",
    "        return x\n",
    "\n",
    "model = LeNet5()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b633475",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(2),\n",
    "    # ToTensor：PIL Image -> Tensor，且把像素值从 [0,255] 映射到 [0.0,1.0]\n",
    "    transforms.ToTensor()# ,\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# root 指向当前目录 '.'，torchvision 会在 './MNIST' 下查找 raw/processed\n",
    "train_dataset = datasets.MNIST(root='.', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='.', train=False, download=False, transform=transform)\n",
    "\n",
    "# 使用全局 BATCH_SIZE\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Train samples:', len(train_dataset), 'Test samples:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede04776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取一个batch并查看类型\n",
    "for batch in train_loader:\n",
    "    print(\"Batch类型:\", type(batch))\n",
    "    print(\"Batch长度:\", len(batch))\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"第{i}个元素类型: {type(item)}\")\n",
    "        print(f\"第{i}个元素形状: {item.shape}\")\n",
    "        print(f\"第{i}个元素数据类型: {item.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, loss_function, epoch, writer):\n",
    "    model.train()\n",
    "    # 从 1 开始编号\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader, start=1):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算当前 batch 的准确率\n",
    "        preds = outputs.argmax(dim=1) \n",
    "        correct = (preds == targets).sum().item()\n",
    "        accuracy = 100.0 * correct / targets.size(0)\n",
    "\n",
    "        # 写入 TensorBoard\n",
    "        global_step = (epoch - 1) * len(train_loader) + (batch_idx - 1)\n",
    "        writer.add_scalar('metrics/train/loss', loss.item(), global_step)\n",
    "        writer.add_scalar('metrics/train/accuracy', accuracy, global_step)\n",
    "        \n",
    "        # 打印\n",
    "        print(f\"Epoch {epoch} [{batch_idx}/{len(train_loader)}]  Loss: {loss.item():.4f}  Acc: {accuracy:.2f}%\")\n",
    "        \n",
    "        # 强制刷新写入，确保数据立即写入磁盘\n",
    "        writer.flush()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, loss_function, epoch, writer):\n",
    "    \"\"\"在完整测试集上评估\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            bsize = targets.size(0)\n",
    "            total_loss += loss.item() * bsize\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += bsize\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    print(f\"\\nTest set: Average loss: {avg_loss:.4f}, Accuracy: {total_correct}/{total_samples} ({accuracy:.2f}%)\\n\")\n",
    "\n",
    "    ''' \n",
    "    写入 TensorBoard可视化显示\n",
    "    writer.add_scalar('metrics/test/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('metrics/test/accuracy', accuracy, epoch)\n",
    "    writer.flush()\n",
    "    '''\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import webbrowser\n",
    "from tensorboard import program\n",
    "\n",
    "# 1. 定义日志目录 (绝对路径)\n",
    "tb_logdir = \"./runs/lenet_mnist\"\n",
    "print(f\"TensorBoard 监控目录: {tb_logdir}\")\n",
    "\n",
    "# 2. 尝试关闭占用端口 6006 的 TensorBoard 进程 (Windows)\n",
    "# 这样可以释放对日志文件的锁定，允许我们清空目录\n",
    "print(\"正在检查端口 6006...\")\n",
    "try:\n",
    "    result = subprocess.check_output('netstat -ano | findstr :6006', shell=True).decode()\n",
    "    if result:\n",
    "        print(\"发现旧 TensorBoard 进程，正在终止...\")\n",
    "        pids = set()\n",
    "        for line in result.strip().split('\\n'):\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                pid = parts[-1]\n",
    "                pids.add(pid)\n",
    "        \n",
    "        for pid in pids:\n",
    "            subprocess.run(f'taskkill /F /PID {pid}', \n",
    "                           shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        time.sleep(2) # 等待系统释放资源\n",
    "        print(\"旧 TensorBoard 已关闭。\")\n",
    "except subprocess.CalledProcessError:\n",
    "    # findstr 返回非 0 表示没找到，即没有进程在运行\n",
    "    print(\"端口 6006 未被占用。\")\n",
    "except Exception as e:\n",
    "    print(f\"尝试关闭进程时出错 (可忽略): {e}\")\n",
    "\n",
    "# 3. 清空日志目录 (确保无历史曲线)\n",
    "if os.path.exists(tb_logdir):\n",
    "    try:\n",
    "        shutil.rmtree(tb_logdir)\n",
    "        print(\"已清空历史日志目录。\")\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 无法完全清空目录: {e}\")\n",
    "\n",
    "os.makedirs(tb_logdir, exist_ok=True)\n",
    "\n",
    "# 4. 启动 TensorBoard\n",
    "tb = program.TensorBoard()\n",
    "# --reload_interval 1: 设置后端每 1 秒去读取一次磁盘数据（默认通常是 5 秒）\n",
    "# 这能让数据更新更及时，但前端页面仍需开启自动刷新\n",
    "tb.configure(argv=[None, '--logdir', tb_logdir, '--port', '6006', '--host', '127.0.0.1', '--reload_interval', '1'])\n",
    "url = tb.launch()\n",
    "\n",
    "# 打开浏览器\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "writer = SummaryWriter(\"./runs/lenet_mnist\")\n",
    "\n",
    "for epoch in range(1, 1 + EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train(model, DEVICE, train_loader, optimizer, loss_function, epoch, writer)\n",
    "    test(model, DEVICE, test_loader, loss_function, epoch, writer)\n",
    "    print(f'Epoch {epoch} finished in {time.time() - t0:.1f}s')\n",
    "\n",
    "model_path = './lenet_mnist.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model saved to', model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e178ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：加载保存的模型并可视化若干预测结果\n",
    "# 加载模型\n",
    "model = LeNet5()\n",
    "model.load_state_dict(torch.load('./lenet_mnist.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# 取几张测试图像并预测\n",
    "examples = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        if i >= 1:\n",
    "            break\n",
    "        outputs = model(data)\n",
    "        preds = outputs.argmax(dim=1).numpy()\n",
    "        for j in range(min(8, data.size(0))):\n",
    "            img = data[j].squeeze().numpy()\n",
    "            examples.append(img)\n",
    "            labels.append((int(target[j].item()), int(preds[j].item())))\n",
    "\n",
    "# 绘制\n",
    "plt.figure(figsize=(12, 6))\n",
    "for idx, img in enumerate(examples):\n",
    "    plt.subplot(2, 4, idx+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    gt, pr = labels[idx]\n",
    "    plt.title(f'GT:{gt} Pred:{pr}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0fe26",
   "metadata": {},
   "source": [
    "## 本地手写窗口（Tkinter）\n",
    "\n",
    "- 运行下一个单元将打开一个本地窗口。\n",
    "- 操作：按住左键在白板上书写；点击“识别”进行推断；“清空”重置画布；“退出”关闭窗口。\n",
    "- 说明：此窗口使用 Tkinter（Windows 通常自带）。若环境未安装 Tk 支持，可能无法启动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35464471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地手写窗口：Tkinter 画布 + LeNet-5 推理\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tkinter 可能在某些环境不可用\n",
    "try:\n",
    "    import tkinter as tk\n",
    "except Exception as e:\n",
    "    print(\"未能导入 Tkinter：\", e)\n",
    "    raise\n",
    "\n",
    "# 复用已定义的 LeNet5，如果此单元单独运行则做一次定义\n",
    "try:\n",
    "    LeNet5\n",
    "except NameError:\n",
    "    print(\"警告：LeNet-5 模型未定义\")\n",
    "\n",
    "# 加载模型（CPU 推理）\n",
    "_device = torch.device('cpu')\n",
    "_model = LeNet5().to(_device)\n",
    "weights_path = './lenet_mnist.pth'\n",
    "if os.path.exists(weights_path):    \n",
    "    _model.load_state_dict(torch.load(weights_path, map_location=_device))\n",
    "    _model.eval()\n",
    "else:\n",
    "    print('警告：未找到模型权重 ./lenet_mnist.pth，请先运行训练单元保存模型。')\n",
    "\n",
    "_MEAN, _STD = 0.1307, 0.3081\n",
    "\n",
    "\n",
    "def _preprocess_pil(pil_img: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"将 PIL 图像转换为 1×1×32×32 标准化张量（与训练一致）。\"\"\"\n",
    "    if pil_img.mode != 'L':\n",
    "        pil_img = pil_img.convert('L')\n",
    "    pil_img = pil_img.resize((28, 28), Image.NEAREST)\n",
    "    arr = np.array(pil_img).astype(np.float32) / 255.0\n",
    "    arr = 1.0 - arr  # 画布白底黑字 -> MNIST 黑底白字\n",
    "    arr = (arr - _MEAN) / _STD\n",
    "    arr = np.pad(arr, pad_width=((2, 2), (2, 2)), mode='constant', constant_values=0.0)\n",
    "    ten = torch.from_numpy(arr)[None, None, :, :].to(_device)\n",
    "    return ten\n",
    "\n",
    "\n",
    "def _predict_from_pil(pil_img: Image.Image):\n",
    "    if _model is None:\n",
    "        return {str(i): 0.0 for i in range(10)}\n",
    "    x = _preprocess_pil(pil_img)\n",
    "    with torch.no_grad():\n",
    "        logits = _model(x)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    return {str(i): float(probs[i]) for i in range(10)}\n",
    "\n",
    "\n",
    "# === Tkinter 手写窗口 ===\n",
    "CANVAS_SIZE = 280            # 画布像素大小（放大版）\n",
    "BRUSH_WIDTH = 20             # 笔刷粗细\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('MNIST 手写数字识别 (LeNet-5) - 本地窗口')\n",
    "\n",
    "canvas = tk.Canvas(root, width=CANVAS_SIZE, height=CANVAS_SIZE, bg='white')\n",
    "canvas.pack(padx=8, pady=8)\n",
    "\n",
    "# 用于推理的灰度图缓存（白底）\n",
    "buffer_img = Image.new('L', (CANVAS_SIZE, CANVAS_SIZE), color=255)\n",
    "buffer_draw = ImageDraw.Draw(buffer_img)\n",
    "\n",
    "last_pos = {'x': None, 'y': None}\n",
    "\n",
    "\n",
    "def on_button_press(event):\n",
    "    last_pos['x'], last_pos['y'] = event.x, event.y\n",
    "\n",
    "\n",
    "def on_move(event):\n",
    "    lx, ly = last_pos['x'], last_pos['y']\n",
    "    if lx is None or ly is None:\n",
    "        last_pos['x'], last_pos['y'] = event.x, event.y\n",
    "        return\n",
    "    x, y = event.x, event.y\n",
    "    canvas.create_line(lx, ly, x, y, width=BRUSH_WIDTH, fill='black', capstyle=tk.ROUND, smooth=True)\n",
    "    buffer_draw.line([lx, ly, x, y], fill=0, width=BRUSH_WIDTH)\n",
    "    last_pos['x'], last_pos['y'] = x, y\n",
    "\n",
    "\n",
    "def on_button_release(event):\n",
    "    last_pos['x'], last_pos['y'] = None, None\n",
    "\n",
    "\n",
    "def clear_canvas():\n",
    "    canvas.delete('all')\n",
    "    buffer_draw.rectangle([(0, 0), (CANVAS_SIZE, CANVAS_SIZE)], fill=255)\n",
    "    result_var.set('结果：')\n",
    "\n",
    "\n",
    "def predict_canvas():\n",
    "    probs = _predict_from_pil(buffer_img)\n",
    "    # 取 Top-3 显示\n",
    "    items = sorted([(int(k), v) for k, v in probs.items()], key=lambda kv: kv[1], reverse=True)[:3]\n",
    "    text = '结果：' + '  '.join([f'{k}: {v*100:.2f}%' for k, v in items])\n",
    "    result_var.set(text)\n",
    "\n",
    "\n",
    "btn_frame = tk.Frame(root)\n",
    "btn_frame.pack(fill='x', padx=8, pady=4)\n",
    "\n",
    "tk.Button(btn_frame, text='识别', command=predict_canvas).pack(side='left', padx=4)\n",
    "tk.Button(btn_frame, text='清空', command=clear_canvas).pack(side='left', padx=4)\n",
    "tk.Button(btn_frame, text='退出', command=root.destroy).pack(side='right', padx=4)\n",
    "\n",
    "result_var = tk.StringVar(value='结果：')\n",
    "result_label = tk.Label(root, textvariable=result_var, anchor='w')\n",
    "result_label.pack(fill='x', padx=8, pady=4)\n",
    "\n",
    "canvas.bind('<ButtonPress-1>', on_button_press)\n",
    "canvas.bind('<B1-Motion>', on_move)\n",
    "canvas.bind('<ButtonRelease-1>', on_button_release)\n",
    "\n",
    "# 启动窗口（注意：在某些 Jupyter 环境中主线程阻塞是预期行为）\n",
    "try:\n",
    "    root.mainloop()\n",
    "except Exception as e:\n",
    "    print('Tkinter 主循环启动失败：', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
