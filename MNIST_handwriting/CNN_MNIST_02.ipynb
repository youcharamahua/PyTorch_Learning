{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2871f06a",
   "metadata": {},
   "source": [
    "# LeNet-5 手写数字识别 (PyTorch + TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4befbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77264c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前运行设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# === 全局超参数与配置 ===\n",
    "# 训练参数\n",
    "BATCH_SIZE = 64          # 批大小\n",
    "LEARNING_RATE = 0.01     # 初始学习率\n",
    "MOMENTUM = 0.9           # 优化器动量\n",
    "EPOCHS = 5               # 训练总轮数\n",
    "\n",
    "# 设备配置\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"当前运行设备: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57c1b1",
   "metadata": {},
   "source": [
    "## 计算公式与关键参数速览（LeNet-5 相关）\n",
    "- 卷积输出尺寸（单维度，高或宽相同计算）\n",
    "  - 公式：$H_{out} = \\left\\lfloor \\frac{H_{in} + 2P - D\\cdot(K-1) - 1}{S} + 1 \\right\\rfloor$\n",
    "  - 符号：$K$=kernel_size，$S$=stride，$P$=padding，$D$=dilation。\n",
    "- 池化输出尺寸（平均/最大池化同理）\n",
    "  - 公式：$H_{out} = \\left\\lfloor \\frac{H_{in} + 2P - (K-1) - 1}{S} + 1 \\right\\rfloor$\n",
    "- 参数量（Parameter Count）估算\n",
    "  - Conv2d：$\\text{params} = C_{out} \\times \\left(\\frac{C_{in}}{\\text{groups}} \\times K_h \\times K_w\\right) + (\\text{bias? } C_{out}:0)$\n",
    "  - Linear：$\\text{params} = \\text{in\\_features} \\times \\text{out\\_features} + (\\text{bias? } \\text{out\\_features}:0)$\n",
    "- 交叉熵损失 CrossEntropyLoss（训练单元使用）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9892b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Tanh()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): Tanh()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2,\n",
    "                         ceil_mode=False, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2,\n",
    "                         ceil_mode=False, count_include_pad=False),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5,\n",
    "                      stride=1, dilation=1, groups=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84), #全连接层\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 形状：Batchs×1×32×32\n",
    "        x = self.features(x)   # 经过卷积/池化后：Batchs×120×1×1\n",
    "        x = x.view(x.size(0), -1)  # 展平为：Batchs×120（保留批维度N(x.size(0))，合并其余维度）\n",
    "        x = self.classifier(x)  # 全连接分类：N×10\n",
    "        return x\n",
    "\n",
    "model = LeNet5()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b633475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60000 Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(2),\n",
    "    # ToTensor：PIL Image -> Tensor，且把像素值从 [0,255] 映射到 [0.0,1.0]\n",
    "    transforms.ToTensor()# ,\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# root 指向当前目录 '.'，torchvision 会在 './MNIST' 下查找 raw/processed\n",
    "train_dataset = datasets.MNIST(root='.', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='.', train=False, download=False, transform=transform)\n",
    "\n",
    "# 使用全局 BATCH_SIZE\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print('Train samples:', len(train_dataset), 'Test samples:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede04776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch类型: <class 'list'>\n",
      "Batch长度: 2\n",
      "第0个元素类型: <class 'torch.Tensor'>\n",
      "第0个元素形状: torch.Size([64, 1, 32, 32])\n",
      "第0个元素数据类型: torch.float32\n",
      "第1个元素类型: <class 'torch.Tensor'>\n",
      "第1个元素形状: torch.Size([64])\n",
      "第1个元素数据类型: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# 获取一个batch并查看类型\n",
    "for batch in train_loader:\n",
    "    print(\"Batch类型:\", type(batch))\n",
    "    print(\"Batch长度:\", len(batch))\n",
    "    \n",
    "    for i, item in enumerate(batch):\n",
    "        print(f\"第{i}个元素类型: {type(item)}\")\n",
    "        print(f\"第{i}个元素形状: {item.shape}\")\n",
    "        print(f\"第{i}个元素数据类型: {item.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dde0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, loss_function, epoch, writer):\n",
    "    model.train()\n",
    "    # 从 1 开始编号\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader, start=1):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 计算当前 batch 的准确率\n",
    "        preds = outputs.argmax(dim=1) \n",
    "        correct = (preds == targets).sum().item()\n",
    "        accuracy = 100.0 * correct / targets.size(0)\n",
    "\n",
    "        # 写入 TensorBoard\n",
    "        global_step = (epoch - 1) * len(train_loader) + (batch_idx - 1)\n",
    "        writer.add_scalar('metrics/train/loss', loss.item(), global_step)\n",
    "        writer.add_scalar('metrics/train/accuracy', accuracy, global_step)\n",
    "        \n",
    "        # 打印\n",
    "        print(f\"Epoch {epoch} [{batch_idx}/{len(train_loader)}]  Loss: {loss.item():.4f}  Acc: {accuracy:.2f}%\")\n",
    "        \n",
    "        # 强制刷新写入，确保数据立即写入磁盘\n",
    "        writer.flush()\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, loss_function, epoch, writer):\n",
    "    \"\"\"在完整测试集上评估\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            bsize = targets.size(0)\n",
    "            total_loss += loss.item() * bsize\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += bsize\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    print(f\"\\nTest set: Average loss: {avg_loss:.4f}, Accuracy: {total_correct}/{total_samples} ({accuracy:.2f}%)\\n\")\n",
    "\n",
    "    ''' \n",
    "    写入 TensorBoard可视化显示\n",
    "    writer.add_scalar('metrics/test/loss', avg_loss, epoch)\n",
    "    writer.add_scalar('metrics/test/accuracy', accuracy, epoch)\n",
    "    writer.flush()\n",
    "    '''\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd0f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 监控目录: ./runs/lenet_mnist\n",
      "正在检查端口 6006...\n",
      "端口 6006 未被占用。\n",
      "已清空历史日志目录。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import webbrowser\n",
    "from tensorboard import program\n",
    "\n",
    "# 1. 定义日志目录 (绝对路径)\n",
    "tb_logdir = \"./runs/lenet_mnist\"\n",
    "print(f\"TensorBoard 监控目录: {tb_logdir}\")\n",
    "\n",
    "# 2. 尝试关闭占用端口 6006 的 TensorBoard 进程 (Windows)\n",
    "# 这样可以释放对日志文件的锁定，允许我们清空目录\n",
    "print(\"正在检查端口 6006...\")\n",
    "try:\n",
    "    result = subprocess.check_output('netstat -ano | findstr :6006', shell=True).decode()\n",
    "    if result:\n",
    "        print(\"发现旧 TensorBoard 进程，正在终止...\")\n",
    "        pids = set()\n",
    "        for line in result.strip().split('\\n'):\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                pid = parts[-1]\n",
    "                pids.add(pid)\n",
    "        \n",
    "        for pid in pids:\n",
    "            subprocess.run(f'taskkill /F /PID {pid}', \n",
    "                           shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        time.sleep(2) # 等待系统释放资源\n",
    "        print(\"旧 TensorBoard 已关闭。\")\n",
    "except subprocess.CalledProcessError:\n",
    "    # findstr 返回非 0 表示没找到，即没有进程在运行\n",
    "    print(\"端口 6006 未被占用。\")\n",
    "except Exception as e:\n",
    "    print(f\"尝试关闭进程时出错 (可忽略): {e}\")\n",
    "\n",
    "# 3. 清空日志目录 (确保无历史曲线)\n",
    "if os.path.exists(tb_logdir):\n",
    "    try:\n",
    "        shutil.rmtree(tb_logdir)\n",
    "        print(\"已清空历史日志目录。\")\n",
    "    except Exception as e:\n",
    "        print(f\"警告: 无法完全清空目录: {e}\")\n",
    "\n",
    "os.makedirs(tb_logdir, exist_ok=True)\n",
    "\n",
    "# 4. 启动 TensorBoard\n",
    "tb = program.TensorBoard()\n",
    "# --reload_interval 1: 设置后端每 1 秒去读取一次磁盘数据（默认通常是 5 秒）\n",
    "# 这能让数据更新更及时，但前端页面仍需开启自动刷新\n",
    "tb.configure(argv=[None, '--logdir', tb_logdir, '--port', '6006', '--host', '127.0.0.1', '--reload_interval', '1'])\n",
    "url = tb.launch()\n",
    "\n",
    "# 打开浏览器\n",
    "webbrowser.open(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [1/938]  Loss: 2.3065  Acc: 12.50%\n",
      "Epoch 1 [2/938]  Loss: 2.3133  Acc: 7.81%\n",
      "Epoch 1 [3/938]  Loss: 2.3155  Acc: 3.12%\n",
      "Epoch 1 [4/938]  Loss: 2.3056  Acc: 14.06%\n",
      "Epoch 1 [5/938]  Loss: 2.3181  Acc: 6.25%\n",
      "Epoch 1 [6/938]  Loss: 2.3189  Acc: 7.81%\n",
      "Epoch 1 [7/938]  Loss: 2.3024  Acc: 10.94%\n",
      "Epoch 1 [8/938]  Loss: 2.3045  Acc: 10.94%\n",
      "Epoch 1 [9/938]  Loss: 2.3043  Acc: 3.12%\n",
      "Epoch 1 [10/938]  Loss: 2.3012  Acc: 10.94%\n",
      "Epoch 1 [11/938]  Loss: 2.3000  Acc: 17.19%\n",
      "Epoch 1 [12/938]  Loss: 2.3019  Acc: 9.38%\n",
      "Epoch 1 [13/938]  Loss: 2.3046  Acc: 10.94%\n",
      "Epoch 1 [14/938]  Loss: 2.3140  Acc: 6.25%\n",
      "Epoch 1 [15/938]  Loss: 2.2965  Acc: 9.38%\n",
      "Epoch 1 [16/938]  Loss: 2.3059  Acc: 9.38%\n",
      "Epoch 1 [17/938]  Loss: 2.2985  Acc: 18.75%\n",
      "Epoch 1 [18/938]  Loss: 2.3043  Acc: 7.81%\n",
      "Epoch 1 [19/938]  Loss: 2.3028  Acc: 15.62%\n",
      "Epoch 1 [20/938]  Loss: 2.3087  Acc: 6.25%\n",
      "Epoch 1 [21/938]  Loss: 2.2940  Acc: 15.62%\n",
      "Epoch 1 [22/938]  Loss: 2.3032  Acc: 4.69%\n",
      "Epoch 1 [23/938]  Loss: 2.2867  Acc: 20.31%\n",
      "Epoch 1 [24/938]  Loss: 2.2903  Acc: 20.31%\n",
      "Epoch 1 [25/938]  Loss: 2.2887  Acc: 10.94%\n",
      "Epoch 1 [26/938]  Loss: 2.2942  Acc: 10.94%\n",
      "Epoch 1 [27/938]  Loss: 2.2956  Acc: 20.31%\n",
      "Epoch 1 [28/938]  Loss: 2.2975  Acc: 12.50%\n",
      "Epoch 1 [29/938]  Loss: 2.2864  Acc: 18.75%\n",
      "Epoch 1 [30/938]  Loss: 2.2849  Acc: 26.56%\n",
      "Epoch 1 [31/938]  Loss: 2.2917  Acc: 12.50%\n",
      "Epoch 1 [32/938]  Loss: 2.2882  Acc: 18.75%\n",
      "Epoch 1 [33/938]  Loss: 2.2812  Acc: 34.38%\n",
      "Epoch 1 [34/938]  Loss: 2.2796  Acc: 37.50%\n",
      "Epoch 1 [35/938]  Loss: 2.2896  Acc: 29.69%\n",
      "Epoch 1 [36/938]  Loss: 2.2849  Acc: 31.25%\n",
      "Epoch 1 [37/938]  Loss: 2.2863  Acc: 26.56%\n",
      "Epoch 1 [38/938]  Loss: 2.2819  Acc: 28.12%\n",
      "Epoch 1 [39/938]  Loss: 2.2755  Acc: 28.12%\n",
      "Epoch 1 [40/938]  Loss: 2.2787  Acc: 29.69%\n",
      "Epoch 1 [41/938]  Loss: 2.2752  Acc: 18.75%\n",
      "Epoch 1 [42/938]  Loss: 2.2809  Acc: 15.62%\n",
      "Epoch 1 [43/938]  Loss: 2.2745  Acc: 28.12%\n",
      "Epoch 1 [44/938]  Loss: 2.2603  Acc: 37.50%\n",
      "Epoch 1 [45/938]  Loss: 2.2810  Acc: 18.75%\n",
      "Epoch 1 [46/938]  Loss: 2.2622  Acc: 29.69%\n",
      "Epoch 1 [47/938]  Loss: 2.2653  Acc: 28.12%\n",
      "Epoch 1 [48/938]  Loss: 2.2631  Acc: 29.69%\n",
      "Epoch 1 [49/938]  Loss: 2.2665  Acc: 28.12%\n",
      "Epoch 1 [50/938]  Loss: 2.2722  Acc: 25.00%\n",
      "Epoch 1 [51/938]  Loss: 2.2803  Acc: 10.94%\n",
      "Epoch 1 [52/938]  Loss: 2.2616  Acc: 28.12%\n",
      "Epoch 1 [53/938]  Loss: 2.2579  Acc: 34.38%\n",
      "Epoch 1 [54/938]  Loss: 2.2486  Acc: 37.50%\n",
      "Epoch 1 [55/938]  Loss: 2.2639  Acc: 17.19%\n",
      "Epoch 1 [56/938]  Loss: 2.2555  Acc: 29.69%\n",
      "Epoch 1 [57/938]  Loss: 2.2492  Acc: 28.12%\n",
      "Epoch 1 [58/938]  Loss: 2.2233  Acc: 50.00%\n",
      "Epoch 1 [59/938]  Loss: 2.2273  Acc: 48.44%\n",
      "Epoch 1 [60/938]  Loss: 2.2304  Acc: 43.75%\n",
      "Epoch 1 [61/938]  Loss: 2.2280  Acc: 48.44%\n",
      "Epoch 1 [62/938]  Loss: 2.2256  Acc: 35.94%\n",
      "Epoch 1 [63/938]  Loss: 2.2279  Acc: 43.75%\n",
      "Epoch 1 [64/938]  Loss: 2.2166  Acc: 45.31%\n",
      "Epoch 1 [65/938]  Loss: 2.2178  Acc: 43.75%\n",
      "Epoch 1 [66/938]  Loss: 2.2090  Acc: 42.19%\n",
      "Epoch 1 [67/938]  Loss: 2.1919  Acc: 54.69%\n",
      "Epoch 1 [68/938]  Loss: 2.1886  Acc: 51.56%\n",
      "Epoch 1 [69/938]  Loss: 2.2139  Acc: 40.62%\n",
      "Epoch 1 [70/938]  Loss: 2.1658  Acc: 60.94%\n",
      "Epoch 1 [71/938]  Loss: 2.1810  Acc: 53.12%\n",
      "Epoch 1 [72/938]  Loss: 2.1785  Acc: 45.31%\n",
      "Epoch 1 [73/938]  Loss: 2.1547  Acc: 53.12%\n",
      "Epoch 1 [74/938]  Loss: 2.1544  Acc: 46.88%\n",
      "Epoch 1 [75/938]  Loss: 2.1508  Acc: 56.25%\n",
      "Epoch 1 [76/938]  Loss: 2.1208  Acc: 57.81%\n",
      "Epoch 1 [77/938]  Loss: 2.1166  Acc: 67.19%\n",
      "Epoch 1 [78/938]  Loss: 2.1103  Acc: 50.00%\n",
      "Epoch 1 [79/938]  Loss: 2.1097  Acc: 48.44%\n",
      "Epoch 1 [80/938]  Loss: 2.1121  Acc: 51.56%\n",
      "Epoch 1 [81/938]  Loss: 2.0500  Acc: 59.38%\n",
      "Epoch 1 [82/938]  Loss: 2.0642  Acc: 53.12%\n",
      "Epoch 1 [83/938]  Loss: 2.0608  Acc: 51.56%\n",
      "Epoch 1 [84/938]  Loss: 2.0243  Acc: 45.31%\n",
      "Epoch 1 [85/938]  Loss: 2.0637  Acc: 42.19%\n",
      "Epoch 1 [86/938]  Loss: 1.9635  Acc: 59.38%\n",
      "Epoch 1 [87/938]  Loss: 1.9288  Acc: 54.69%\n",
      "Epoch 1 [88/938]  Loss: 1.9610  Acc: 53.12%\n",
      "Epoch 1 [89/938]  Loss: 1.8549  Acc: 64.06%\n",
      "Epoch 1 [90/938]  Loss: 1.9738  Acc: 45.31%\n",
      "Epoch 1 [91/938]  Loss: 1.9641  Acc: 43.75%\n",
      "Epoch 1 [92/938]  Loss: 1.9564  Acc: 45.31%\n",
      "Epoch 1 [93/938]  Loss: 1.9179  Acc: 51.56%\n",
      "Epoch 1 [94/938]  Loss: 1.8119  Acc: 48.44%\n",
      "Epoch 1 [95/938]  Loss: 1.8205  Acc: 56.25%\n",
      "Epoch 1 [96/938]  Loss: 1.8083  Acc: 43.75%\n",
      "Epoch 1 [97/938]  Loss: 1.6218  Acc: 60.94%\n",
      "Epoch 1 [98/938]  Loss: 1.7962  Acc: 51.56%\n",
      "Epoch 1 [99/938]  Loss: 1.7095  Acc: 62.50%\n",
      "Epoch 1 [100/938]  Loss: 1.6565  Acc: 56.25%\n",
      "Epoch 1 [101/938]  Loss: 1.7705  Acc: 48.44%\n",
      "Epoch 1 [102/938]  Loss: 1.7180  Acc: 57.81%\n",
      "Epoch 1 [103/938]  Loss: 1.5245  Acc: 68.75%\n",
      "Epoch 1 [104/938]  Loss: 1.6864  Acc: 54.69%\n",
      "Epoch 1 [105/938]  Loss: 1.5336  Acc: 64.06%\n",
      "Epoch 1 [106/938]  Loss: 1.5680  Acc: 51.56%\n",
      "Epoch 1 [107/938]  Loss: 1.4521  Acc: 60.94%\n",
      "Epoch 1 [108/938]  Loss: 1.4705  Acc: 60.94%\n",
      "Epoch 1 [109/938]  Loss: 1.5817  Acc: 54.69%\n",
      "Epoch 1 [110/938]  Loss: 1.3851  Acc: 64.06%\n",
      "Epoch 1 [111/938]  Loss: 1.3834  Acc: 62.50%\n",
      "Epoch 1 [112/938]  Loss: 1.5490  Acc: 50.00%\n",
      "Epoch 1 [113/938]  Loss: 1.4097  Acc: 64.06%\n",
      "Epoch 1 [114/938]  Loss: 1.3839  Acc: 64.06%\n",
      "Epoch 1 [115/938]  Loss: 1.2650  Acc: 68.75%\n",
      "Epoch 1 [116/938]  Loss: 1.3605  Acc: 68.75%\n",
      "Epoch 1 [117/938]  Loss: 1.3246  Acc: 62.50%\n",
      "Epoch 1 [118/938]  Loss: 1.1773  Acc: 68.75%\n",
      "Epoch 1 [119/938]  Loss: 1.3111  Acc: 60.94%\n",
      "Epoch 1 [120/938]  Loss: 1.2212  Acc: 60.94%\n",
      "Epoch 1 [59/938]  Loss: 2.2273  Acc: 48.44%\n",
      "Epoch 1 [60/938]  Loss: 2.2304  Acc: 43.75%\n",
      "Epoch 1 [61/938]  Loss: 2.2280  Acc: 48.44%\n",
      "Epoch 1 [62/938]  Loss: 2.2256  Acc: 35.94%\n",
      "Epoch 1 [63/938]  Loss: 2.2279  Acc: 43.75%\n",
      "Epoch 1 [64/938]  Loss: 2.2166  Acc: 45.31%\n",
      "Epoch 1 [65/938]  Loss: 2.2178  Acc: 43.75%\n",
      "Epoch 1 [66/938]  Loss: 2.2090  Acc: 42.19%\n",
      "Epoch 1 [67/938]  Loss: 2.1919  Acc: 54.69%\n",
      "Epoch 1 [68/938]  Loss: 2.1886  Acc: 51.56%\n",
      "Epoch 1 [69/938]  Loss: 2.2139  Acc: 40.62%\n",
      "Epoch 1 [70/938]  Loss: 2.1658  Acc: 60.94%\n",
      "Epoch 1 [71/938]  Loss: 2.1810  Acc: 53.12%\n",
      "Epoch 1 [72/938]  Loss: 2.1785  Acc: 45.31%\n",
      "Epoch 1 [73/938]  Loss: 2.1547  Acc: 53.12%\n",
      "Epoch 1 [74/938]  Loss: 2.1544  Acc: 46.88%\n",
      "Epoch 1 [75/938]  Loss: 2.1508  Acc: 56.25%\n",
      "Epoch 1 [76/938]  Loss: 2.1208  Acc: 57.81%\n",
      "Epoch 1 [77/938]  Loss: 2.1166  Acc: 67.19%\n",
      "Epoch 1 [78/938]  Loss: 2.1103  Acc: 50.00%\n",
      "Epoch 1 [79/938]  Loss: 2.1097  Acc: 48.44%\n",
      "Epoch 1 [80/938]  Loss: 2.1121  Acc: 51.56%\n",
      "Epoch 1 [81/938]  Loss: 2.0500  Acc: 59.38%\n",
      "Epoch 1 [82/938]  Loss: 2.0642  Acc: 53.12%\n",
      "Epoch 1 [83/938]  Loss: 2.0608  Acc: 51.56%\n",
      "Epoch 1 [84/938]  Loss: 2.0243  Acc: 45.31%\n",
      "Epoch 1 [85/938]  Loss: 2.0637  Acc: 42.19%\n",
      "Epoch 1 [86/938]  Loss: 1.9635  Acc: 59.38%\n",
      "Epoch 1 [87/938]  Loss: 1.9288  Acc: 54.69%\n",
      "Epoch 1 [88/938]  Loss: 1.9610  Acc: 53.12%\n",
      "Epoch 1 [89/938]  Loss: 1.8549  Acc: 64.06%\n",
      "Epoch 1 [90/938]  Loss: 1.9738  Acc: 45.31%\n",
      "Epoch 1 [91/938]  Loss: 1.9641  Acc: 43.75%\n",
      "Epoch 1 [92/938]  Loss: 1.9564  Acc: 45.31%\n",
      "Epoch 1 [93/938]  Loss: 1.9179  Acc: 51.56%\n",
      "Epoch 1 [94/938]  Loss: 1.8119  Acc: 48.44%\n",
      "Epoch 1 [95/938]  Loss: 1.8205  Acc: 56.25%\n",
      "Epoch 1 [96/938]  Loss: 1.8083  Acc: 43.75%\n",
      "Epoch 1 [97/938]  Loss: 1.6218  Acc: 60.94%\n",
      "Epoch 1 [98/938]  Loss: 1.7962  Acc: 51.56%\n",
      "Epoch 1 [99/938]  Loss: 1.7095  Acc: 62.50%\n",
      "Epoch 1 [100/938]  Loss: 1.6565  Acc: 56.25%\n",
      "Epoch 1 [101/938]  Loss: 1.7705  Acc: 48.44%\n",
      "Epoch 1 [102/938]  Loss: 1.7180  Acc: 57.81%\n",
      "Epoch 1 [103/938]  Loss: 1.5245  Acc: 68.75%\n",
      "Epoch 1 [104/938]  Loss: 1.6864  Acc: 54.69%\n",
      "Epoch 1 [105/938]  Loss: 1.5336  Acc: 64.06%\n",
      "Epoch 1 [106/938]  Loss: 1.5680  Acc: 51.56%\n",
      "Epoch 1 [107/938]  Loss: 1.4521  Acc: 60.94%\n",
      "Epoch 1 [108/938]  Loss: 1.4705  Acc: 60.94%\n",
      "Epoch 1 [109/938]  Loss: 1.5817  Acc: 54.69%\n",
      "Epoch 1 [110/938]  Loss: 1.3851  Acc: 64.06%\n",
      "Epoch 1 [111/938]  Loss: 1.3834  Acc: 62.50%\n",
      "Epoch 1 [112/938]  Loss: 1.5490  Acc: 50.00%\n",
      "Epoch 1 [113/938]  Loss: 1.4097  Acc: 64.06%\n",
      "Epoch 1 [114/938]  Loss: 1.3839  Acc: 64.06%\n",
      "Epoch 1 [115/938]  Loss: 1.2650  Acc: 68.75%\n",
      "Epoch 1 [116/938]  Loss: 1.3605  Acc: 68.75%\n",
      "Epoch 1 [117/938]  Loss: 1.3246  Acc: 62.50%\n",
      "Epoch 1 [118/938]  Loss: 1.1773  Acc: 68.75%\n",
      "Epoch 1 [119/938]  Loss: 1.3111  Acc: 60.94%\n",
      "Epoch 1 [120/938]  Loss: 1.2212  Acc: 60.94%\n",
      "Epoch 1 [121/938]  Loss: 1.1752  Acc: 70.31%\n",
      "Epoch 1 [122/938]  Loss: 1.3032  Acc: 62.50%\n",
      "Epoch 1 [123/938]  Loss: 1.1922  Acc: 64.06%\n",
      "Epoch 1 [124/938]  Loss: 1.1964  Acc: 64.06%\n",
      "Epoch 1 [125/938]  Loss: 1.0212  Acc: 79.69%\n",
      "Epoch 1 [126/938]  Loss: 1.0996  Acc: 67.19%\n",
      "Epoch 1 [127/938]  Loss: 1.1199  Acc: 68.75%\n",
      "Epoch 1 [128/938]  Loss: 0.8966  Acc: 85.94%\n",
      "Epoch 1 [129/938]  Loss: 0.9057  Acc: 81.25%\n",
      "Epoch 1 [130/938]  Loss: 0.9563  Acc: 79.69%\n",
      "Epoch 1 [131/938]  Loss: 1.1088  Acc: 59.38%\n",
      "Epoch 1 [132/938]  Loss: 0.9487  Acc: 73.44%\n",
      "Epoch 1 [133/938]  Loss: 1.0682  Acc: 62.50%\n",
      "Epoch 1 [134/938]  Loss: 0.8580  Acc: 79.69%\n",
      "Epoch 1 [135/938]  Loss: 1.0529  Acc: 78.12%\n",
      "Epoch 1 [136/938]  Loss: 0.8742  Acc: 79.69%\n",
      "Epoch 1 [137/938]  Loss: 0.9873  Acc: 71.88%\n",
      "Epoch 1 [138/938]  Loss: 0.8895  Acc: 71.88%\n",
      "Epoch 1 [139/938]  Loss: 0.9493  Acc: 84.38%\n",
      "Epoch 1 [140/938]  Loss: 0.9117  Acc: 73.44%\n",
      "Epoch 1 [141/938]  Loss: 0.8707  Acc: 71.88%\n",
      "Epoch 1 [142/938]  Loss: 1.0285  Acc: 67.19%\n",
      "Epoch 1 [143/938]  Loss: 0.9142  Acc: 70.31%\n",
      "Epoch 1 [144/938]  Loss: 0.7648  Acc: 78.12%\n",
      "Epoch 1 [145/938]  Loss: 0.7114  Acc: 79.69%\n",
      "Epoch 1 [146/938]  Loss: 0.7661  Acc: 79.69%\n",
      "Epoch 1 [147/938]  Loss: 0.7456  Acc: 84.38%\n",
      "Epoch 1 [148/938]  Loss: 0.6761  Acc: 82.81%\n",
      "Epoch 1 [149/938]  Loss: 0.8090  Acc: 75.00%\n",
      "Epoch 1 [150/938]  Loss: 0.6779  Acc: 82.81%\n",
      "Epoch 1 [151/938]  Loss: 0.7419  Acc: 79.69%\n",
      "Epoch 1 [152/938]  Loss: 0.8459  Acc: 79.69%\n",
      "Epoch 1 [153/938]  Loss: 0.8235  Acc: 81.25%\n",
      "Epoch 1 [154/938]  Loss: 0.6451  Acc: 87.50%\n",
      "Epoch 1 [155/938]  Loss: 0.6920  Acc: 78.12%\n",
      "Epoch 1 [156/938]  Loss: 0.6578  Acc: 82.81%\n",
      "Epoch 1 [157/938]  Loss: 0.8584  Acc: 73.44%\n",
      "Epoch 1 [158/938]  Loss: 0.6559  Acc: 85.94%\n",
      "Epoch 1 [159/938]  Loss: 0.6415  Acc: 79.69%\n",
      "Epoch 1 [160/938]  Loss: 0.6632  Acc: 78.12%\n",
      "Epoch 1 [161/938]  Loss: 0.7309  Acc: 78.12%\n",
      "Epoch 1 [162/938]  Loss: 0.6381  Acc: 81.25%\n",
      "Epoch 1 [163/938]  Loss: 0.6426  Acc: 85.94%\n",
      "Epoch 1 [164/938]  Loss: 0.4924  Acc: 89.06%\n",
      "Epoch 1 [165/938]  Loss: 0.7350  Acc: 76.56%\n",
      "Epoch 1 [166/938]  Loss: 0.5883  Acc: 82.81%\n",
      "Epoch 1 [167/938]  Loss: 0.6980  Acc: 82.81%\n",
      "Epoch 1 [168/938]  Loss: 0.6652  Acc: 79.69%\n",
      "Epoch 1 [169/938]  Loss: 0.5608  Acc: 84.38%\n",
      "Epoch 1 [170/938]  Loss: 0.6875  Acc: 78.12%\n",
      "Epoch 1 [171/938]  Loss: 0.5086  Acc: 84.38%\n",
      "Epoch 1 [172/938]  Loss: 0.4799  Acc: 87.50%\n",
      "Epoch 1 [173/938]  Loss: 0.6462  Acc: 81.25%\n",
      "Epoch 1 [174/938]  Loss: 0.7103  Acc: 81.25%\n",
      "Epoch 1 [175/938]  Loss: 0.7550  Acc: 76.56%\n",
      "Epoch 1 [176/938]  Loss: 0.7013  Acc: 79.69%\n",
      "Epoch 1 [177/938]  Loss: 0.5312  Acc: 78.12%\n",
      "Epoch 1 [178/938]  Loss: 0.4392  Acc: 90.62%\n",
      "Epoch 1 [121/938]  Loss: 1.1752  Acc: 70.31%\n",
      "Epoch 1 [122/938]  Loss: 1.3032  Acc: 62.50%\n",
      "Epoch 1 [123/938]  Loss: 1.1922  Acc: 64.06%\n",
      "Epoch 1 [124/938]  Loss: 1.1964  Acc: 64.06%\n",
      "Epoch 1 [125/938]  Loss: 1.0212  Acc: 79.69%\n",
      "Epoch 1 [126/938]  Loss: 1.0996  Acc: 67.19%\n",
      "Epoch 1 [127/938]  Loss: 1.1199  Acc: 68.75%\n",
      "Epoch 1 [128/938]  Loss: 0.8966  Acc: 85.94%\n",
      "Epoch 1 [129/938]  Loss: 0.9057  Acc: 81.25%\n",
      "Epoch 1 [130/938]  Loss: 0.9563  Acc: 79.69%\n",
      "Epoch 1 [131/938]  Loss: 1.1088  Acc: 59.38%\n",
      "Epoch 1 [132/938]  Loss: 0.9487  Acc: 73.44%\n",
      "Epoch 1 [133/938]  Loss: 1.0682  Acc: 62.50%\n",
      "Epoch 1 [134/938]  Loss: 0.8580  Acc: 79.69%\n",
      "Epoch 1 [135/938]  Loss: 1.0529  Acc: 78.12%\n",
      "Epoch 1 [136/938]  Loss: 0.8742  Acc: 79.69%\n",
      "Epoch 1 [137/938]  Loss: 0.9873  Acc: 71.88%\n",
      "Epoch 1 [138/938]  Loss: 0.8895  Acc: 71.88%\n",
      "Epoch 1 [139/938]  Loss: 0.9493  Acc: 84.38%\n",
      "Epoch 1 [140/938]  Loss: 0.9117  Acc: 73.44%\n",
      "Epoch 1 [141/938]  Loss: 0.8707  Acc: 71.88%\n",
      "Epoch 1 [142/938]  Loss: 1.0285  Acc: 67.19%\n",
      "Epoch 1 [143/938]  Loss: 0.9142  Acc: 70.31%\n",
      "Epoch 1 [144/938]  Loss: 0.7648  Acc: 78.12%\n",
      "Epoch 1 [145/938]  Loss: 0.7114  Acc: 79.69%\n",
      "Epoch 1 [146/938]  Loss: 0.7661  Acc: 79.69%\n",
      "Epoch 1 [147/938]  Loss: 0.7456  Acc: 84.38%\n",
      "Epoch 1 [148/938]  Loss: 0.6761  Acc: 82.81%\n",
      "Epoch 1 [149/938]  Loss: 0.8090  Acc: 75.00%\n",
      "Epoch 1 [150/938]  Loss: 0.6779  Acc: 82.81%\n",
      "Epoch 1 [151/938]  Loss: 0.7419  Acc: 79.69%\n",
      "Epoch 1 [152/938]  Loss: 0.8459  Acc: 79.69%\n",
      "Epoch 1 [153/938]  Loss: 0.8235  Acc: 81.25%\n",
      "Epoch 1 [154/938]  Loss: 0.6451  Acc: 87.50%\n",
      "Epoch 1 [155/938]  Loss: 0.6920  Acc: 78.12%\n",
      "Epoch 1 [156/938]  Loss: 0.6578  Acc: 82.81%\n",
      "Epoch 1 [157/938]  Loss: 0.8584  Acc: 73.44%\n",
      "Epoch 1 [158/938]  Loss: 0.6559  Acc: 85.94%\n",
      "Epoch 1 [159/938]  Loss: 0.6415  Acc: 79.69%\n",
      "Epoch 1 [160/938]  Loss: 0.6632  Acc: 78.12%\n",
      "Epoch 1 [161/938]  Loss: 0.7309  Acc: 78.12%\n",
      "Epoch 1 [162/938]  Loss: 0.6381  Acc: 81.25%\n",
      "Epoch 1 [163/938]  Loss: 0.6426  Acc: 85.94%\n",
      "Epoch 1 [164/938]  Loss: 0.4924  Acc: 89.06%\n",
      "Epoch 1 [165/938]  Loss: 0.7350  Acc: 76.56%\n",
      "Epoch 1 [166/938]  Loss: 0.5883  Acc: 82.81%\n",
      "Epoch 1 [167/938]  Loss: 0.6980  Acc: 82.81%\n",
      "Epoch 1 [168/938]  Loss: 0.6652  Acc: 79.69%\n",
      "Epoch 1 [169/938]  Loss: 0.5608  Acc: 84.38%\n",
      "Epoch 1 [170/938]  Loss: 0.6875  Acc: 78.12%\n",
      "Epoch 1 [171/938]  Loss: 0.5086  Acc: 84.38%\n",
      "Epoch 1 [172/938]  Loss: 0.4799  Acc: 87.50%\n",
      "Epoch 1 [173/938]  Loss: 0.6462  Acc: 81.25%\n",
      "Epoch 1 [174/938]  Loss: 0.7103  Acc: 81.25%\n",
      "Epoch 1 [175/938]  Loss: 0.7550  Acc: 76.56%\n",
      "Epoch 1 [176/938]  Loss: 0.7013  Acc: 79.69%\n",
      "Epoch 1 [177/938]  Loss: 0.5312  Acc: 78.12%\n",
      "Epoch 1 [178/938]  Loss: 0.4392  Acc: 90.62%\n",
      "Epoch 1 [179/938]  Loss: 0.5171  Acc: 85.94%\n",
      "Epoch 1 [180/938]  Loss: 0.5818  Acc: 90.62%\n",
      "Epoch 1 [181/938]  Loss: 0.5153  Acc: 85.94%\n",
      "Epoch 1 [182/938]  Loss: 0.5253  Acc: 85.94%\n",
      "Epoch 1 [183/938]  Loss: 0.5511  Acc: 85.94%\n",
      "Epoch 1 [184/938]  Loss: 0.4838  Acc: 87.50%\n",
      "Epoch 1 [185/938]  Loss: 0.5187  Acc: 84.38%\n",
      "Epoch 1 [186/938]  Loss: 0.5252  Acc: 82.81%\n",
      "Epoch 1 [187/938]  Loss: 0.5466  Acc: 81.25%\n",
      "Epoch 1 [188/938]  Loss: 0.5063  Acc: 84.38%\n",
      "Epoch 1 [189/938]  Loss: 0.5552  Acc: 79.69%\n",
      "Epoch 1 [190/938]  Loss: 0.5956  Acc: 82.81%\n",
      "Epoch 1 [191/938]  Loss: 0.7325  Acc: 70.31%\n",
      "Epoch 1 [192/938]  Loss: 0.5399  Acc: 84.38%\n",
      "Epoch 1 [193/938]  Loss: 0.5913  Acc: 84.38%\n",
      "Epoch 1 [194/938]  Loss: 0.5089  Acc: 87.50%\n",
      "Epoch 1 [195/938]  Loss: 0.4631  Acc: 95.31%\n",
      "Epoch 1 [196/938]  Loss: 0.5162  Acc: 87.50%\n",
      "Epoch 1 [197/938]  Loss: 0.6110  Acc: 85.94%\n",
      "Epoch 1 [198/938]  Loss: 0.4305  Acc: 84.38%\n",
      "Epoch 1 [199/938]  Loss: 0.5817  Acc: 82.81%\n",
      "Epoch 1 [200/938]  Loss: 0.5198  Acc: 89.06%\n",
      "Epoch 1 [201/938]  Loss: 0.5846  Acc: 87.50%\n",
      "Epoch 1 [202/938]  Loss: 0.4815  Acc: 82.81%\n",
      "Epoch 1 [203/938]  Loss: 0.5345  Acc: 82.81%\n",
      "Epoch 1 [204/938]  Loss: 0.6256  Acc: 85.94%\n",
      "Epoch 1 [205/938]  Loss: 0.4354  Acc: 90.62%\n",
      "Epoch 1 [206/938]  Loss: 0.6902  Acc: 81.25%\n",
      "Epoch 1 [207/938]  Loss: 0.5015  Acc: 82.81%\n",
      "Epoch 1 [208/938]  Loss: 0.5724  Acc: 85.94%\n",
      "Epoch 1 [209/938]  Loss: 0.3786  Acc: 89.06%\n",
      "Epoch 1 [210/938]  Loss: 0.3135  Acc: 95.31%\n",
      "Epoch 1 [211/938]  Loss: 0.4443  Acc: 87.50%\n",
      "Epoch 1 [212/938]  Loss: 0.4735  Acc: 87.50%\n",
      "Epoch 1 [213/938]  Loss: 0.4338  Acc: 85.94%\n",
      "Epoch 1 [214/938]  Loss: 0.4177  Acc: 90.62%\n",
      "Epoch 1 [215/938]  Loss: 0.5486  Acc: 84.38%\n",
      "Epoch 1 [216/938]  Loss: 0.3238  Acc: 89.06%\n",
      "Epoch 1 [217/938]  Loss: 0.5790  Acc: 84.38%\n",
      "Epoch 1 [218/938]  Loss: 0.5041  Acc: 85.94%\n",
      "Epoch 1 [219/938]  Loss: 0.7139  Acc: 76.56%\n",
      "Epoch 1 [220/938]  Loss: 0.3576  Acc: 87.50%\n",
      "Epoch 1 [221/938]  Loss: 0.6500  Acc: 82.81%\n",
      "Epoch 1 [222/938]  Loss: 0.4657  Acc: 84.38%\n",
      "Epoch 1 [223/938]  Loss: 0.5083  Acc: 81.25%\n",
      "Epoch 1 [224/938]  Loss: 0.4338  Acc: 92.19%\n",
      "Epoch 1 [225/938]  Loss: 0.4301  Acc: 89.06%\n",
      "Epoch 1 [226/938]  Loss: 0.5951  Acc: 79.69%\n",
      "Epoch 1 [227/938]  Loss: 0.6602  Acc: 79.69%\n",
      "Epoch 1 [228/938]  Loss: 0.3503  Acc: 93.75%\n",
      "Epoch 1 [229/938]  Loss: 0.4205  Acc: 87.50%\n",
      "Epoch 1 [230/938]  Loss: 0.4084  Acc: 87.50%\n",
      "Epoch 1 [231/938]  Loss: 0.4239  Acc: 90.62%\n",
      "Epoch 1 [232/938]  Loss: 0.4371  Acc: 87.50%\n",
      "Epoch 1 [233/938]  Loss: 0.4939  Acc: 85.94%\n",
      "Epoch 1 [234/938]  Loss: 0.5417  Acc: 84.38%\n",
      "Epoch 1 [235/938]  Loss: 0.5103  Acc: 84.38%\n",
      "Epoch 1 [236/938]  Loss: 0.3617  Acc: 90.62%\n",
      "Epoch 1 [237/938]  Loss: 0.4584  Acc: 90.62%\n",
      "Epoch 1 [238/938]  Loss: 0.5083  Acc: 85.94%\n",
      "Epoch 1 [239/938]  Loss: 0.4011  Acc: 84.38%\n",
      "Epoch 1 [240/938]  Loss: 0.5056  Acc: 85.94%\n",
      "Epoch 1 [241/938]  Loss: 0.3758  Acc: 90.62%\n",
      "Epoch 1 [242/938]  Loss: 0.3637  Acc: 93.75%\n",
      "Epoch 1 [243/938]  Loss: 0.5436  Acc: 89.06%\n",
      "Epoch 1 [244/938]  Loss: 0.3889  Acc: 87.50%\n",
      "Epoch 1 [179/938]  Loss: 0.5171  Acc: 85.94%\n",
      "Epoch 1 [180/938]  Loss: 0.5818  Acc: 90.62%\n",
      "Epoch 1 [181/938]  Loss: 0.5153  Acc: 85.94%\n",
      "Epoch 1 [182/938]  Loss: 0.5253  Acc: 85.94%\n",
      "Epoch 1 [183/938]  Loss: 0.5511  Acc: 85.94%\n",
      "Epoch 1 [184/938]  Loss: 0.4838  Acc: 87.50%\n",
      "Epoch 1 [185/938]  Loss: 0.5187  Acc: 84.38%\n",
      "Epoch 1 [186/938]  Loss: 0.5252  Acc: 82.81%\n",
      "Epoch 1 [187/938]  Loss: 0.5466  Acc: 81.25%\n",
      "Epoch 1 [188/938]  Loss: 0.5063  Acc: 84.38%\n",
      "Epoch 1 [189/938]  Loss: 0.5552  Acc: 79.69%\n",
      "Epoch 1 [190/938]  Loss: 0.5956  Acc: 82.81%\n",
      "Epoch 1 [191/938]  Loss: 0.7325  Acc: 70.31%\n",
      "Epoch 1 [192/938]  Loss: 0.5399  Acc: 84.38%\n",
      "Epoch 1 [193/938]  Loss: 0.5913  Acc: 84.38%\n",
      "Epoch 1 [194/938]  Loss: 0.5089  Acc: 87.50%\n",
      "Epoch 1 [195/938]  Loss: 0.4631  Acc: 95.31%\n",
      "Epoch 1 [196/938]  Loss: 0.5162  Acc: 87.50%\n",
      "Epoch 1 [197/938]  Loss: 0.6110  Acc: 85.94%\n",
      "Epoch 1 [198/938]  Loss: 0.4305  Acc: 84.38%\n",
      "Epoch 1 [199/938]  Loss: 0.5817  Acc: 82.81%\n",
      "Epoch 1 [200/938]  Loss: 0.5198  Acc: 89.06%\n",
      "Epoch 1 [201/938]  Loss: 0.5846  Acc: 87.50%\n",
      "Epoch 1 [202/938]  Loss: 0.4815  Acc: 82.81%\n",
      "Epoch 1 [203/938]  Loss: 0.5345  Acc: 82.81%\n",
      "Epoch 1 [204/938]  Loss: 0.6256  Acc: 85.94%\n",
      "Epoch 1 [205/938]  Loss: 0.4354  Acc: 90.62%\n",
      "Epoch 1 [206/938]  Loss: 0.6902  Acc: 81.25%\n",
      "Epoch 1 [207/938]  Loss: 0.5015  Acc: 82.81%\n",
      "Epoch 1 [208/938]  Loss: 0.5724  Acc: 85.94%\n",
      "Epoch 1 [209/938]  Loss: 0.3786  Acc: 89.06%\n",
      "Epoch 1 [210/938]  Loss: 0.3135  Acc: 95.31%\n",
      "Epoch 1 [211/938]  Loss: 0.4443  Acc: 87.50%\n",
      "Epoch 1 [212/938]  Loss: 0.4735  Acc: 87.50%\n",
      "Epoch 1 [213/938]  Loss: 0.4338  Acc: 85.94%\n",
      "Epoch 1 [214/938]  Loss: 0.4177  Acc: 90.62%\n",
      "Epoch 1 [215/938]  Loss: 0.5486  Acc: 84.38%\n",
      "Epoch 1 [216/938]  Loss: 0.3238  Acc: 89.06%\n",
      "Epoch 1 [217/938]  Loss: 0.5790  Acc: 84.38%\n",
      "Epoch 1 [218/938]  Loss: 0.5041  Acc: 85.94%\n",
      "Epoch 1 [219/938]  Loss: 0.7139  Acc: 76.56%\n",
      "Epoch 1 [220/938]  Loss: 0.3576  Acc: 87.50%\n",
      "Epoch 1 [221/938]  Loss: 0.6500  Acc: 82.81%\n",
      "Epoch 1 [222/938]  Loss: 0.4657  Acc: 84.38%\n",
      "Epoch 1 [223/938]  Loss: 0.5083  Acc: 81.25%\n",
      "Epoch 1 [224/938]  Loss: 0.4338  Acc: 92.19%\n",
      "Epoch 1 [225/938]  Loss: 0.4301  Acc: 89.06%\n",
      "Epoch 1 [226/938]  Loss: 0.5951  Acc: 79.69%\n",
      "Epoch 1 [227/938]  Loss: 0.6602  Acc: 79.69%\n",
      "Epoch 1 [228/938]  Loss: 0.3503  Acc: 93.75%\n",
      "Epoch 1 [229/938]  Loss: 0.4205  Acc: 87.50%\n",
      "Epoch 1 [230/938]  Loss: 0.4084  Acc: 87.50%\n",
      "Epoch 1 [231/938]  Loss: 0.4239  Acc: 90.62%\n",
      "Epoch 1 [232/938]  Loss: 0.4371  Acc: 87.50%\n",
      "Epoch 1 [233/938]  Loss: 0.4939  Acc: 85.94%\n",
      "Epoch 1 [234/938]  Loss: 0.5417  Acc: 84.38%\n",
      "Epoch 1 [235/938]  Loss: 0.5103  Acc: 84.38%\n",
      "Epoch 1 [236/938]  Loss: 0.3617  Acc: 90.62%\n",
      "Epoch 1 [237/938]  Loss: 0.4584  Acc: 90.62%\n",
      "Epoch 1 [238/938]  Loss: 0.5083  Acc: 85.94%\n",
      "Epoch 1 [239/938]  Loss: 0.4011  Acc: 84.38%\n",
      "Epoch 1 [240/938]  Loss: 0.5056  Acc: 85.94%\n",
      "Epoch 1 [241/938]  Loss: 0.3758  Acc: 90.62%\n",
      "Epoch 1 [242/938]  Loss: 0.3637  Acc: 93.75%\n",
      "Epoch 1 [243/938]  Loss: 0.5436  Acc: 89.06%\n",
      "Epoch 1 [244/938]  Loss: 0.3889  Acc: 87.50%\n",
      "Epoch 1 [245/938]  Loss: 0.4434  Acc: 82.81%\n",
      "Epoch 1 [246/938]  Loss: 0.3513  Acc: 90.62%\n",
      "Epoch 1 [247/938]  Loss: 0.4367  Acc: 84.38%\n",
      "Epoch 1 [248/938]  Loss: 0.5327  Acc: 82.81%\n",
      "Epoch 1 [249/938]  Loss: 0.4704  Acc: 85.94%\n",
      "Epoch 1 [250/938]  Loss: 0.4377  Acc: 90.62%\n",
      "Epoch 1 [251/938]  Loss: 0.3281  Acc: 92.19%\n",
      "Epoch 1 [252/938]  Loss: 0.4391  Acc: 92.19%\n",
      "Epoch 1 [253/938]  Loss: 0.2643  Acc: 93.75%\n",
      "Epoch 1 [254/938]  Loss: 0.3808  Acc: 89.06%\n",
      "Epoch 1 [255/938]  Loss: 0.4232  Acc: 84.38%\n",
      "Epoch 1 [256/938]  Loss: 0.2997  Acc: 90.62%\n",
      "Epoch 1 [257/938]  Loss: 0.3324  Acc: 92.19%\n",
      "Epoch 1 [258/938]  Loss: 0.5783  Acc: 84.38%\n",
      "Epoch 1 [259/938]  Loss: 0.5850  Acc: 79.69%\n",
      "Epoch 1 [260/938]  Loss: 0.5397  Acc: 85.94%\n",
      "Epoch 1 [261/938]  Loss: 0.5199  Acc: 87.50%\n",
      "Epoch 1 [262/938]  Loss: 0.3695  Acc: 90.62%\n",
      "Epoch 1 [263/938]  Loss: 0.2407  Acc: 92.19%\n",
      "Epoch 1 [264/938]  Loss: 0.2840  Acc: 95.31%\n",
      "Epoch 1 [265/938]  Loss: 0.5490  Acc: 82.81%\n",
      "Epoch 1 [266/938]  Loss: 0.6095  Acc: 84.38%\n",
      "Epoch 1 [267/938]  Loss: 0.4276  Acc: 90.62%\n",
      "Epoch 1 [268/938]  Loss: 0.4255  Acc: 87.50%\n",
      "Epoch 1 [269/938]  Loss: 0.3590  Acc: 93.75%\n",
      "Epoch 1 [270/938]  Loss: 0.2336  Acc: 95.31%\n",
      "Epoch 1 [271/938]  Loss: 0.3897  Acc: 90.62%\n",
      "Epoch 1 [272/938]  Loss: 0.4629  Acc: 85.94%\n",
      "Epoch 1 [273/938]  Loss: 0.2847  Acc: 90.62%\n",
      "Epoch 1 [274/938]  Loss: 0.2484  Acc: 93.75%\n",
      "Epoch 1 [275/938]  Loss: 0.4201  Acc: 87.50%\n",
      "Epoch 1 [276/938]  Loss: 0.3736  Acc: 90.62%\n",
      "Epoch 1 [277/938]  Loss: 0.2651  Acc: 93.75%\n",
      "Epoch 1 [278/938]  Loss: 0.7110  Acc: 84.38%\n",
      "Epoch 1 [279/938]  Loss: 0.3488  Acc: 89.06%\n",
      "Epoch 1 [280/938]  Loss: 0.2352  Acc: 96.88%\n",
      "Epoch 1 [281/938]  Loss: 0.3225  Acc: 90.62%\n",
      "Epoch 1 [282/938]  Loss: 0.4908  Acc: 81.25%\n",
      "Epoch 1 [283/938]  Loss: 0.3353  Acc: 92.19%\n",
      "Epoch 1 [284/938]  Loss: 0.3837  Acc: 87.50%\n",
      "Epoch 1 [285/938]  Loss: 0.2459  Acc: 95.31%\n",
      "Epoch 1 [286/938]  Loss: 0.2923  Acc: 90.62%\n",
      "Epoch 1 [287/938]  Loss: 0.3710  Acc: 90.62%\n",
      "Epoch 1 [288/938]  Loss: 0.5238  Acc: 82.81%\n",
      "Epoch 1 [289/938]  Loss: 0.4446  Acc: 89.06%\n",
      "Epoch 1 [290/938]  Loss: 0.2641  Acc: 90.62%\n",
      "Epoch 1 [291/938]  Loss: 0.3685  Acc: 92.19%\n",
      "Epoch 1 [292/938]  Loss: 0.5093  Acc: 89.06%\n",
      "Epoch 1 [293/938]  Loss: 0.2950  Acc: 90.62%\n",
      "Epoch 1 [294/938]  Loss: 0.2102  Acc: 95.31%\n",
      "Epoch 1 [295/938]  Loss: 0.4202  Acc: 89.06%\n",
      "Epoch 1 [245/938]  Loss: 0.4434  Acc: 82.81%\n",
      "Epoch 1 [246/938]  Loss: 0.3513  Acc: 90.62%\n",
      "Epoch 1 [247/938]  Loss: 0.4367  Acc: 84.38%\n",
      "Epoch 1 [248/938]  Loss: 0.5327  Acc: 82.81%\n",
      "Epoch 1 [249/938]  Loss: 0.4704  Acc: 85.94%\n",
      "Epoch 1 [250/938]  Loss: 0.4377  Acc: 90.62%\n",
      "Epoch 1 [251/938]  Loss: 0.3281  Acc: 92.19%\n",
      "Epoch 1 [252/938]  Loss: 0.4391  Acc: 92.19%\n",
      "Epoch 1 [253/938]  Loss: 0.2643  Acc: 93.75%\n",
      "Epoch 1 [254/938]  Loss: 0.3808  Acc: 89.06%\n",
      "Epoch 1 [255/938]  Loss: 0.4232  Acc: 84.38%\n",
      "Epoch 1 [256/938]  Loss: 0.2997  Acc: 90.62%\n",
      "Epoch 1 [257/938]  Loss: 0.3324  Acc: 92.19%\n",
      "Epoch 1 [258/938]  Loss: 0.5783  Acc: 84.38%\n",
      "Epoch 1 [259/938]  Loss: 0.5850  Acc: 79.69%\n",
      "Epoch 1 [260/938]  Loss: 0.5397  Acc: 85.94%\n",
      "Epoch 1 [261/938]  Loss: 0.5199  Acc: 87.50%\n",
      "Epoch 1 [262/938]  Loss: 0.3695  Acc: 90.62%\n",
      "Epoch 1 [263/938]  Loss: 0.2407  Acc: 92.19%\n",
      "Epoch 1 [264/938]  Loss: 0.2840  Acc: 95.31%\n",
      "Epoch 1 [265/938]  Loss: 0.5490  Acc: 82.81%\n",
      "Epoch 1 [266/938]  Loss: 0.6095  Acc: 84.38%\n",
      "Epoch 1 [267/938]  Loss: 0.4276  Acc: 90.62%\n",
      "Epoch 1 [268/938]  Loss: 0.4255  Acc: 87.50%\n",
      "Epoch 1 [269/938]  Loss: 0.3590  Acc: 93.75%\n",
      "Epoch 1 [270/938]  Loss: 0.2336  Acc: 95.31%\n",
      "Epoch 1 [271/938]  Loss: 0.3897  Acc: 90.62%\n",
      "Epoch 1 [272/938]  Loss: 0.4629  Acc: 85.94%\n",
      "Epoch 1 [273/938]  Loss: 0.2847  Acc: 90.62%\n",
      "Epoch 1 [274/938]  Loss: 0.2484  Acc: 93.75%\n",
      "Epoch 1 [275/938]  Loss: 0.4201  Acc: 87.50%\n",
      "Epoch 1 [276/938]  Loss: 0.3736  Acc: 90.62%\n",
      "Epoch 1 [277/938]  Loss: 0.2651  Acc: 93.75%\n",
      "Epoch 1 [278/938]  Loss: 0.7110  Acc: 84.38%\n",
      "Epoch 1 [279/938]  Loss: 0.3488  Acc: 89.06%\n",
      "Epoch 1 [280/938]  Loss: 0.2352  Acc: 96.88%\n",
      "Epoch 1 [281/938]  Loss: 0.3225  Acc: 90.62%\n",
      "Epoch 1 [282/938]  Loss: 0.4908  Acc: 81.25%\n",
      "Epoch 1 [283/938]  Loss: 0.3353  Acc: 92.19%\n",
      "Epoch 1 [284/938]  Loss: 0.3837  Acc: 87.50%\n",
      "Epoch 1 [285/938]  Loss: 0.2459  Acc: 95.31%\n",
      "Epoch 1 [286/938]  Loss: 0.2923  Acc: 90.62%\n",
      "Epoch 1 [287/938]  Loss: 0.3710  Acc: 90.62%\n",
      "Epoch 1 [288/938]  Loss: 0.5238  Acc: 82.81%\n",
      "Epoch 1 [289/938]  Loss: 0.4446  Acc: 89.06%\n",
      "Epoch 1 [290/938]  Loss: 0.2641  Acc: 90.62%\n",
      "Epoch 1 [291/938]  Loss: 0.3685  Acc: 92.19%\n",
      "Epoch 1 [292/938]  Loss: 0.5093  Acc: 89.06%\n",
      "Epoch 1 [293/938]  Loss: 0.2950  Acc: 90.62%\n",
      "Epoch 1 [294/938]  Loss: 0.2102  Acc: 95.31%\n",
      "Epoch 1 [295/938]  Loss: 0.4202  Acc: 89.06%\n",
      "Epoch 1 [296/938]  Loss: 0.3012  Acc: 89.06%\n",
      "Epoch 1 [297/938]  Loss: 0.3205  Acc: 90.62%\n",
      "Epoch 1 [298/938]  Loss: 0.3927  Acc: 87.50%\n",
      "Epoch 1 [299/938]  Loss: 0.2671  Acc: 90.62%\n",
      "Epoch 1 [300/938]  Loss: 0.3943  Acc: 87.50%\n",
      "Epoch 1 [301/938]  Loss: 0.3579  Acc: 92.19%\n",
      "Epoch 1 [302/938]  Loss: 0.4382  Acc: 90.62%\n",
      "Epoch 1 [303/938]  Loss: 0.3788  Acc: 92.19%\n",
      "Epoch 1 [304/938]  Loss: 0.4064  Acc: 85.94%\n",
      "Epoch 1 [305/938]  Loss: 0.3710  Acc: 90.62%\n",
      "Epoch 1 [306/938]  Loss: 0.2264  Acc: 93.75%\n",
      "Epoch 1 [307/938]  Loss: 0.4892  Acc: 89.06%\n",
      "Epoch 1 [308/938]  Loss: 0.2184  Acc: 92.19%\n",
      "Epoch 1 [309/938]  Loss: 0.3464  Acc: 90.62%\n",
      "Epoch 1 [310/938]  Loss: 0.3574  Acc: 90.62%\n",
      "Epoch 1 [311/938]  Loss: 0.3966  Acc: 89.06%\n",
      "Epoch 1 [312/938]  Loss: 0.3726  Acc: 85.94%\n",
      "Epoch 1 [313/938]  Loss: 0.2841  Acc: 90.62%\n",
      "Epoch 1 [314/938]  Loss: 0.1723  Acc: 95.31%\n",
      "Epoch 1 [315/938]  Loss: 0.1903  Acc: 98.44%\n",
      "Epoch 1 [316/938]  Loss: 0.5484  Acc: 81.25%\n",
      "Epoch 1 [317/938]  Loss: 0.2531  Acc: 89.06%\n",
      "Epoch 1 [318/938]  Loss: 0.3135  Acc: 87.50%\n",
      "Epoch 1 [319/938]  Loss: 0.3420  Acc: 92.19%\n",
      "Epoch 1 [320/938]  Loss: 0.3069  Acc: 93.75%\n",
      "Epoch 1 [321/938]  Loss: 0.4864  Acc: 87.50%\n",
      "Epoch 1 [322/938]  Loss: 0.3958  Acc: 87.50%\n",
      "Epoch 1 [323/938]  Loss: 0.4538  Acc: 87.50%\n",
      "Epoch 1 [324/938]  Loss: 0.5134  Acc: 84.38%\n",
      "Epoch 1 [325/938]  Loss: 0.2206  Acc: 95.31%\n",
      "Epoch 1 [326/938]  Loss: 0.4820  Acc: 82.81%\n",
      "Epoch 1 [327/938]  Loss: 0.2853  Acc: 89.06%\n",
      "Epoch 1 [328/938]  Loss: 0.5798  Acc: 85.94%\n",
      "Epoch 1 [329/938]  Loss: 0.3363  Acc: 92.19%\n",
      "Epoch 1 [330/938]  Loss: 0.2905  Acc: 93.75%\n",
      "Epoch 1 [331/938]  Loss: 0.3454  Acc: 89.06%\n",
      "Epoch 1 [332/938]  Loss: 0.3392  Acc: 89.06%\n",
      "Epoch 1 [333/938]  Loss: 0.2904  Acc: 87.50%\n",
      "Epoch 1 [334/938]  Loss: 0.4459  Acc: 79.69%\n",
      "Epoch 1 [335/938]  Loss: 0.5739  Acc: 79.69%\n",
      "Epoch 1 [336/938]  Loss: 0.4473  Acc: 85.94%\n",
      "Epoch 1 [337/938]  Loss: 0.4066  Acc: 87.50%\n",
      "Epoch 1 [338/938]  Loss: 0.4898  Acc: 90.62%\n",
      "Epoch 1 [339/938]  Loss: 0.3653  Acc: 92.19%\n",
      "Epoch 1 [340/938]  Loss: 0.3385  Acc: 85.94%\n",
      "Epoch 1 [341/938]  Loss: 0.3766  Acc: 90.62%\n",
      "Epoch 1 [342/938]  Loss: 0.2576  Acc: 93.75%\n",
      "Epoch 1 [343/938]  Loss: 0.4226  Acc: 84.38%\n",
      "Epoch 1 [344/938]  Loss: 0.3397  Acc: 90.62%\n",
      "Epoch 1 [345/938]  Loss: 0.3343  Acc: 87.50%\n",
      "Epoch 1 [346/938]  Loss: 0.4560  Acc: 87.50%\n",
      "Epoch 1 [347/938]  Loss: 0.3527  Acc: 87.50%\n",
      "Epoch 1 [348/938]  Loss: 0.3016  Acc: 93.75%\n",
      "Epoch 1 [349/938]  Loss: 0.1981  Acc: 93.75%\n",
      "Epoch 1 [350/938]  Loss: 0.3286  Acc: 89.06%\n",
      "Epoch 1 [351/938]  Loss: 0.3450  Acc: 90.62%\n",
      "Epoch 1 [352/938]  Loss: 0.4146  Acc: 90.62%\n",
      "Epoch 1 [353/938]  Loss: 0.2917  Acc: 92.19%\n",
      "Epoch 1 [354/938]  Loss: 0.4808  Acc: 85.94%\n",
      "Epoch 1 [296/938]  Loss: 0.3012  Acc: 89.06%\n",
      "Epoch 1 [297/938]  Loss: 0.3205  Acc: 90.62%\n",
      "Epoch 1 [298/938]  Loss: 0.3927  Acc: 87.50%\n",
      "Epoch 1 [299/938]  Loss: 0.2671  Acc: 90.62%\n",
      "Epoch 1 [300/938]  Loss: 0.3943  Acc: 87.50%\n",
      "Epoch 1 [301/938]  Loss: 0.3579  Acc: 92.19%\n",
      "Epoch 1 [302/938]  Loss: 0.4382  Acc: 90.62%\n",
      "Epoch 1 [303/938]  Loss: 0.3788  Acc: 92.19%\n",
      "Epoch 1 [304/938]  Loss: 0.4064  Acc: 85.94%\n",
      "Epoch 1 [305/938]  Loss: 0.3710  Acc: 90.62%\n",
      "Epoch 1 [306/938]  Loss: 0.2264  Acc: 93.75%\n",
      "Epoch 1 [307/938]  Loss: 0.4892  Acc: 89.06%\n",
      "Epoch 1 [308/938]  Loss: 0.2184  Acc: 92.19%\n",
      "Epoch 1 [309/938]  Loss: 0.3464  Acc: 90.62%\n",
      "Epoch 1 [310/938]  Loss: 0.3574  Acc: 90.62%\n",
      "Epoch 1 [311/938]  Loss: 0.3966  Acc: 89.06%\n",
      "Epoch 1 [312/938]  Loss: 0.3726  Acc: 85.94%\n",
      "Epoch 1 [313/938]  Loss: 0.2841  Acc: 90.62%\n",
      "Epoch 1 [314/938]  Loss: 0.1723  Acc: 95.31%\n",
      "Epoch 1 [315/938]  Loss: 0.1903  Acc: 98.44%\n",
      "Epoch 1 [316/938]  Loss: 0.5484  Acc: 81.25%\n",
      "Epoch 1 [317/938]  Loss: 0.2531  Acc: 89.06%\n",
      "Epoch 1 [318/938]  Loss: 0.3135  Acc: 87.50%\n",
      "Epoch 1 [319/938]  Loss: 0.3420  Acc: 92.19%\n",
      "Epoch 1 [320/938]  Loss: 0.3069  Acc: 93.75%\n",
      "Epoch 1 [321/938]  Loss: 0.4864  Acc: 87.50%\n",
      "Epoch 1 [322/938]  Loss: 0.3958  Acc: 87.50%\n",
      "Epoch 1 [323/938]  Loss: 0.4538  Acc: 87.50%\n",
      "Epoch 1 [324/938]  Loss: 0.5134  Acc: 84.38%\n",
      "Epoch 1 [325/938]  Loss: 0.2206  Acc: 95.31%\n",
      "Epoch 1 [326/938]  Loss: 0.4820  Acc: 82.81%\n",
      "Epoch 1 [327/938]  Loss: 0.2853  Acc: 89.06%\n",
      "Epoch 1 [328/938]  Loss: 0.5798  Acc: 85.94%\n",
      "Epoch 1 [329/938]  Loss: 0.3363  Acc: 92.19%\n",
      "Epoch 1 [330/938]  Loss: 0.2905  Acc: 93.75%\n",
      "Epoch 1 [331/938]  Loss: 0.3454  Acc: 89.06%\n",
      "Epoch 1 [332/938]  Loss: 0.3392  Acc: 89.06%\n",
      "Epoch 1 [333/938]  Loss: 0.2904  Acc: 87.50%\n",
      "Epoch 1 [334/938]  Loss: 0.4459  Acc: 79.69%\n",
      "Epoch 1 [335/938]  Loss: 0.5739  Acc: 79.69%\n",
      "Epoch 1 [336/938]  Loss: 0.4473  Acc: 85.94%\n",
      "Epoch 1 [337/938]  Loss: 0.4066  Acc: 87.50%\n",
      "Epoch 1 [338/938]  Loss: 0.4898  Acc: 90.62%\n",
      "Epoch 1 [339/938]  Loss: 0.3653  Acc: 92.19%\n",
      "Epoch 1 [340/938]  Loss: 0.3385  Acc: 85.94%\n",
      "Epoch 1 [341/938]  Loss: 0.3766  Acc: 90.62%\n",
      "Epoch 1 [342/938]  Loss: 0.2576  Acc: 93.75%\n",
      "Epoch 1 [343/938]  Loss: 0.4226  Acc: 84.38%\n",
      "Epoch 1 [344/938]  Loss: 0.3397  Acc: 90.62%\n",
      "Epoch 1 [345/938]  Loss: 0.3343  Acc: 87.50%\n",
      "Epoch 1 [346/938]  Loss: 0.4560  Acc: 87.50%\n",
      "Epoch 1 [347/938]  Loss: 0.3527  Acc: 87.50%\n",
      "Epoch 1 [348/938]  Loss: 0.3016  Acc: 93.75%\n",
      "Epoch 1 [349/938]  Loss: 0.1981  Acc: 93.75%\n",
      "Epoch 1 [350/938]  Loss: 0.3286  Acc: 89.06%\n",
      "Epoch 1 [351/938]  Loss: 0.3450  Acc: 90.62%\n",
      "Epoch 1 [352/938]  Loss: 0.4146  Acc: 90.62%\n",
      "Epoch 1 [353/938]  Loss: 0.2917  Acc: 92.19%\n",
      "Epoch 1 [354/938]  Loss: 0.4808  Acc: 85.94%\n",
      "Epoch 1 [355/938]  Loss: 0.4058  Acc: 84.38%\n",
      "Epoch 1 [356/938]  Loss: 0.2834  Acc: 92.19%\n",
      "Epoch 1 [357/938]  Loss: 0.3589  Acc: 84.38%\n",
      "Epoch 1 [358/938]  Loss: 0.2359  Acc: 95.31%\n",
      "Epoch 1 [359/938]  Loss: 0.5962  Acc: 85.94%\n",
      "Epoch 1 [360/938]  Loss: 0.3647  Acc: 90.62%\n",
      "Epoch 1 [361/938]  Loss: 0.3426  Acc: 92.19%\n",
      "Epoch 1 [362/938]  Loss: 0.3520  Acc: 89.06%\n",
      "Epoch 1 [363/938]  Loss: 0.3934  Acc: 87.50%\n",
      "Epoch 1 [364/938]  Loss: 0.4376  Acc: 89.06%\n",
      "Epoch 1 [365/938]  Loss: 0.3554  Acc: 90.62%\n",
      "Epoch 1 [366/938]  Loss: 0.3046  Acc: 89.06%\n",
      "Epoch 1 [367/938]  Loss: 0.4977  Acc: 85.94%\n",
      "Epoch 1 [368/938]  Loss: 0.2897  Acc: 93.75%\n",
      "Epoch 1 [369/938]  Loss: 0.3140  Acc: 92.19%\n",
      "Epoch 1 [370/938]  Loss: 0.5119  Acc: 81.25%\n",
      "Epoch 1 [371/938]  Loss: 0.2662  Acc: 92.19%\n",
      "Epoch 1 [372/938]  Loss: 0.3728  Acc: 90.62%\n",
      "Epoch 1 [373/938]  Loss: 0.3588  Acc: 87.50%\n",
      "Epoch 1 [374/938]  Loss: 0.2669  Acc: 90.62%\n",
      "Epoch 1 [375/938]  Loss: 0.3414  Acc: 84.38%\n",
      "Epoch 1 [376/938]  Loss: 0.2912  Acc: 93.75%\n",
      "Epoch 1 [377/938]  Loss: 0.2207  Acc: 98.44%\n",
      "Epoch 1 [378/938]  Loss: 0.2032  Acc: 96.88%\n",
      "Epoch 1 [379/938]  Loss: 0.2677  Acc: 89.06%\n",
      "Epoch 1 [380/938]  Loss: 0.2837  Acc: 90.62%\n",
      "Epoch 1 [381/938]  Loss: 0.3099  Acc: 95.31%\n",
      "Epoch 1 [382/938]  Loss: 0.2691  Acc: 90.62%\n",
      "Epoch 1 [383/938]  Loss: 0.2784  Acc: 90.62%\n",
      "Epoch 1 [384/938]  Loss: 0.2232  Acc: 93.75%\n",
      "Epoch 1 [385/938]  Loss: 0.2868  Acc: 93.75%\n",
      "Epoch 1 [386/938]  Loss: 0.2793  Acc: 95.31%\n",
      "Epoch 1 [387/938]  Loss: 0.4370  Acc: 89.06%\n",
      "Epoch 1 [388/938]  Loss: 0.3038  Acc: 90.62%\n",
      "Epoch 1 [389/938]  Loss: 0.2696  Acc: 92.19%\n",
      "Epoch 1 [390/938]  Loss: 0.2792  Acc: 90.62%\n",
      "Epoch 1 [391/938]  Loss: 0.2224  Acc: 93.75%\n",
      "Epoch 1 [392/938]  Loss: 0.2570  Acc: 92.19%\n",
      "Epoch 1 [393/938]  Loss: 0.2369  Acc: 92.19%\n",
      "Epoch 1 [394/938]  Loss: 0.1507  Acc: 93.75%\n",
      "Epoch 1 [395/938]  Loss: 0.2875  Acc: 90.62%\n",
      "Epoch 1 [396/938]  Loss: 0.3615  Acc: 87.50%\n",
      "Epoch 1 [397/938]  Loss: 0.3532  Acc: 87.50%\n",
      "Epoch 1 [398/938]  Loss: 0.4219  Acc: 89.06%\n",
      "Epoch 1 [399/938]  Loss: 0.2150  Acc: 93.75%\n",
      "Epoch 1 [400/938]  Loss: 0.2305  Acc: 92.19%\n",
      "Epoch 1 [401/938]  Loss: 0.2779  Acc: 90.62%\n",
      "Epoch 1 [402/938]  Loss: 0.5190  Acc: 82.81%\n",
      "Epoch 1 [403/938]  Loss: 0.2054  Acc: 96.88%\n",
      "Epoch 1 [404/938]  Loss: 0.3042  Acc: 89.06%\n",
      "Epoch 1 [405/938]  Loss: 0.3076  Acc: 84.38%\n",
      "Epoch 1 [406/938]  Loss: 0.3603  Acc: 87.50%\n",
      "Epoch 1 [407/938]  Loss: 0.2059  Acc: 95.31%\n",
      "Epoch 1 [408/938]  Loss: 0.2958  Acc: 92.19%\n",
      "Epoch 1 [409/938]  Loss: 0.4095  Acc: 85.94%\n",
      "Epoch 1 [410/938]  Loss: 0.2035  Acc: 93.75%\n",
      "Epoch 1 [411/938]  Loss: 0.4266  Acc: 87.50%\n",
      "Epoch 1 [412/938]  Loss: 0.3232  Acc: 92.19%\n",
      "Epoch 1 [413/938]  Loss: 0.2694  Acc: 90.62%\n",
      "Epoch 1 [414/938]  Loss: 0.3532  Acc: 92.19%\n",
      "Epoch 1 [415/938]  Loss: 0.2468  Acc: 92.19%\n",
      "Epoch 1 [416/938]  Loss: 0.3595  Acc: 89.06%\n",
      "Epoch 1 [355/938]  Loss: 0.4058  Acc: 84.38%\n",
      "Epoch 1 [356/938]  Loss: 0.2834  Acc: 92.19%\n",
      "Epoch 1 [357/938]  Loss: 0.3589  Acc: 84.38%\n",
      "Epoch 1 [358/938]  Loss: 0.2359  Acc: 95.31%\n",
      "Epoch 1 [359/938]  Loss: 0.5962  Acc: 85.94%\n",
      "Epoch 1 [360/938]  Loss: 0.3647  Acc: 90.62%\n",
      "Epoch 1 [361/938]  Loss: 0.3426  Acc: 92.19%\n",
      "Epoch 1 [362/938]  Loss: 0.3520  Acc: 89.06%\n",
      "Epoch 1 [363/938]  Loss: 0.3934  Acc: 87.50%\n",
      "Epoch 1 [364/938]  Loss: 0.4376  Acc: 89.06%\n",
      "Epoch 1 [365/938]  Loss: 0.3554  Acc: 90.62%\n",
      "Epoch 1 [366/938]  Loss: 0.3046  Acc: 89.06%\n",
      "Epoch 1 [367/938]  Loss: 0.4977  Acc: 85.94%\n",
      "Epoch 1 [368/938]  Loss: 0.2897  Acc: 93.75%\n",
      "Epoch 1 [369/938]  Loss: 0.3140  Acc: 92.19%\n",
      "Epoch 1 [370/938]  Loss: 0.5119  Acc: 81.25%\n",
      "Epoch 1 [371/938]  Loss: 0.2662  Acc: 92.19%\n",
      "Epoch 1 [372/938]  Loss: 0.3728  Acc: 90.62%\n",
      "Epoch 1 [373/938]  Loss: 0.3588  Acc: 87.50%\n",
      "Epoch 1 [374/938]  Loss: 0.2669  Acc: 90.62%\n",
      "Epoch 1 [375/938]  Loss: 0.3414  Acc: 84.38%\n",
      "Epoch 1 [376/938]  Loss: 0.2912  Acc: 93.75%\n",
      "Epoch 1 [377/938]  Loss: 0.2207  Acc: 98.44%\n",
      "Epoch 1 [378/938]  Loss: 0.2032  Acc: 96.88%\n",
      "Epoch 1 [379/938]  Loss: 0.2677  Acc: 89.06%\n",
      "Epoch 1 [380/938]  Loss: 0.2837  Acc: 90.62%\n",
      "Epoch 1 [381/938]  Loss: 0.3099  Acc: 95.31%\n",
      "Epoch 1 [382/938]  Loss: 0.2691  Acc: 90.62%\n",
      "Epoch 1 [383/938]  Loss: 0.2784  Acc: 90.62%\n",
      "Epoch 1 [384/938]  Loss: 0.2232  Acc: 93.75%\n",
      "Epoch 1 [385/938]  Loss: 0.2868  Acc: 93.75%\n",
      "Epoch 1 [386/938]  Loss: 0.2793  Acc: 95.31%\n",
      "Epoch 1 [387/938]  Loss: 0.4370  Acc: 89.06%\n",
      "Epoch 1 [388/938]  Loss: 0.3038  Acc: 90.62%\n",
      "Epoch 1 [389/938]  Loss: 0.2696  Acc: 92.19%\n",
      "Epoch 1 [390/938]  Loss: 0.2792  Acc: 90.62%\n",
      "Epoch 1 [391/938]  Loss: 0.2224  Acc: 93.75%\n",
      "Epoch 1 [392/938]  Loss: 0.2570  Acc: 92.19%\n",
      "Epoch 1 [393/938]  Loss: 0.2369  Acc: 92.19%\n",
      "Epoch 1 [394/938]  Loss: 0.1507  Acc: 93.75%\n",
      "Epoch 1 [395/938]  Loss: 0.2875  Acc: 90.62%\n",
      "Epoch 1 [396/938]  Loss: 0.3615  Acc: 87.50%\n",
      "Epoch 1 [397/938]  Loss: 0.3532  Acc: 87.50%\n",
      "Epoch 1 [398/938]  Loss: 0.4219  Acc: 89.06%\n",
      "Epoch 1 [399/938]  Loss: 0.2150  Acc: 93.75%\n",
      "Epoch 1 [400/938]  Loss: 0.2305  Acc: 92.19%\n",
      "Epoch 1 [401/938]  Loss: 0.2779  Acc: 90.62%\n",
      "Epoch 1 [402/938]  Loss: 0.5190  Acc: 82.81%\n",
      "Epoch 1 [403/938]  Loss: 0.2054  Acc: 96.88%\n",
      "Epoch 1 [404/938]  Loss: 0.3042  Acc: 89.06%\n",
      "Epoch 1 [405/938]  Loss: 0.3076  Acc: 84.38%\n",
      "Epoch 1 [406/938]  Loss: 0.3603  Acc: 87.50%\n",
      "Epoch 1 [407/938]  Loss: 0.2059  Acc: 95.31%\n",
      "Epoch 1 [408/938]  Loss: 0.2958  Acc: 92.19%\n",
      "Epoch 1 [409/938]  Loss: 0.4095  Acc: 85.94%\n",
      "Epoch 1 [410/938]  Loss: 0.2035  Acc: 93.75%\n",
      "Epoch 1 [411/938]  Loss: 0.4266  Acc: 87.50%\n",
      "Epoch 1 [412/938]  Loss: 0.3232  Acc: 92.19%\n",
      "Epoch 1 [413/938]  Loss: 0.2694  Acc: 90.62%\n",
      "Epoch 1 [414/938]  Loss: 0.3532  Acc: 92.19%\n",
      "Epoch 1 [415/938]  Loss: 0.2468  Acc: 92.19%\n",
      "Epoch 1 [416/938]  Loss: 0.3595  Acc: 89.06%\n",
      "Epoch 1 [417/938]  Loss: 0.2016  Acc: 96.88%\n",
      "Epoch 1 [418/938]  Loss: 0.3761  Acc: 87.50%\n",
      "Epoch 1 [419/938]  Loss: 0.5328  Acc: 87.50%\n",
      "Epoch 1 [420/938]  Loss: 0.3020  Acc: 93.75%\n",
      "Epoch 1 [421/938]  Loss: 0.2311  Acc: 95.31%\n",
      "Epoch 1 [422/938]  Loss: 0.2980  Acc: 89.06%\n",
      "Epoch 1 [423/938]  Loss: 0.1627  Acc: 96.88%\n",
      "Epoch 1 [424/938]  Loss: 0.4396  Acc: 82.81%\n",
      "Epoch 1 [425/938]  Loss: 0.4273  Acc: 87.50%\n",
      "Epoch 1 [426/938]  Loss: 0.3101  Acc: 90.62%\n",
      "Epoch 1 [427/938]  Loss: 0.3440  Acc: 92.19%\n",
      "Epoch 1 [428/938]  Loss: 0.3909  Acc: 85.94%\n",
      "Epoch 1 [429/938]  Loss: 0.3234  Acc: 85.94%\n",
      "Epoch 1 [430/938]  Loss: 0.4285  Acc: 89.06%\n",
      "Epoch 1 [431/938]  Loss: 0.3375  Acc: 93.75%\n",
      "Epoch 1 [432/938]  Loss: 0.3228  Acc: 92.19%\n",
      "Epoch 1 [433/938]  Loss: 0.2463  Acc: 90.62%\n",
      "Epoch 1 [434/938]  Loss: 0.2730  Acc: 90.62%\n",
      "Epoch 1 [435/938]  Loss: 0.5277  Acc: 81.25%\n",
      "Epoch 1 [436/938]  Loss: 0.3792  Acc: 85.94%\n",
      "Epoch 1 [437/938]  Loss: 0.2123  Acc: 92.19%\n",
      "Epoch 1 [438/938]  Loss: 0.4046  Acc: 87.50%\n",
      "Epoch 1 [439/938]  Loss: 0.2362  Acc: 92.19%\n",
      "Epoch 1 [440/938]  Loss: 0.3277  Acc: 89.06%\n",
      "Epoch 1 [441/938]  Loss: 0.4108  Acc: 87.50%\n",
      "Epoch 1 [442/938]  Loss: 0.3088  Acc: 90.62%\n",
      "Epoch 1 [443/938]  Loss: 0.2482  Acc: 89.06%\n",
      "Epoch 1 [444/938]  Loss: 0.2812  Acc: 93.75%\n",
      "Epoch 1 [445/938]  Loss: 0.1462  Acc: 96.88%\n",
      "Epoch 1 [446/938]  Loss: 0.4278  Acc: 89.06%\n",
      "Epoch 1 [447/938]  Loss: 0.4154  Acc: 87.50%\n",
      "Epoch 1 [448/938]  Loss: 0.3061  Acc: 93.75%\n",
      "Epoch 1 [449/938]  Loss: 0.2147  Acc: 95.31%\n",
      "Epoch 1 [450/938]  Loss: 0.2904  Acc: 87.50%\n",
      "Epoch 1 [451/938]  Loss: 0.4114  Acc: 85.94%\n",
      "Epoch 1 [452/938]  Loss: 0.3866  Acc: 92.19%\n",
      "Epoch 1 [453/938]  Loss: 0.3647  Acc: 89.06%\n",
      "Epoch 1 [454/938]  Loss: 0.3581  Acc: 90.62%\n",
      "Epoch 1 [455/938]  Loss: 0.2127  Acc: 95.31%\n",
      "Epoch 1 [456/938]  Loss: 0.2456  Acc: 95.31%\n",
      "Epoch 1 [457/938]  Loss: 0.3265  Acc: 92.19%\n",
      "Epoch 1 [458/938]  Loss: 0.4753  Acc: 84.38%\n",
      "Epoch 1 [459/938]  Loss: 0.2584  Acc: 89.06%\n",
      "Epoch 1 [460/938]  Loss: 0.4117  Acc: 85.94%\n",
      "Epoch 1 [461/938]  Loss: 0.2946  Acc: 90.62%\n",
      "Epoch 1 [462/938]  Loss: 0.3284  Acc: 93.75%\n",
      "Epoch 1 [463/938]  Loss: 0.2673  Acc: 90.62%\n",
      "Epoch 1 [464/938]  Loss: 0.2087  Acc: 95.31%\n",
      "Epoch 1 [465/938]  Loss: 0.3734  Acc: 89.06%\n",
      "Epoch 1 [466/938]  Loss: 0.3925  Acc: 90.62%\n",
      "Epoch 1 [467/938]  Loss: 0.3260  Acc: 87.50%\n",
      "Epoch 1 [468/938]  Loss: 0.2347  Acc: 93.75%\n",
      "Epoch 1 [469/938]  Loss: 0.3095  Acc: 92.19%\n",
      "Epoch 1 [470/938]  Loss: 0.2891  Acc: 95.31%\n",
      "Epoch 1 [471/938]  Loss: 0.3437  Acc: 90.62%\n",
      "Epoch 1 [472/938]  Loss: 0.2988  Acc: 93.75%\n",
      "Epoch 1 [473/938]  Loss: 0.4091  Acc: 87.50%\n",
      "Epoch 1 [474/938]  Loss: 0.3176  Acc: 87.50%\n",
      "Epoch 1 [417/938]  Loss: 0.2016  Acc: 96.88%\n",
      "Epoch 1 [418/938]  Loss: 0.3761  Acc: 87.50%\n",
      "Epoch 1 [419/938]  Loss: 0.5328  Acc: 87.50%\n",
      "Epoch 1 [420/938]  Loss: 0.3020  Acc: 93.75%\n",
      "Epoch 1 [421/938]  Loss: 0.2311  Acc: 95.31%\n",
      "Epoch 1 [422/938]  Loss: 0.2980  Acc: 89.06%\n",
      "Epoch 1 [423/938]  Loss: 0.1627  Acc: 96.88%\n",
      "Epoch 1 [424/938]  Loss: 0.4396  Acc: 82.81%\n",
      "Epoch 1 [425/938]  Loss: 0.4273  Acc: 87.50%\n",
      "Epoch 1 [426/938]  Loss: 0.3101  Acc: 90.62%\n",
      "Epoch 1 [427/938]  Loss: 0.3440  Acc: 92.19%\n",
      "Epoch 1 [428/938]  Loss: 0.3909  Acc: 85.94%\n",
      "Epoch 1 [429/938]  Loss: 0.3234  Acc: 85.94%\n",
      "Epoch 1 [430/938]  Loss: 0.4285  Acc: 89.06%\n",
      "Epoch 1 [431/938]  Loss: 0.3375  Acc: 93.75%\n",
      "Epoch 1 [432/938]  Loss: 0.3228  Acc: 92.19%\n",
      "Epoch 1 [433/938]  Loss: 0.2463  Acc: 90.62%\n",
      "Epoch 1 [434/938]  Loss: 0.2730  Acc: 90.62%\n",
      "Epoch 1 [435/938]  Loss: 0.5277  Acc: 81.25%\n",
      "Epoch 1 [436/938]  Loss: 0.3792  Acc: 85.94%\n",
      "Epoch 1 [437/938]  Loss: 0.2123  Acc: 92.19%\n",
      "Epoch 1 [438/938]  Loss: 0.4046  Acc: 87.50%\n",
      "Epoch 1 [439/938]  Loss: 0.2362  Acc: 92.19%\n",
      "Epoch 1 [440/938]  Loss: 0.3277  Acc: 89.06%\n",
      "Epoch 1 [441/938]  Loss: 0.4108  Acc: 87.50%\n",
      "Epoch 1 [442/938]  Loss: 0.3088  Acc: 90.62%\n",
      "Epoch 1 [443/938]  Loss: 0.2482  Acc: 89.06%\n",
      "Epoch 1 [444/938]  Loss: 0.2812  Acc: 93.75%\n",
      "Epoch 1 [445/938]  Loss: 0.1462  Acc: 96.88%\n",
      "Epoch 1 [446/938]  Loss: 0.4278  Acc: 89.06%\n",
      "Epoch 1 [447/938]  Loss: 0.4154  Acc: 87.50%\n",
      "Epoch 1 [448/938]  Loss: 0.3061  Acc: 93.75%\n",
      "Epoch 1 [449/938]  Loss: 0.2147  Acc: 95.31%\n",
      "Epoch 1 [450/938]  Loss: 0.2904  Acc: 87.50%\n",
      "Epoch 1 [451/938]  Loss: 0.4114  Acc: 85.94%\n",
      "Epoch 1 [452/938]  Loss: 0.3866  Acc: 92.19%\n",
      "Epoch 1 [453/938]  Loss: 0.3647  Acc: 89.06%\n",
      "Epoch 1 [454/938]  Loss: 0.3581  Acc: 90.62%\n",
      "Epoch 1 [455/938]  Loss: 0.2127  Acc: 95.31%\n",
      "Epoch 1 [456/938]  Loss: 0.2456  Acc: 95.31%\n",
      "Epoch 1 [457/938]  Loss: 0.3265  Acc: 92.19%\n",
      "Epoch 1 [458/938]  Loss: 0.4753  Acc: 84.38%\n",
      "Epoch 1 [459/938]  Loss: 0.2584  Acc: 89.06%\n",
      "Epoch 1 [460/938]  Loss: 0.4117  Acc: 85.94%\n",
      "Epoch 1 [461/938]  Loss: 0.2946  Acc: 90.62%\n",
      "Epoch 1 [462/938]  Loss: 0.3284  Acc: 93.75%\n",
      "Epoch 1 [463/938]  Loss: 0.2673  Acc: 90.62%\n",
      "Epoch 1 [464/938]  Loss: 0.2087  Acc: 95.31%\n",
      "Epoch 1 [465/938]  Loss: 0.3734  Acc: 89.06%\n",
      "Epoch 1 [466/938]  Loss: 0.3925  Acc: 90.62%\n",
      "Epoch 1 [467/938]  Loss: 0.3260  Acc: 87.50%\n",
      "Epoch 1 [468/938]  Loss: 0.2347  Acc: 93.75%\n",
      "Epoch 1 [469/938]  Loss: 0.3095  Acc: 92.19%\n",
      "Epoch 1 [470/938]  Loss: 0.2891  Acc: 95.31%\n",
      "Epoch 1 [471/938]  Loss: 0.3437  Acc: 90.62%\n",
      "Epoch 1 [472/938]  Loss: 0.2988  Acc: 93.75%\n",
      "Epoch 1 [473/938]  Loss: 0.4091  Acc: 87.50%\n",
      "Epoch 1 [474/938]  Loss: 0.3176  Acc: 87.50%\n",
      "Epoch 1 [475/938]  Loss: 0.2285  Acc: 93.75%\n",
      "Epoch 1 [476/938]  Loss: 0.2798  Acc: 90.62%\n",
      "Epoch 1 [477/938]  Loss: 0.1187  Acc: 96.88%\n",
      "Epoch 1 [478/938]  Loss: 0.1505  Acc: 98.44%\n",
      "Epoch 1 [479/938]  Loss: 0.4878  Acc: 84.38%\n",
      "Epoch 1 [480/938]  Loss: 0.2419  Acc: 92.19%\n",
      "Epoch 1 [481/938]  Loss: 0.3948  Acc: 89.06%\n",
      "Epoch 1 [482/938]  Loss: 0.5079  Acc: 87.50%\n",
      "Epoch 1 [483/938]  Loss: 0.2290  Acc: 89.06%\n",
      "Epoch 1 [484/938]  Loss: 0.4312  Acc: 84.38%\n",
      "Epoch 1 [485/938]  Loss: 0.2918  Acc: 92.19%\n",
      "Epoch 1 [486/938]  Loss: 0.2343  Acc: 92.19%\n",
      "Epoch 1 [487/938]  Loss: 0.3179  Acc: 92.19%\n",
      "Epoch 1 [488/938]  Loss: 0.2840  Acc: 92.19%\n",
      "Epoch 1 [489/938]  Loss: 0.3786  Acc: 89.06%\n",
      "Epoch 1 [490/938]  Loss: 0.1917  Acc: 93.75%\n",
      "Epoch 1 [491/938]  Loss: 0.2353  Acc: 93.75%\n",
      "Epoch 1 [492/938]  Loss: 0.3205  Acc: 92.19%\n",
      "Epoch 1 [493/938]  Loss: 0.1855  Acc: 95.31%\n",
      "Epoch 1 [494/938]  Loss: 0.2884  Acc: 93.75%\n",
      "Epoch 1 [495/938]  Loss: 0.2912  Acc: 90.62%\n",
      "Epoch 1 [496/938]  Loss: 0.1894  Acc: 96.88%\n",
      "Epoch 1 [497/938]  Loss: 0.3355  Acc: 92.19%\n",
      "Epoch 1 [498/938]  Loss: 0.3244  Acc: 92.19%\n",
      "Epoch 1 [499/938]  Loss: 0.1949  Acc: 92.19%\n",
      "Epoch 1 [500/938]  Loss: 0.3851  Acc: 85.94%\n",
      "Epoch 1 [501/938]  Loss: 0.2846  Acc: 92.19%\n",
      "Epoch 1 [502/938]  Loss: 0.2885  Acc: 93.75%\n",
      "Epoch 1 [503/938]  Loss: 0.4268  Acc: 89.06%\n",
      "Epoch 1 [504/938]  Loss: 0.2345  Acc: 95.31%\n",
      "Epoch 1 [505/938]  Loss: 0.4506  Acc: 87.50%\n",
      "Epoch 1 [506/938]  Loss: 0.2700  Acc: 90.62%\n",
      "Epoch 1 [507/938]  Loss: 0.2051  Acc: 93.75%\n",
      "Epoch 1 [508/938]  Loss: 0.3216  Acc: 89.06%\n",
      "Epoch 1 [509/938]  Loss: 0.1639  Acc: 93.75%\n",
      "Epoch 1 [510/938]  Loss: 0.3396  Acc: 87.50%\n",
      "Epoch 1 [511/938]  Loss: 0.3308  Acc: 90.62%\n",
      "Epoch 1 [512/938]  Loss: 0.2236  Acc: 96.88%\n",
      "Epoch 1 [513/938]  Loss: 0.2849  Acc: 89.06%\n",
      "Epoch 1 [514/938]  Loss: 0.2408  Acc: 93.75%\n",
      "Epoch 1 [515/938]  Loss: 0.2975  Acc: 90.62%\n",
      "Epoch 1 [516/938]  Loss: 0.2765  Acc: 92.19%\n",
      "Epoch 1 [517/938]  Loss: 0.2742  Acc: 90.62%\n",
      "Epoch 1 [518/938]  Loss: 0.3117  Acc: 90.62%\n",
      "Epoch 1 [519/938]  Loss: 0.1982  Acc: 95.31%\n",
      "Epoch 1 [520/938]  Loss: 0.1326  Acc: 96.88%\n",
      "Epoch 1 [521/938]  Loss: 0.4865  Acc: 85.94%\n",
      "Epoch 1 [522/938]  Loss: 0.2519  Acc: 90.62%\n",
      "Epoch 1 [523/938]  Loss: 0.2710  Acc: 92.19%\n",
      "Epoch 1 [524/938]  Loss: 0.3144  Acc: 87.50%\n",
      "Epoch 1 [525/938]  Loss: 0.2812  Acc: 90.62%\n",
      "Epoch 1 [526/938]  Loss: 0.2387  Acc: 93.75%\n",
      "Epoch 1 [527/938]  Loss: 0.3103  Acc: 93.75%\n",
      "Epoch 1 [528/938]  Loss: 0.3532  Acc: 92.19%\n",
      "Epoch 1 [529/938]  Loss: 0.3928  Acc: 85.94%\n",
      "Epoch 1 [475/938]  Loss: 0.2285  Acc: 93.75%\n",
      "Epoch 1 [476/938]  Loss: 0.2798  Acc: 90.62%\n",
      "Epoch 1 [477/938]  Loss: 0.1187  Acc: 96.88%\n",
      "Epoch 1 [478/938]  Loss: 0.1505  Acc: 98.44%\n",
      "Epoch 1 [479/938]  Loss: 0.4878  Acc: 84.38%\n",
      "Epoch 1 [480/938]  Loss: 0.2419  Acc: 92.19%\n",
      "Epoch 1 [481/938]  Loss: 0.3948  Acc: 89.06%\n",
      "Epoch 1 [482/938]  Loss: 0.5079  Acc: 87.50%\n",
      "Epoch 1 [483/938]  Loss: 0.2290  Acc: 89.06%\n",
      "Epoch 1 [484/938]  Loss: 0.4312  Acc: 84.38%\n",
      "Epoch 1 [485/938]  Loss: 0.2918  Acc: 92.19%\n",
      "Epoch 1 [486/938]  Loss: 0.2343  Acc: 92.19%\n",
      "Epoch 1 [487/938]  Loss: 0.3179  Acc: 92.19%\n",
      "Epoch 1 [488/938]  Loss: 0.2840  Acc: 92.19%\n",
      "Epoch 1 [489/938]  Loss: 0.3786  Acc: 89.06%\n",
      "Epoch 1 [490/938]  Loss: 0.1917  Acc: 93.75%\n",
      "Epoch 1 [491/938]  Loss: 0.2353  Acc: 93.75%\n",
      "Epoch 1 [492/938]  Loss: 0.3205  Acc: 92.19%\n",
      "Epoch 1 [493/938]  Loss: 0.1855  Acc: 95.31%\n",
      "Epoch 1 [494/938]  Loss: 0.2884  Acc: 93.75%\n",
      "Epoch 1 [495/938]  Loss: 0.2912  Acc: 90.62%\n",
      "Epoch 1 [496/938]  Loss: 0.1894  Acc: 96.88%\n",
      "Epoch 1 [497/938]  Loss: 0.3355  Acc: 92.19%\n",
      "Epoch 1 [498/938]  Loss: 0.3244  Acc: 92.19%\n",
      "Epoch 1 [499/938]  Loss: 0.1949  Acc: 92.19%\n",
      "Epoch 1 [500/938]  Loss: 0.3851  Acc: 85.94%\n",
      "Epoch 1 [501/938]  Loss: 0.2846  Acc: 92.19%\n",
      "Epoch 1 [502/938]  Loss: 0.2885  Acc: 93.75%\n",
      "Epoch 1 [503/938]  Loss: 0.4268  Acc: 89.06%\n",
      "Epoch 1 [504/938]  Loss: 0.2345  Acc: 95.31%\n",
      "Epoch 1 [505/938]  Loss: 0.4506  Acc: 87.50%\n",
      "Epoch 1 [506/938]  Loss: 0.2700  Acc: 90.62%\n",
      "Epoch 1 [507/938]  Loss: 0.2051  Acc: 93.75%\n",
      "Epoch 1 [508/938]  Loss: 0.3216  Acc: 89.06%\n",
      "Epoch 1 [509/938]  Loss: 0.1639  Acc: 93.75%\n",
      "Epoch 1 [510/938]  Loss: 0.3396  Acc: 87.50%\n",
      "Epoch 1 [511/938]  Loss: 0.3308  Acc: 90.62%\n",
      "Epoch 1 [512/938]  Loss: 0.2236  Acc: 96.88%\n",
      "Epoch 1 [513/938]  Loss: 0.2849  Acc: 89.06%\n",
      "Epoch 1 [514/938]  Loss: 0.2408  Acc: 93.75%\n",
      "Epoch 1 [515/938]  Loss: 0.2975  Acc: 90.62%\n",
      "Epoch 1 [516/938]  Loss: 0.2765  Acc: 92.19%\n",
      "Epoch 1 [517/938]  Loss: 0.2742  Acc: 90.62%\n",
      "Epoch 1 [518/938]  Loss: 0.3117  Acc: 90.62%\n",
      "Epoch 1 [519/938]  Loss: 0.1982  Acc: 95.31%\n",
      "Epoch 1 [520/938]  Loss: 0.1326  Acc: 96.88%\n",
      "Epoch 1 [521/938]  Loss: 0.4865  Acc: 85.94%\n",
      "Epoch 1 [522/938]  Loss: 0.2519  Acc: 90.62%\n",
      "Epoch 1 [523/938]  Loss: 0.2710  Acc: 92.19%\n",
      "Epoch 1 [524/938]  Loss: 0.3144  Acc: 87.50%\n",
      "Epoch 1 [525/938]  Loss: 0.2812  Acc: 90.62%\n",
      "Epoch 1 [526/938]  Loss: 0.2387  Acc: 93.75%\n",
      "Epoch 1 [527/938]  Loss: 0.3103  Acc: 93.75%\n",
      "Epoch 1 [528/938]  Loss: 0.3532  Acc: 92.19%\n",
      "Epoch 1 [529/938]  Loss: 0.3928  Acc: 85.94%\n",
      "Epoch 1 [530/938]  Loss: 0.1853  Acc: 95.31%\n",
      "Epoch 1 [531/938]  Loss: 0.3085  Acc: 89.06%\n",
      "Epoch 1 [532/938]  Loss: 0.3696  Acc: 89.06%\n",
      "Epoch 1 [533/938]  Loss: 0.3344  Acc: 89.06%\n",
      "Epoch 1 [534/938]  Loss: 0.1300  Acc: 95.31%\n",
      "Epoch 1 [535/938]  Loss: 0.2179  Acc: 93.75%\n",
      "Epoch 1 [536/938]  Loss: 0.3643  Acc: 89.06%\n",
      "Epoch 1 [537/938]  Loss: 0.2551  Acc: 93.75%\n",
      "Epoch 1 [538/938]  Loss: 0.3540  Acc: 89.06%\n",
      "Epoch 1 [539/938]  Loss: 0.1428  Acc: 95.31%\n",
      "Epoch 1 [540/938]  Loss: 0.1383  Acc: 98.44%\n",
      "Epoch 1 [541/938]  Loss: 0.2186  Acc: 96.88%\n",
      "Epoch 1 [542/938]  Loss: 0.1973  Acc: 93.75%\n",
      "Epoch 1 [543/938]  Loss: 0.3740  Acc: 85.94%\n",
      "Epoch 1 [544/938]  Loss: 0.2794  Acc: 92.19%\n",
      "Epoch 1 [545/938]  Loss: 0.2768  Acc: 92.19%\n",
      "Epoch 1 [546/938]  Loss: 0.1797  Acc: 96.88%\n",
      "Epoch 1 [547/938]  Loss: 0.3350  Acc: 90.62%\n",
      "Epoch 1 [548/938]  Loss: 0.2346  Acc: 93.75%\n",
      "Epoch 1 [549/938]  Loss: 0.1675  Acc: 96.88%\n",
      "Epoch 1 [550/938]  Loss: 0.1522  Acc: 95.31%\n",
      "Epoch 1 [551/938]  Loss: 0.3256  Acc: 89.06%\n",
      "Epoch 1 [552/938]  Loss: 0.2868  Acc: 89.06%\n",
      "Epoch 1 [553/938]  Loss: 0.1661  Acc: 95.31%\n",
      "Epoch 1 [554/938]  Loss: 0.3200  Acc: 90.62%\n",
      "Epoch 1 [555/938]  Loss: 0.2843  Acc: 89.06%\n",
      "Epoch 1 [556/938]  Loss: 0.1491  Acc: 95.31%\n",
      "Epoch 1 [557/938]  Loss: 0.1835  Acc: 93.75%\n",
      "Epoch 1 [558/938]  Loss: 0.2433  Acc: 93.75%\n",
      "Epoch 1 [559/938]  Loss: 0.2187  Acc: 95.31%\n",
      "Epoch 1 [560/938]  Loss: 0.3341  Acc: 92.19%\n",
      "Epoch 1 [561/938]  Loss: 0.2671  Acc: 90.62%\n",
      "Epoch 1 [562/938]  Loss: 0.2455  Acc: 90.62%\n",
      "Epoch 1 [563/938]  Loss: 0.4939  Acc: 89.06%\n",
      "Epoch 1 [564/938]  Loss: 0.3133  Acc: 90.62%\n",
      "Epoch 1 [565/938]  Loss: 0.1316  Acc: 96.88%\n",
      "Epoch 1 [566/938]  Loss: 0.3593  Acc: 90.62%\n",
      "Epoch 1 [567/938]  Loss: 0.2316  Acc: 93.75%\n",
      "Epoch 1 [568/938]  Loss: 0.3053  Acc: 87.50%\n",
      "Epoch 1 [569/938]  Loss: 0.1876  Acc: 93.75%\n",
      "Epoch 1 [570/938]  Loss: 0.1774  Acc: 95.31%\n",
      "Epoch 1 [571/938]  Loss: 0.2671  Acc: 95.31%\n",
      "Epoch 1 [572/938]  Loss: 0.1696  Acc: 95.31%\n",
      "Epoch 1 [573/938]  Loss: 0.1828  Acc: 96.88%\n",
      "Epoch 1 [574/938]  Loss: 0.3123  Acc: 92.19%\n",
      "Epoch 1 [575/938]  Loss: 0.1938  Acc: 95.31%\n",
      "Epoch 1 [576/938]  Loss: 0.1790  Acc: 93.75%\n",
      "Epoch 1 [577/938]  Loss: 0.1885  Acc: 95.31%\n",
      "Epoch 1 [578/938]  Loss: 0.3657  Acc: 89.06%\n",
      "Epoch 1 [579/938]  Loss: 0.2713  Acc: 90.62%\n",
      "Epoch 1 [580/938]  Loss: 0.3025  Acc: 90.62%\n",
      "Epoch 1 [581/938]  Loss: 0.2326  Acc: 93.75%\n",
      "Epoch 1 [582/938]  Loss: 0.3493  Acc: 85.94%\n",
      "Epoch 1 [583/938]  Loss: 0.1648  Acc: 93.75%\n",
      "Epoch 1 [584/938]  Loss: 0.1539  Acc: 96.88%\n",
      "Epoch 1 [585/938]  Loss: 0.3194  Acc: 85.94%\n",
      "Epoch 1 [530/938]  Loss: 0.1853  Acc: 95.31%\n",
      "Epoch 1 [531/938]  Loss: 0.3085  Acc: 89.06%\n",
      "Epoch 1 [532/938]  Loss: 0.3696  Acc: 89.06%\n",
      "Epoch 1 [533/938]  Loss: 0.3344  Acc: 89.06%\n",
      "Epoch 1 [534/938]  Loss: 0.1300  Acc: 95.31%\n",
      "Epoch 1 [535/938]  Loss: 0.2179  Acc: 93.75%\n",
      "Epoch 1 [536/938]  Loss: 0.3643  Acc: 89.06%\n",
      "Epoch 1 [537/938]  Loss: 0.2551  Acc: 93.75%\n",
      "Epoch 1 [538/938]  Loss: 0.3540  Acc: 89.06%\n",
      "Epoch 1 [539/938]  Loss: 0.1428  Acc: 95.31%\n",
      "Epoch 1 [540/938]  Loss: 0.1383  Acc: 98.44%\n",
      "Epoch 1 [541/938]  Loss: 0.2186  Acc: 96.88%\n",
      "Epoch 1 [542/938]  Loss: 0.1973  Acc: 93.75%\n",
      "Epoch 1 [543/938]  Loss: 0.3740  Acc: 85.94%\n",
      "Epoch 1 [544/938]  Loss: 0.2794  Acc: 92.19%\n",
      "Epoch 1 [545/938]  Loss: 0.2768  Acc: 92.19%\n",
      "Epoch 1 [546/938]  Loss: 0.1797  Acc: 96.88%\n",
      "Epoch 1 [547/938]  Loss: 0.3350  Acc: 90.62%\n",
      "Epoch 1 [548/938]  Loss: 0.2346  Acc: 93.75%\n",
      "Epoch 1 [549/938]  Loss: 0.1675  Acc: 96.88%\n",
      "Epoch 1 [550/938]  Loss: 0.1522  Acc: 95.31%\n",
      "Epoch 1 [551/938]  Loss: 0.3256  Acc: 89.06%\n",
      "Epoch 1 [552/938]  Loss: 0.2868  Acc: 89.06%\n",
      "Epoch 1 [553/938]  Loss: 0.1661  Acc: 95.31%\n",
      "Epoch 1 [554/938]  Loss: 0.3200  Acc: 90.62%\n",
      "Epoch 1 [555/938]  Loss: 0.2843  Acc: 89.06%\n",
      "Epoch 1 [556/938]  Loss: 0.1491  Acc: 95.31%\n",
      "Epoch 1 [557/938]  Loss: 0.1835  Acc: 93.75%\n",
      "Epoch 1 [558/938]  Loss: 0.2433  Acc: 93.75%\n",
      "Epoch 1 [559/938]  Loss: 0.2187  Acc: 95.31%\n",
      "Epoch 1 [560/938]  Loss: 0.3341  Acc: 92.19%\n",
      "Epoch 1 [561/938]  Loss: 0.2671  Acc: 90.62%\n",
      "Epoch 1 [562/938]  Loss: 0.2455  Acc: 90.62%\n",
      "Epoch 1 [563/938]  Loss: 0.4939  Acc: 89.06%\n",
      "Epoch 1 [564/938]  Loss: 0.3133  Acc: 90.62%\n",
      "Epoch 1 [565/938]  Loss: 0.1316  Acc: 96.88%\n",
      "Epoch 1 [566/938]  Loss: 0.3593  Acc: 90.62%\n",
      "Epoch 1 [567/938]  Loss: 0.2316  Acc: 93.75%\n",
      "Epoch 1 [568/938]  Loss: 0.3053  Acc: 87.50%\n",
      "Epoch 1 [569/938]  Loss: 0.1876  Acc: 93.75%\n",
      "Epoch 1 [570/938]  Loss: 0.1774  Acc: 95.31%\n",
      "Epoch 1 [571/938]  Loss: 0.2671  Acc: 95.31%\n",
      "Epoch 1 [572/938]  Loss: 0.1696  Acc: 95.31%\n",
      "Epoch 1 [573/938]  Loss: 0.1828  Acc: 96.88%\n",
      "Epoch 1 [574/938]  Loss: 0.3123  Acc: 92.19%\n",
      "Epoch 1 [575/938]  Loss: 0.1938  Acc: 95.31%\n",
      "Epoch 1 [576/938]  Loss: 0.1790  Acc: 93.75%\n",
      "Epoch 1 [577/938]  Loss: 0.1885  Acc: 95.31%\n",
      "Epoch 1 [578/938]  Loss: 0.3657  Acc: 89.06%\n",
      "Epoch 1 [579/938]  Loss: 0.2713  Acc: 90.62%\n",
      "Epoch 1 [580/938]  Loss: 0.3025  Acc: 90.62%\n",
      "Epoch 1 [581/938]  Loss: 0.2326  Acc: 93.75%\n",
      "Epoch 1 [582/938]  Loss: 0.3493  Acc: 85.94%\n",
      "Epoch 1 [583/938]  Loss: 0.1648  Acc: 93.75%\n",
      "Epoch 1 [584/938]  Loss: 0.1539  Acc: 96.88%\n",
      "Epoch 1 [585/938]  Loss: 0.3194  Acc: 85.94%\n",
      "Epoch 1 [586/938]  Loss: 0.2699  Acc: 93.75%\n",
      "Epoch 1 [587/938]  Loss: 0.2430  Acc: 93.75%\n",
      "Epoch 1 [588/938]  Loss: 0.1508  Acc: 93.75%\n",
      "Epoch 1 [589/938]  Loss: 0.1804  Acc: 95.31%\n",
      "Epoch 1 [590/938]  Loss: 0.2906  Acc: 92.19%\n",
      "Epoch 1 [591/938]  Loss: 0.2706  Acc: 89.06%\n",
      "Epoch 1 [592/938]  Loss: 0.1112  Acc: 96.88%\n",
      "Epoch 1 [593/938]  Loss: 0.2797  Acc: 93.75%\n",
      "Epoch 1 [594/938]  Loss: 0.1620  Acc: 96.88%\n",
      "Epoch 1 [595/938]  Loss: 0.2387  Acc: 89.06%\n",
      "Epoch 1 [596/938]  Loss: 0.4381  Acc: 87.50%\n",
      "Epoch 1 [597/938]  Loss: 0.1567  Acc: 95.31%\n",
      "Epoch 1 [598/938]  Loss: 0.2842  Acc: 87.50%\n",
      "Epoch 1 [599/938]  Loss: 0.1791  Acc: 96.88%\n",
      "Epoch 1 [600/938]  Loss: 0.1397  Acc: 98.44%\n",
      "Epoch 1 [601/938]  Loss: 0.3704  Acc: 92.19%\n",
      "Epoch 1 [602/938]  Loss: 0.2718  Acc: 93.75%\n",
      "Epoch 1 [603/938]  Loss: 0.2379  Acc: 90.62%\n",
      "Epoch 1 [604/938]  Loss: 0.1724  Acc: 95.31%\n",
      "Epoch 1 [605/938]  Loss: 0.1850  Acc: 96.88%\n",
      "Epoch 1 [606/938]  Loss: 0.1646  Acc: 98.44%\n",
      "Epoch 1 [607/938]  Loss: 0.1739  Acc: 93.75%\n",
      "Epoch 1 [608/938]  Loss: 0.1693  Acc: 93.75%\n",
      "Epoch 1 [609/938]  Loss: 0.2503  Acc: 92.19%\n",
      "Epoch 1 [610/938]  Loss: 0.2029  Acc: 92.19%\n",
      "Epoch 1 [611/938]  Loss: 0.1644  Acc: 96.88%\n",
      "Epoch 1 [612/938]  Loss: 0.1581  Acc: 95.31%\n",
      "Epoch 1 [613/938]  Loss: 0.1875  Acc: 92.19%\n",
      "Epoch 1 [614/938]  Loss: 0.1792  Acc: 93.75%\n",
      "Epoch 1 [615/938]  Loss: 0.3771  Acc: 92.19%\n",
      "Epoch 1 [616/938]  Loss: 0.1023  Acc: 95.31%\n",
      "Epoch 1 [617/938]  Loss: 0.3068  Acc: 90.62%\n",
      "Epoch 1 [618/938]  Loss: 0.2224  Acc: 93.75%\n",
      "Epoch 1 [619/938]  Loss: 0.3881  Acc: 87.50%\n",
      "Epoch 1 [620/938]  Loss: 0.1615  Acc: 92.19%\n",
      "Epoch 1 [621/938]  Loss: 0.2224  Acc: 96.88%\n",
      "Epoch 1 [622/938]  Loss: 0.2146  Acc: 96.88%\n",
      "Epoch 1 [586/938]  Loss: 0.2699  Acc: 93.75%\n",
      "Epoch 1 [587/938]  Loss: 0.2430  Acc: 93.75%\n",
      "Epoch 1 [588/938]  Loss: 0.1508  Acc: 93.75%\n",
      "Epoch 1 [589/938]  Loss: 0.1804  Acc: 95.31%\n",
      "Epoch 1 [590/938]  Loss: 0.2906  Acc: 92.19%\n",
      "Epoch 1 [591/938]  Loss: 0.2706  Acc: 89.06%\n",
      "Epoch 1 [592/938]  Loss: 0.1112  Acc: 96.88%\n",
      "Epoch 1 [593/938]  Loss: 0.2797  Acc: 93.75%\n",
      "Epoch 1 [594/938]  Loss: 0.1620  Acc: 96.88%\n",
      "Epoch 1 [595/938]  Loss: 0.2387  Acc: 89.06%\n",
      "Epoch 1 [596/938]  Loss: 0.4381  Acc: 87.50%\n",
      "Epoch 1 [597/938]  Loss: 0.1567  Acc: 95.31%\n",
      "Epoch 1 [598/938]  Loss: 0.2842  Acc: 87.50%\n",
      "Epoch 1 [599/938]  Loss: 0.1791  Acc: 96.88%\n",
      "Epoch 1 [600/938]  Loss: 0.1397  Acc: 98.44%\n",
      "Epoch 1 [601/938]  Loss: 0.3704  Acc: 92.19%\n",
      "Epoch 1 [602/938]  Loss: 0.2718  Acc: 93.75%\n",
      "Epoch 1 [603/938]  Loss: 0.2379  Acc: 90.62%\n",
      "Epoch 1 [604/938]  Loss: 0.1724  Acc: 95.31%\n",
      "Epoch 1 [605/938]  Loss: 0.1850  Acc: 96.88%\n",
      "Epoch 1 [606/938]  Loss: 0.1646  Acc: 98.44%\n",
      "Epoch 1 [607/938]  Loss: 0.1739  Acc: 93.75%\n",
      "Epoch 1 [608/938]  Loss: 0.1693  Acc: 93.75%\n",
      "Epoch 1 [609/938]  Loss: 0.2503  Acc: 92.19%\n",
      "Epoch 1 [610/938]  Loss: 0.2029  Acc: 92.19%\n",
      "Epoch 1 [611/938]  Loss: 0.1644  Acc: 96.88%\n",
      "Epoch 1 [612/938]  Loss: 0.1581  Acc: 95.31%\n",
      "Epoch 1 [613/938]  Loss: 0.1875  Acc: 92.19%\n",
      "Epoch 1 [614/938]  Loss: 0.1792  Acc: 93.75%\n",
      "Epoch 1 [615/938]  Loss: 0.3771  Acc: 92.19%\n",
      "Epoch 1 [616/938]  Loss: 0.1023  Acc: 95.31%\n",
      "Epoch 1 [617/938]  Loss: 0.3068  Acc: 90.62%\n",
      "Epoch 1 [618/938]  Loss: 0.2224  Acc: 93.75%\n",
      "Epoch 1 [619/938]  Loss: 0.3881  Acc: 87.50%\n",
      "Epoch 1 [620/938]  Loss: 0.1615  Acc: 92.19%\n",
      "Epoch 1 [621/938]  Loss: 0.2224  Acc: 96.88%\n",
      "Epoch 1 [622/938]  Loss: 0.2146  Acc: 96.88%\n",
      "Epoch 1 [623/938]  Loss: 0.1654  Acc: 95.31%\n",
      "Epoch 1 [624/938]  Loss: 0.1949  Acc: 95.31%\n",
      "Epoch 1 [625/938]  Loss: 0.1493  Acc: 93.75%\n",
      "Epoch 1 [626/938]  Loss: 0.2528  Acc: 89.06%\n",
      "Epoch 1 [627/938]  Loss: 0.1611  Acc: 93.75%\n",
      "Epoch 1 [628/938]  Loss: 0.1795  Acc: 95.31%\n",
      "Epoch 1 [629/938]  Loss: 0.3953  Acc: 87.50%\n",
      "Epoch 1 [630/938]  Loss: 0.1205  Acc: 98.44%\n",
      "Epoch 1 [631/938]  Loss: 0.1177  Acc: 98.44%\n",
      "Epoch 1 [632/938]  Loss: 0.2789  Acc: 89.06%\n",
      "Epoch 1 [633/938]  Loss: 0.2194  Acc: 95.31%\n",
      "Epoch 1 [634/938]  Loss: 0.2016  Acc: 92.19%\n",
      "Epoch 1 [635/938]  Loss: 0.2821  Acc: 92.19%\n",
      "Epoch 1 [636/938]  Loss: 0.3383  Acc: 90.62%\n",
      "Epoch 1 [637/938]  Loss: 0.2983  Acc: 90.62%\n",
      "Epoch 1 [638/938]  Loss: 0.2054  Acc: 93.75%\n",
      "Epoch 1 [639/938]  Loss: 0.1711  Acc: 95.31%\n",
      "Epoch 1 [640/938]  Loss: 0.3781  Acc: 90.62%\n",
      "Epoch 1 [641/938]  Loss: 0.1128  Acc: 96.88%\n",
      "Epoch 1 [642/938]  Loss: 0.2963  Acc: 89.06%\n",
      "Epoch 1 [643/938]  Loss: 0.3223  Acc: 89.06%\n",
      "Epoch 1 [644/938]  Loss: 0.3093  Acc: 95.31%\n",
      "Epoch 1 [645/938]  Loss: 0.1861  Acc: 96.88%\n",
      "Epoch 1 [646/938]  Loss: 0.0930  Acc: 98.44%\n",
      "Epoch 1 [647/938]  Loss: 0.1322  Acc: 96.88%\n",
      "Epoch 1 [648/938]  Loss: 0.2353  Acc: 90.62%\n",
      "Epoch 1 [649/938]  Loss: 0.2075  Acc: 92.19%\n",
      "Epoch 1 [650/938]  Loss: 0.2480  Acc: 90.62%\n",
      "Epoch 1 [651/938]  Loss: 0.1562  Acc: 95.31%\n",
      "Epoch 1 [652/938]  Loss: 0.1834  Acc: 95.31%\n",
      "Epoch 1 [653/938]  Loss: 0.1914  Acc: 96.88%\n",
      "Epoch 1 [654/938]  Loss: 0.3337  Acc: 95.31%\n",
      "Epoch 1 [655/938]  Loss: 0.1943  Acc: 93.75%\n",
      "Epoch 1 [656/938]  Loss: 0.1712  Acc: 93.75%\n",
      "Epoch 1 [657/938]  Loss: 0.2365  Acc: 93.75%\n",
      "Epoch 1 [658/938]  Loss: 0.1948  Acc: 90.62%\n",
      "Epoch 1 [659/938]  Loss: 0.2170  Acc: 93.75%\n",
      "Epoch 1 [660/938]  Loss: 0.2231  Acc: 92.19%\n",
      "Epoch 1 [661/938]  Loss: 0.1719  Acc: 95.31%\n",
      "Epoch 1 [662/938]  Loss: 0.1685  Acc: 95.31%\n",
      "Epoch 1 [663/938]  Loss: 0.2129  Acc: 93.75%\n",
      "Epoch 1 [664/938]  Loss: 0.3695  Acc: 92.19%\n",
      "Epoch 1 [665/938]  Loss: 0.2416  Acc: 93.75%\n",
      "Epoch 1 [666/938]  Loss: 0.2918  Acc: 92.19%\n",
      "Epoch 1 [667/938]  Loss: 0.2997  Acc: 90.62%\n",
      "Epoch 1 [668/938]  Loss: 0.2016  Acc: 92.19%\n",
      "Epoch 1 [669/938]  Loss: 0.1957  Acc: 93.75%\n",
      "Epoch 1 [670/938]  Loss: 0.1247  Acc: 96.88%\n",
      "Epoch 1 [671/938]  Loss: 0.3123  Acc: 90.62%\n",
      "Epoch 1 [672/938]  Loss: 0.1687  Acc: 95.31%\n",
      "Epoch 1 [623/938]  Loss: 0.1654  Acc: 95.31%\n",
      "Epoch 1 [624/938]  Loss: 0.1949  Acc: 95.31%\n",
      "Epoch 1 [625/938]  Loss: 0.1493  Acc: 93.75%\n",
      "Epoch 1 [626/938]  Loss: 0.2528  Acc: 89.06%\n",
      "Epoch 1 [627/938]  Loss: 0.1611  Acc: 93.75%\n",
      "Epoch 1 [628/938]  Loss: 0.1795  Acc: 95.31%\n",
      "Epoch 1 [629/938]  Loss: 0.3953  Acc: 87.50%\n",
      "Epoch 1 [630/938]  Loss: 0.1205  Acc: 98.44%\n",
      "Epoch 1 [631/938]  Loss: 0.1177  Acc: 98.44%\n",
      "Epoch 1 [632/938]  Loss: 0.2789  Acc: 89.06%\n",
      "Epoch 1 [633/938]  Loss: 0.2194  Acc: 95.31%\n",
      "Epoch 1 [634/938]  Loss: 0.2016  Acc: 92.19%\n",
      "Epoch 1 [635/938]  Loss: 0.2821  Acc: 92.19%\n",
      "Epoch 1 [636/938]  Loss: 0.3383  Acc: 90.62%\n",
      "Epoch 1 [637/938]  Loss: 0.2983  Acc: 90.62%\n",
      "Epoch 1 [638/938]  Loss: 0.2054  Acc: 93.75%\n",
      "Epoch 1 [639/938]  Loss: 0.1711  Acc: 95.31%\n",
      "Epoch 1 [640/938]  Loss: 0.3781  Acc: 90.62%\n",
      "Epoch 1 [641/938]  Loss: 0.1128  Acc: 96.88%\n",
      "Epoch 1 [642/938]  Loss: 0.2963  Acc: 89.06%\n",
      "Epoch 1 [643/938]  Loss: 0.3223  Acc: 89.06%\n",
      "Epoch 1 [644/938]  Loss: 0.3093  Acc: 95.31%\n",
      "Epoch 1 [645/938]  Loss: 0.1861  Acc: 96.88%\n",
      "Epoch 1 [646/938]  Loss: 0.0930  Acc: 98.44%\n",
      "Epoch 1 [647/938]  Loss: 0.1322  Acc: 96.88%\n",
      "Epoch 1 [648/938]  Loss: 0.2353  Acc: 90.62%\n",
      "Epoch 1 [649/938]  Loss: 0.2075  Acc: 92.19%\n",
      "Epoch 1 [650/938]  Loss: 0.2480  Acc: 90.62%\n",
      "Epoch 1 [651/938]  Loss: 0.1562  Acc: 95.31%\n",
      "Epoch 1 [652/938]  Loss: 0.1834  Acc: 95.31%\n",
      "Epoch 1 [653/938]  Loss: 0.1914  Acc: 96.88%\n",
      "Epoch 1 [654/938]  Loss: 0.3337  Acc: 95.31%\n",
      "Epoch 1 [655/938]  Loss: 0.1943  Acc: 93.75%\n",
      "Epoch 1 [656/938]  Loss: 0.1712  Acc: 93.75%\n",
      "Epoch 1 [657/938]  Loss: 0.2365  Acc: 93.75%\n",
      "Epoch 1 [658/938]  Loss: 0.1948  Acc: 90.62%\n",
      "Epoch 1 [659/938]  Loss: 0.2170  Acc: 93.75%\n",
      "Epoch 1 [660/938]  Loss: 0.2231  Acc: 92.19%\n",
      "Epoch 1 [661/938]  Loss: 0.1719  Acc: 95.31%\n",
      "Epoch 1 [662/938]  Loss: 0.1685  Acc: 95.31%\n",
      "Epoch 1 [663/938]  Loss: 0.2129  Acc: 93.75%\n",
      "Epoch 1 [664/938]  Loss: 0.3695  Acc: 92.19%\n",
      "Epoch 1 [665/938]  Loss: 0.2416  Acc: 93.75%\n",
      "Epoch 1 [666/938]  Loss: 0.2918  Acc: 92.19%\n",
      "Epoch 1 [667/938]  Loss: 0.2997  Acc: 90.62%\n",
      "Epoch 1 [668/938]  Loss: 0.2016  Acc: 92.19%\n",
      "Epoch 1 [669/938]  Loss: 0.1957  Acc: 93.75%\n",
      "Epoch 1 [670/938]  Loss: 0.1247  Acc: 96.88%\n",
      "Epoch 1 [671/938]  Loss: 0.3123  Acc: 90.62%\n",
      "Epoch 1 [672/938]  Loss: 0.1687  Acc: 95.31%\n",
      "Epoch 1 [673/938]  Loss: 0.2757  Acc: 92.19%\n",
      "Epoch 1 [674/938]  Loss: 0.0689  Acc: 100.00%\n",
      "Epoch 1 [675/938]  Loss: 0.3156  Acc: 93.75%\n",
      "Epoch 1 [676/938]  Loss: 0.2394  Acc: 92.19%\n",
      "Epoch 1 [677/938]  Loss: 0.2628  Acc: 93.75%\n",
      "Epoch 1 [678/938]  Loss: 0.2150  Acc: 93.75%\n",
      "Epoch 1 [679/938]  Loss: 0.1851  Acc: 95.31%\n",
      "Epoch 1 [680/938]  Loss: 0.1453  Acc: 95.31%\n",
      "Epoch 1 [681/938]  Loss: 0.1325  Acc: 95.31%\n",
      "Epoch 1 [682/938]  Loss: 0.1151  Acc: 96.88%\n",
      "Epoch 1 [683/938]  Loss: 0.2191  Acc: 96.88%\n",
      "Epoch 1 [684/938]  Loss: 0.2910  Acc: 90.62%\n",
      "Epoch 1 [685/938]  Loss: 0.2248  Acc: 92.19%\n",
      "Epoch 1 [686/938]  Loss: 0.1390  Acc: 96.88%\n",
      "Epoch 1 [687/938]  Loss: 0.2803  Acc: 89.06%\n",
      "Epoch 1 [688/938]  Loss: 0.1927  Acc: 93.75%\n",
      "Epoch 1 [689/938]  Loss: 0.1669  Acc: 92.19%\n",
      "Epoch 1 [690/938]  Loss: 0.0951  Acc: 96.88%\n",
      "Epoch 1 [691/938]  Loss: 0.2136  Acc: 93.75%\n",
      "Epoch 1 [692/938]  Loss: 0.1696  Acc: 93.75%\n",
      "Epoch 1 [693/938]  Loss: 0.1970  Acc: 93.75%\n",
      "Epoch 1 [694/938]  Loss: 0.1000  Acc: 98.44%\n",
      "Epoch 1 [695/938]  Loss: 0.1514  Acc: 96.88%\n",
      "Epoch 1 [696/938]  Loss: 0.2263  Acc: 95.31%\n",
      "Epoch 1 [697/938]  Loss: 0.0971  Acc: 98.44%\n",
      "Epoch 1 [698/938]  Loss: 0.0630  Acc: 98.44%\n",
      "Epoch 1 [699/938]  Loss: 0.0948  Acc: 95.31%\n",
      "Epoch 1 [700/938]  Loss: 0.1958  Acc: 93.75%\n",
      "Epoch 1 [701/938]  Loss: 0.3045  Acc: 93.75%\n",
      "Epoch 1 [702/938]  Loss: 0.2450  Acc: 89.06%\n",
      "Epoch 1 [703/938]  Loss: 0.2266  Acc: 95.31%\n",
      "Epoch 1 [704/938]  Loss: 0.2229  Acc: 95.31%\n",
      "Epoch 1 [705/938]  Loss: 0.1602  Acc: 92.19%\n",
      "Epoch 1 [706/938]  Loss: 0.1121  Acc: 98.44%\n",
      "Epoch 1 [707/938]  Loss: 0.1958  Acc: 93.75%\n",
      "Epoch 1 [708/938]  Loss: 0.1073  Acc: 96.88%\n",
      "Epoch 1 [709/938]  Loss: 0.2619  Acc: 93.75%\n",
      "Epoch 1 [710/938]  Loss: 0.1778  Acc: 92.19%\n",
      "Epoch 1 [673/938]  Loss: 0.2757  Acc: 92.19%\n",
      "Epoch 1 [674/938]  Loss: 0.0689  Acc: 100.00%\n",
      "Epoch 1 [675/938]  Loss: 0.3156  Acc: 93.75%\n",
      "Epoch 1 [676/938]  Loss: 0.2394  Acc: 92.19%\n",
      "Epoch 1 [677/938]  Loss: 0.2628  Acc: 93.75%\n",
      "Epoch 1 [678/938]  Loss: 0.2150  Acc: 93.75%\n",
      "Epoch 1 [679/938]  Loss: 0.1851  Acc: 95.31%\n",
      "Epoch 1 [680/938]  Loss: 0.1453  Acc: 95.31%\n",
      "Epoch 1 [681/938]  Loss: 0.1325  Acc: 95.31%\n",
      "Epoch 1 [682/938]  Loss: 0.1151  Acc: 96.88%\n",
      "Epoch 1 [683/938]  Loss: 0.2191  Acc: 96.88%\n",
      "Epoch 1 [684/938]  Loss: 0.2910  Acc: 90.62%\n",
      "Epoch 1 [685/938]  Loss: 0.2248  Acc: 92.19%\n",
      "Epoch 1 [686/938]  Loss: 0.1390  Acc: 96.88%\n",
      "Epoch 1 [687/938]  Loss: 0.2803  Acc: 89.06%\n",
      "Epoch 1 [688/938]  Loss: 0.1927  Acc: 93.75%\n",
      "Epoch 1 [689/938]  Loss: 0.1669  Acc: 92.19%\n",
      "Epoch 1 [690/938]  Loss: 0.0951  Acc: 96.88%\n",
      "Epoch 1 [691/938]  Loss: 0.2136  Acc: 93.75%\n",
      "Epoch 1 [692/938]  Loss: 0.1696  Acc: 93.75%\n",
      "Epoch 1 [693/938]  Loss: 0.1970  Acc: 93.75%\n",
      "Epoch 1 [694/938]  Loss: 0.1000  Acc: 98.44%\n",
      "Epoch 1 [695/938]  Loss: 0.1514  Acc: 96.88%\n",
      "Epoch 1 [696/938]  Loss: 0.2263  Acc: 95.31%\n",
      "Epoch 1 [697/938]  Loss: 0.0971  Acc: 98.44%\n",
      "Epoch 1 [698/938]  Loss: 0.0630  Acc: 98.44%\n",
      "Epoch 1 [699/938]  Loss: 0.0948  Acc: 95.31%\n",
      "Epoch 1 [700/938]  Loss: 0.1958  Acc: 93.75%\n",
      "Epoch 1 [701/938]  Loss: 0.3045  Acc: 93.75%\n",
      "Epoch 1 [702/938]  Loss: 0.2450  Acc: 89.06%\n",
      "Epoch 1 [703/938]  Loss: 0.2266  Acc: 95.31%\n",
      "Epoch 1 [704/938]  Loss: 0.2229  Acc: 95.31%\n",
      "Epoch 1 [705/938]  Loss: 0.1602  Acc: 92.19%\n",
      "Epoch 1 [706/938]  Loss: 0.1121  Acc: 98.44%\n",
      "Epoch 1 [707/938]  Loss: 0.1958  Acc: 93.75%\n",
      "Epoch 1 [708/938]  Loss: 0.1073  Acc: 96.88%\n",
      "Epoch 1 [709/938]  Loss: 0.2619  Acc: 93.75%\n",
      "Epoch 1 [710/938]  Loss: 0.1778  Acc: 92.19%\n",
      "Epoch 1 [711/938]  Loss: 0.2253  Acc: 92.19%\n",
      "Epoch 1 [712/938]  Loss: 0.2305  Acc: 93.75%\n",
      "Epoch 1 [713/938]  Loss: 0.1448  Acc: 96.88%\n",
      "Epoch 1 [714/938]  Loss: 0.1111  Acc: 98.44%\n",
      "Epoch 1 [715/938]  Loss: 0.1969  Acc: 93.75%\n",
      "Epoch 1 [716/938]  Loss: 0.1666  Acc: 95.31%\n",
      "Epoch 1 [717/938]  Loss: 0.1909  Acc: 93.75%\n",
      "Epoch 1 [718/938]  Loss: 0.1461  Acc: 98.44%\n",
      "Epoch 1 [719/938]  Loss: 0.2620  Acc: 89.06%\n",
      "Epoch 1 [720/938]  Loss: 0.1462  Acc: 96.88%\n",
      "Epoch 1 [721/938]  Loss: 0.1261  Acc: 95.31%\n",
      "Epoch 1 [722/938]  Loss: 0.1635  Acc: 95.31%\n",
      "Epoch 1 [723/938]  Loss: 0.2943  Acc: 90.62%\n",
      "Epoch 1 [724/938]  Loss: 0.1755  Acc: 95.31%\n",
      "Epoch 1 [725/938]  Loss: 0.1865  Acc: 95.31%\n",
      "Epoch 1 [726/938]  Loss: 0.2119  Acc: 90.62%\n",
      "Epoch 1 [727/938]  Loss: 0.1836  Acc: 93.75%\n",
      "Epoch 1 [728/938]  Loss: 0.2596  Acc: 90.62%\n",
      "Epoch 1 [729/938]  Loss: 0.2019  Acc: 93.75%\n",
      "Epoch 1 [730/938]  Loss: 0.5241  Acc: 87.50%\n",
      "Epoch 1 [731/938]  Loss: 0.2477  Acc: 93.75%\n",
      "Epoch 1 [732/938]  Loss: 0.1712  Acc: 93.75%\n",
      "Epoch 1 [733/938]  Loss: 0.3110  Acc: 85.94%\n",
      "Epoch 1 [734/938]  Loss: 0.2032  Acc: 92.19%\n",
      "Epoch 1 [735/938]  Loss: 0.1694  Acc: 93.75%\n",
      "Epoch 1 [736/938]  Loss: 0.3165  Acc: 89.06%\n",
      "Epoch 1 [737/938]  Loss: 0.3392  Acc: 92.19%\n",
      "Epoch 1 [738/938]  Loss: 0.2876  Acc: 90.62%\n",
      "Epoch 1 [739/938]  Loss: 0.2333  Acc: 93.75%\n",
      "Epoch 1 [740/938]  Loss: 0.0921  Acc: 98.44%\n",
      "Epoch 1 [741/938]  Loss: 0.3056  Acc: 92.19%\n",
      "Epoch 1 [742/938]  Loss: 0.1160  Acc: 96.88%\n",
      "Epoch 1 [743/938]  Loss: 0.1515  Acc: 95.31%\n",
      "Epoch 1 [744/938]  Loss: 0.3059  Acc: 92.19%\n",
      "Epoch 1 [745/938]  Loss: 0.1466  Acc: 95.31%\n",
      "Epoch 1 [746/938]  Loss: 0.3539  Acc: 87.50%\n",
      "Epoch 1 [747/938]  Loss: 0.0844  Acc: 96.88%\n",
      "Epoch 1 [748/938]  Loss: 0.1887  Acc: 92.19%\n",
      "Epoch 1 [749/938]  Loss: 0.1714  Acc: 92.19%\n",
      "Epoch 1 [750/938]  Loss: 0.1786  Acc: 93.75%\n",
      "Epoch 1 [751/938]  Loss: 0.2314  Acc: 92.19%\n",
      "Epoch 1 [752/938]  Loss: 0.1800  Acc: 92.19%\n",
      "Epoch 1 [711/938]  Loss: 0.2253  Acc: 92.19%\n",
      "Epoch 1 [712/938]  Loss: 0.2305  Acc: 93.75%\n",
      "Epoch 1 [713/938]  Loss: 0.1448  Acc: 96.88%\n",
      "Epoch 1 [714/938]  Loss: 0.1111  Acc: 98.44%\n",
      "Epoch 1 [715/938]  Loss: 0.1969  Acc: 93.75%\n",
      "Epoch 1 [716/938]  Loss: 0.1666  Acc: 95.31%\n",
      "Epoch 1 [717/938]  Loss: 0.1909  Acc: 93.75%\n",
      "Epoch 1 [718/938]  Loss: 0.1461  Acc: 98.44%\n",
      "Epoch 1 [719/938]  Loss: 0.2620  Acc: 89.06%\n",
      "Epoch 1 [720/938]  Loss: 0.1462  Acc: 96.88%\n",
      "Epoch 1 [721/938]  Loss: 0.1261  Acc: 95.31%\n",
      "Epoch 1 [722/938]  Loss: 0.1635  Acc: 95.31%\n",
      "Epoch 1 [723/938]  Loss: 0.2943  Acc: 90.62%\n",
      "Epoch 1 [724/938]  Loss: 0.1755  Acc: 95.31%\n",
      "Epoch 1 [725/938]  Loss: 0.1865  Acc: 95.31%\n",
      "Epoch 1 [726/938]  Loss: 0.2119  Acc: 90.62%\n",
      "Epoch 1 [727/938]  Loss: 0.1836  Acc: 93.75%\n",
      "Epoch 1 [728/938]  Loss: 0.2596  Acc: 90.62%\n",
      "Epoch 1 [729/938]  Loss: 0.2019  Acc: 93.75%\n",
      "Epoch 1 [730/938]  Loss: 0.5241  Acc: 87.50%\n",
      "Epoch 1 [731/938]  Loss: 0.2477  Acc: 93.75%\n",
      "Epoch 1 [732/938]  Loss: 0.1712  Acc: 93.75%\n",
      "Epoch 1 [733/938]  Loss: 0.3110  Acc: 85.94%\n",
      "Epoch 1 [734/938]  Loss: 0.2032  Acc: 92.19%\n",
      "Epoch 1 [735/938]  Loss: 0.1694  Acc: 93.75%\n",
      "Epoch 1 [736/938]  Loss: 0.3165  Acc: 89.06%\n",
      "Epoch 1 [737/938]  Loss: 0.3392  Acc: 92.19%\n",
      "Epoch 1 [738/938]  Loss: 0.2876  Acc: 90.62%\n",
      "Epoch 1 [739/938]  Loss: 0.2333  Acc: 93.75%\n",
      "Epoch 1 [740/938]  Loss: 0.0921  Acc: 98.44%\n",
      "Epoch 1 [741/938]  Loss: 0.3056  Acc: 92.19%\n",
      "Epoch 1 [742/938]  Loss: 0.1160  Acc: 96.88%\n",
      "Epoch 1 [743/938]  Loss: 0.1515  Acc: 95.31%\n",
      "Epoch 1 [744/938]  Loss: 0.3059  Acc: 92.19%\n",
      "Epoch 1 [745/938]  Loss: 0.1466  Acc: 95.31%\n",
      "Epoch 1 [746/938]  Loss: 0.3539  Acc: 87.50%\n",
      "Epoch 1 [747/938]  Loss: 0.0844  Acc: 96.88%\n",
      "Epoch 1 [748/938]  Loss: 0.1887  Acc: 92.19%\n",
      "Epoch 1 [749/938]  Loss: 0.1714  Acc: 92.19%\n",
      "Epoch 1 [750/938]  Loss: 0.1786  Acc: 93.75%\n",
      "Epoch 1 [751/938]  Loss: 0.2314  Acc: 92.19%\n",
      "Epoch 1 [752/938]  Loss: 0.1800  Acc: 92.19%\n",
      "Epoch 1 [753/938]  Loss: 0.0983  Acc: 98.44%\n",
      "Epoch 1 [754/938]  Loss: 0.0568  Acc: 100.00%\n",
      "Epoch 1 [755/938]  Loss: 0.2013  Acc: 93.75%\n",
      "Epoch 1 [756/938]  Loss: 0.2748  Acc: 89.06%\n",
      "Epoch 1 [757/938]  Loss: 0.3455  Acc: 92.19%\n",
      "Epoch 1 [758/938]  Loss: 0.2663  Acc: 92.19%\n",
      "Epoch 1 [759/938]  Loss: 0.2380  Acc: 92.19%\n",
      "Epoch 1 [760/938]  Loss: 0.2433  Acc: 95.31%\n",
      "Epoch 1 [761/938]  Loss: 0.1200  Acc: 95.31%\n",
      "Epoch 1 [762/938]  Loss: 0.1575  Acc: 95.31%\n",
      "Epoch 1 [763/938]  Loss: 0.0938  Acc: 100.00%\n",
      "Epoch 1 [764/938]  Loss: 0.0997  Acc: 96.88%\n",
      "Epoch 1 [765/938]  Loss: 0.2087  Acc: 90.62%\n",
      "Epoch 1 [766/938]  Loss: 0.1120  Acc: 96.88%\n",
      "Epoch 1 [767/938]  Loss: 0.1622  Acc: 95.31%\n",
      "Epoch 1 [768/938]  Loss: 0.0681  Acc: 100.00%\n",
      "Epoch 1 [769/938]  Loss: 0.2598  Acc: 90.62%\n",
      "Epoch 1 [770/938]  Loss: 0.1178  Acc: 96.88%\n",
      "Epoch 1 [771/938]  Loss: 0.2866  Acc: 89.06%\n",
      "Epoch 1 [772/938]  Loss: 0.1961  Acc: 93.75%\n",
      "Epoch 1 [773/938]  Loss: 0.2592  Acc: 92.19%\n",
      "Epoch 1 [774/938]  Loss: 0.2201  Acc: 93.75%\n",
      "Epoch 1 [775/938]  Loss: 0.2193  Acc: 90.62%\n",
      "Epoch 1 [776/938]  Loss: 0.1611  Acc: 93.75%\n",
      "Epoch 1 [777/938]  Loss: 0.1650  Acc: 95.31%\n",
      "Epoch 1 [778/938]  Loss: 0.2676  Acc: 93.75%\n",
      "Epoch 1 [779/938]  Loss: 0.2196  Acc: 93.75%\n",
      "Epoch 1 [780/938]  Loss: 0.3615  Acc: 90.62%\n",
      "Epoch 1 [781/938]  Loss: 0.1153  Acc: 95.31%\n",
      "Epoch 1 [782/938]  Loss: 0.1857  Acc: 92.19%\n",
      "Epoch 1 [783/938]  Loss: 0.1847  Acc: 92.19%\n",
      "Epoch 1 [784/938]  Loss: 0.2628  Acc: 90.62%\n",
      "Epoch 1 [785/938]  Loss: 0.1990  Acc: 92.19%\n",
      "Epoch 1 [786/938]  Loss: 0.2056  Acc: 90.62%\n",
      "Epoch 1 [787/938]  Loss: 0.1610  Acc: 93.75%\n",
      "Epoch 1 [788/938]  Loss: 0.2267  Acc: 95.31%\n",
      "Epoch 1 [753/938]  Loss: 0.0983  Acc: 98.44%\n",
      "Epoch 1 [754/938]  Loss: 0.0568  Acc: 100.00%\n",
      "Epoch 1 [755/938]  Loss: 0.2013  Acc: 93.75%\n",
      "Epoch 1 [756/938]  Loss: 0.2748  Acc: 89.06%\n",
      "Epoch 1 [757/938]  Loss: 0.3455  Acc: 92.19%\n",
      "Epoch 1 [758/938]  Loss: 0.2663  Acc: 92.19%\n",
      "Epoch 1 [759/938]  Loss: 0.2380  Acc: 92.19%\n",
      "Epoch 1 [760/938]  Loss: 0.2433  Acc: 95.31%\n",
      "Epoch 1 [761/938]  Loss: 0.1200  Acc: 95.31%\n",
      "Epoch 1 [762/938]  Loss: 0.1575  Acc: 95.31%\n",
      "Epoch 1 [763/938]  Loss: 0.0938  Acc: 100.00%\n",
      "Epoch 1 [764/938]  Loss: 0.0997  Acc: 96.88%\n",
      "Epoch 1 [765/938]  Loss: 0.2087  Acc: 90.62%\n",
      "Epoch 1 [766/938]  Loss: 0.1120  Acc: 96.88%\n",
      "Epoch 1 [767/938]  Loss: 0.1622  Acc: 95.31%\n",
      "Epoch 1 [768/938]  Loss: 0.0681  Acc: 100.00%\n",
      "Epoch 1 [769/938]  Loss: 0.2598  Acc: 90.62%\n",
      "Epoch 1 [770/938]  Loss: 0.1178  Acc: 96.88%\n",
      "Epoch 1 [771/938]  Loss: 0.2866  Acc: 89.06%\n",
      "Epoch 1 [772/938]  Loss: 0.1961  Acc: 93.75%\n",
      "Epoch 1 [773/938]  Loss: 0.2592  Acc: 92.19%\n",
      "Epoch 1 [774/938]  Loss: 0.2201  Acc: 93.75%\n",
      "Epoch 1 [775/938]  Loss: 0.2193  Acc: 90.62%\n",
      "Epoch 1 [776/938]  Loss: 0.1611  Acc: 93.75%\n",
      "Epoch 1 [777/938]  Loss: 0.1650  Acc: 95.31%\n",
      "Epoch 1 [778/938]  Loss: 0.2676  Acc: 93.75%\n",
      "Epoch 1 [779/938]  Loss: 0.2196  Acc: 93.75%\n",
      "Epoch 1 [780/938]  Loss: 0.3615  Acc: 90.62%\n",
      "Epoch 1 [781/938]  Loss: 0.1153  Acc: 95.31%\n",
      "Epoch 1 [782/938]  Loss: 0.1857  Acc: 92.19%\n",
      "Epoch 1 [783/938]  Loss: 0.1847  Acc: 92.19%\n",
      "Epoch 1 [784/938]  Loss: 0.2628  Acc: 90.62%\n",
      "Epoch 1 [785/938]  Loss: 0.1990  Acc: 92.19%\n",
      "Epoch 1 [786/938]  Loss: 0.2056  Acc: 90.62%\n",
      "Epoch 1 [787/938]  Loss: 0.1610  Acc: 93.75%\n",
      "Epoch 1 [788/938]  Loss: 0.2267  Acc: 95.31%\n",
      "Epoch 1 [789/938]  Loss: 0.2122  Acc: 92.19%\n",
      "Epoch 1 [790/938]  Loss: 0.1171  Acc: 95.31%\n",
      "Epoch 1 [791/938]  Loss: 0.2449  Acc: 92.19%\n",
      "Epoch 1 [792/938]  Loss: 0.1934  Acc: 92.19%\n",
      "Epoch 1 [793/938]  Loss: 0.0901  Acc: 100.00%\n",
      "Epoch 1 [794/938]  Loss: 0.2045  Acc: 92.19%\n",
      "Epoch 1 [795/938]  Loss: 0.0684  Acc: 100.00%\n",
      "Epoch 1 [796/938]  Loss: 0.2868  Acc: 95.31%\n",
      "Epoch 1 [797/938]  Loss: 0.1339  Acc: 95.31%\n",
      "Epoch 1 [798/938]  Loss: 0.1099  Acc: 95.31%\n",
      "Epoch 1 [799/938]  Loss: 0.2086  Acc: 92.19%\n",
      "Epoch 1 [800/938]  Loss: 0.2631  Acc: 93.75%\n",
      "Epoch 1 [801/938]  Loss: 0.2639  Acc: 93.75%\n",
      "Epoch 1 [802/938]  Loss: 0.1353  Acc: 95.31%\n",
      "Epoch 1 [803/938]  Loss: 0.3765  Acc: 92.19%\n",
      "Epoch 1 [804/938]  Loss: 0.2383  Acc: 95.31%\n",
      "Epoch 1 [805/938]  Loss: 0.1399  Acc: 92.19%\n",
      "Epoch 1 [806/938]  Loss: 0.2168  Acc: 95.31%\n",
      "Epoch 1 [807/938]  Loss: 0.1381  Acc: 93.75%\n",
      "Epoch 1 [808/938]  Loss: 0.1349  Acc: 96.88%\n",
      "Epoch 1 [809/938]  Loss: 0.1888  Acc: 95.31%\n",
      "Epoch 1 [810/938]  Loss: 0.2355  Acc: 93.75%\n",
      "Epoch 1 [811/938]  Loss: 0.2959  Acc: 89.06%\n",
      "Epoch 1 [812/938]  Loss: 0.1799  Acc: 95.31%\n",
      "Epoch 1 [789/938]  Loss: 0.2122  Acc: 92.19%\n",
      "Epoch 1 [790/938]  Loss: 0.1171  Acc: 95.31%\n",
      "Epoch 1 [791/938]  Loss: 0.2449  Acc: 92.19%\n",
      "Epoch 1 [792/938]  Loss: 0.1934  Acc: 92.19%\n",
      "Epoch 1 [793/938]  Loss: 0.0901  Acc: 100.00%\n",
      "Epoch 1 [794/938]  Loss: 0.2045  Acc: 92.19%\n",
      "Epoch 1 [795/938]  Loss: 0.0684  Acc: 100.00%\n",
      "Epoch 1 [796/938]  Loss: 0.2868  Acc: 95.31%\n",
      "Epoch 1 [797/938]  Loss: 0.1339  Acc: 95.31%\n",
      "Epoch 1 [798/938]  Loss: 0.1099  Acc: 95.31%\n",
      "Epoch 1 [799/938]  Loss: 0.2086  Acc: 92.19%\n",
      "Epoch 1 [800/938]  Loss: 0.2631  Acc: 93.75%\n",
      "Epoch 1 [801/938]  Loss: 0.2639  Acc: 93.75%\n",
      "Epoch 1 [802/938]  Loss: 0.1353  Acc: 95.31%\n",
      "Epoch 1 [803/938]  Loss: 0.3765  Acc: 92.19%\n",
      "Epoch 1 [804/938]  Loss: 0.2383  Acc: 95.31%\n",
      "Epoch 1 [805/938]  Loss: 0.1399  Acc: 92.19%\n",
      "Epoch 1 [806/938]  Loss: 0.2168  Acc: 95.31%\n",
      "Epoch 1 [807/938]  Loss: 0.1381  Acc: 93.75%\n",
      "Epoch 1 [808/938]  Loss: 0.1349  Acc: 96.88%\n",
      "Epoch 1 [809/938]  Loss: 0.1888  Acc: 95.31%\n",
      "Epoch 1 [810/938]  Loss: 0.2355  Acc: 93.75%\n",
      "Epoch 1 [811/938]  Loss: 0.2959  Acc: 89.06%\n",
      "Epoch 1 [812/938]  Loss: 0.1799  Acc: 95.31%\n",
      "Epoch 1 [813/938]  Loss: 0.6035  Acc: 90.62%\n",
      "Epoch 1 [814/938]  Loss: 0.2497  Acc: 92.19%\n",
      "Epoch 1 [815/938]  Loss: 0.2688  Acc: 95.31%\n",
      "Epoch 1 [816/938]  Loss: 0.1944  Acc: 93.75%\n",
      "Epoch 1 [817/938]  Loss: 0.2854  Acc: 92.19%\n",
      "Epoch 1 [818/938]  Loss: 0.2157  Acc: 95.31%\n",
      "Epoch 1 [819/938]  Loss: 0.2383  Acc: 92.19%\n",
      "Epoch 1 [820/938]  Loss: 0.2487  Acc: 93.75%\n",
      "Epoch 1 [821/938]  Loss: 0.2161  Acc: 90.62%\n",
      "Epoch 1 [822/938]  Loss: 0.2159  Acc: 93.75%\n",
      "Epoch 1 [823/938]  Loss: 0.1997  Acc: 95.31%\n",
      "Epoch 1 [824/938]  Loss: 0.1895  Acc: 93.75%\n",
      "Epoch 1 [825/938]  Loss: 0.1181  Acc: 96.88%\n",
      "Epoch 1 [826/938]  Loss: 0.2376  Acc: 90.62%\n",
      "Epoch 1 [827/938]  Loss: 0.1263  Acc: 96.88%\n",
      "Epoch 1 [828/938]  Loss: 0.0487  Acc: 100.00%\n",
      "Epoch 1 [829/938]  Loss: 0.1125  Acc: 95.31%\n",
      "Epoch 1 [830/938]  Loss: 0.3083  Acc: 89.06%\n",
      "Epoch 1 [831/938]  Loss: 0.1411  Acc: 93.75%\n",
      "Epoch 1 [832/938]  Loss: 0.3744  Acc: 87.50%\n",
      "Epoch 1 [833/938]  Loss: 0.1145  Acc: 96.88%\n",
      "Epoch 1 [834/938]  Loss: 0.1104  Acc: 98.44%\n",
      "Epoch 1 [835/938]  Loss: 0.0889  Acc: 96.88%\n",
      "Epoch 1 [836/938]  Loss: 0.1433  Acc: 96.88%\n",
      "Epoch 1 [837/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 1 [838/938]  Loss: 0.1951  Acc: 93.75%\n",
      "Epoch 1 [839/938]  Loss: 0.3234  Acc: 89.06%\n",
      "Epoch 1 [840/938]  Loss: 0.2742  Acc: 89.06%\n",
      "Epoch 1 [841/938]  Loss: 0.1338  Acc: 95.31%\n",
      "Epoch 1 [842/938]  Loss: 0.1862  Acc: 95.31%\n",
      "Epoch 1 [843/938]  Loss: 0.2033  Acc: 95.31%\n",
      "Epoch 1 [844/938]  Loss: 0.1817  Acc: 93.75%\n",
      "Epoch 1 [845/938]  Loss: 0.2904  Acc: 89.06%\n",
      "Epoch 1 [846/938]  Loss: 0.1720  Acc: 93.75%\n",
      "Epoch 1 [847/938]  Loss: 0.1548  Acc: 96.88%\n",
      "Epoch 1 [848/938]  Loss: 0.1943  Acc: 90.62%\n",
      "Epoch 1 [849/938]  Loss: 0.2874  Acc: 93.75%\n",
      "Epoch 1 [850/938]  Loss: 0.1865  Acc: 93.75%\n",
      "Epoch 1 [851/938]  Loss: 0.1994  Acc: 92.19%\n",
      "Epoch 1 [852/938]  Loss: 0.2228  Acc: 93.75%\n",
      "Epoch 1 [853/938]  Loss: 0.1665  Acc: 95.31%\n",
      "Epoch 1 [854/938]  Loss: 0.1546  Acc: 93.75%\n",
      "Epoch 1 [855/938]  Loss: 0.0947  Acc: 98.44%\n",
      "Epoch 1 [856/938]  Loss: 0.2984  Acc: 90.62%\n",
      "Epoch 1 [857/938]  Loss: 0.3430  Acc: 89.06%\n",
      "Epoch 1 [858/938]  Loss: 0.1269  Acc: 95.31%\n",
      "Epoch 1 [859/938]  Loss: 0.1356  Acc: 93.75%\n",
      "Epoch 1 [860/938]  Loss: 0.2596  Acc: 90.62%\n",
      "Epoch 1 [861/938]  Loss: 0.2701  Acc: 92.19%\n",
      "Epoch 1 [862/938]  Loss: 0.3751  Acc: 89.06%\n",
      "Epoch 1 [863/938]  Loss: 0.1343  Acc: 96.88%\n",
      "Epoch 1 [864/938]  Loss: 0.0984  Acc: 96.88%\n",
      "Epoch 1 [865/938]  Loss: 0.1037  Acc: 98.44%\n",
      "Epoch 1 [866/938]  Loss: 0.1742  Acc: 92.19%\n",
      "Epoch 1 [867/938]  Loss: 0.1299  Acc: 96.88%\n",
      "Epoch 1 [868/938]  Loss: 0.1629  Acc: 90.62%\n",
      "Epoch 1 [813/938]  Loss: 0.6035  Acc: 90.62%\n",
      "Epoch 1 [814/938]  Loss: 0.2497  Acc: 92.19%\n",
      "Epoch 1 [815/938]  Loss: 0.2688  Acc: 95.31%\n",
      "Epoch 1 [816/938]  Loss: 0.1944  Acc: 93.75%\n",
      "Epoch 1 [817/938]  Loss: 0.2854  Acc: 92.19%\n",
      "Epoch 1 [818/938]  Loss: 0.2157  Acc: 95.31%\n",
      "Epoch 1 [819/938]  Loss: 0.2383  Acc: 92.19%\n",
      "Epoch 1 [820/938]  Loss: 0.2487  Acc: 93.75%\n",
      "Epoch 1 [821/938]  Loss: 0.2161  Acc: 90.62%\n",
      "Epoch 1 [822/938]  Loss: 0.2159  Acc: 93.75%\n",
      "Epoch 1 [823/938]  Loss: 0.1997  Acc: 95.31%\n",
      "Epoch 1 [824/938]  Loss: 0.1895  Acc: 93.75%\n",
      "Epoch 1 [825/938]  Loss: 0.1181  Acc: 96.88%\n",
      "Epoch 1 [826/938]  Loss: 0.2376  Acc: 90.62%\n",
      "Epoch 1 [827/938]  Loss: 0.1263  Acc: 96.88%\n",
      "Epoch 1 [828/938]  Loss: 0.0487  Acc: 100.00%\n",
      "Epoch 1 [829/938]  Loss: 0.1125  Acc: 95.31%\n",
      "Epoch 1 [830/938]  Loss: 0.3083  Acc: 89.06%\n",
      "Epoch 1 [831/938]  Loss: 0.1411  Acc: 93.75%\n",
      "Epoch 1 [832/938]  Loss: 0.3744  Acc: 87.50%\n",
      "Epoch 1 [833/938]  Loss: 0.1145  Acc: 96.88%\n",
      "Epoch 1 [834/938]  Loss: 0.1104  Acc: 98.44%\n",
      "Epoch 1 [835/938]  Loss: 0.0889  Acc: 96.88%\n",
      "Epoch 1 [836/938]  Loss: 0.1433  Acc: 96.88%\n",
      "Epoch 1 [837/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 1 [838/938]  Loss: 0.1951  Acc: 93.75%\n",
      "Epoch 1 [839/938]  Loss: 0.3234  Acc: 89.06%\n",
      "Epoch 1 [840/938]  Loss: 0.2742  Acc: 89.06%\n",
      "Epoch 1 [841/938]  Loss: 0.1338  Acc: 95.31%\n",
      "Epoch 1 [842/938]  Loss: 0.1862  Acc: 95.31%\n",
      "Epoch 1 [843/938]  Loss: 0.2033  Acc: 95.31%\n",
      "Epoch 1 [844/938]  Loss: 0.1817  Acc: 93.75%\n",
      "Epoch 1 [845/938]  Loss: 0.2904  Acc: 89.06%\n",
      "Epoch 1 [846/938]  Loss: 0.1720  Acc: 93.75%\n",
      "Epoch 1 [847/938]  Loss: 0.1548  Acc: 96.88%\n",
      "Epoch 1 [848/938]  Loss: 0.1943  Acc: 90.62%\n",
      "Epoch 1 [849/938]  Loss: 0.2874  Acc: 93.75%\n",
      "Epoch 1 [850/938]  Loss: 0.1865  Acc: 93.75%\n",
      "Epoch 1 [851/938]  Loss: 0.1994  Acc: 92.19%\n",
      "Epoch 1 [852/938]  Loss: 0.2228  Acc: 93.75%\n",
      "Epoch 1 [853/938]  Loss: 0.1665  Acc: 95.31%\n",
      "Epoch 1 [854/938]  Loss: 0.1546  Acc: 93.75%\n",
      "Epoch 1 [855/938]  Loss: 0.0947  Acc: 98.44%\n",
      "Epoch 1 [856/938]  Loss: 0.2984  Acc: 90.62%\n",
      "Epoch 1 [857/938]  Loss: 0.3430  Acc: 89.06%\n",
      "Epoch 1 [858/938]  Loss: 0.1269  Acc: 95.31%\n",
      "Epoch 1 [859/938]  Loss: 0.1356  Acc: 93.75%\n",
      "Epoch 1 [860/938]  Loss: 0.2596  Acc: 90.62%\n",
      "Epoch 1 [861/938]  Loss: 0.2701  Acc: 92.19%\n",
      "Epoch 1 [862/938]  Loss: 0.3751  Acc: 89.06%\n",
      "Epoch 1 [863/938]  Loss: 0.1343  Acc: 96.88%\n",
      "Epoch 1 [864/938]  Loss: 0.0984  Acc: 96.88%\n",
      "Epoch 1 [865/938]  Loss: 0.1037  Acc: 98.44%\n",
      "Epoch 1 [866/938]  Loss: 0.1742  Acc: 92.19%\n",
      "Epoch 1 [867/938]  Loss: 0.1299  Acc: 96.88%\n",
      "Epoch 1 [868/938]  Loss: 0.1629  Acc: 90.62%\n",
      "Epoch 1 [869/938]  Loss: 0.0370  Acc: 100.00%\n",
      "Epoch 1 [870/938]  Loss: 0.1077  Acc: 98.44%\n",
      "Epoch 1 [871/938]  Loss: 0.2795  Acc: 90.62%\n",
      "Epoch 1 [872/938]  Loss: 0.0566  Acc: 98.44%\n",
      "Epoch 1 [873/938]  Loss: 0.0968  Acc: 96.88%\n",
      "Epoch 1 [874/938]  Loss: 0.1319  Acc: 95.31%\n",
      "Epoch 1 [875/938]  Loss: 0.2782  Acc: 89.06%\n",
      "Epoch 1 [876/938]  Loss: 0.3329  Acc: 93.75%\n",
      "Epoch 1 [877/938]  Loss: 0.1615  Acc: 95.31%\n",
      "Epoch 1 [878/938]  Loss: 0.1018  Acc: 96.88%\n",
      "Epoch 1 [879/938]  Loss: 0.1766  Acc: 98.44%\n",
      "Epoch 1 [880/938]  Loss: 0.0867  Acc: 98.44%\n",
      "Epoch 1 [881/938]  Loss: 0.0657  Acc: 100.00%\n",
      "Epoch 1 [882/938]  Loss: 0.0964  Acc: 98.44%\n",
      "Epoch 1 [883/938]  Loss: 0.3198  Acc: 90.62%\n",
      "Epoch 1 [884/938]  Loss: 0.1607  Acc: 95.31%\n",
      "Epoch 1 [885/938]  Loss: 0.1543  Acc: 93.75%\n",
      "Epoch 1 [886/938]  Loss: 0.2498  Acc: 92.19%\n",
      "Epoch 1 [887/938]  Loss: 0.0883  Acc: 98.44%\n",
      "Epoch 1 [888/938]  Loss: 0.3365  Acc: 92.19%\n",
      "Epoch 1 [889/938]  Loss: 0.1937  Acc: 92.19%\n",
      "Epoch 1 [890/938]  Loss: 0.3086  Acc: 90.62%\n",
      "Epoch 1 [891/938]  Loss: 0.1489  Acc: 95.31%\n",
      "Epoch 1 [892/938]  Loss: 0.2901  Acc: 93.75%\n",
      "Epoch 1 [893/938]  Loss: 0.2042  Acc: 96.88%\n",
      "Epoch 1 [894/938]  Loss: 0.2529  Acc: 92.19%\n",
      "Epoch 1 [895/938]  Loss: 0.1356  Acc: 95.31%\n",
      "Epoch 1 [896/938]  Loss: 0.1124  Acc: 95.31%\n",
      "Epoch 1 [897/938]  Loss: 0.2299  Acc: 92.19%\n",
      "Epoch 1 [898/938]  Loss: 0.1908  Acc: 92.19%\n",
      "Epoch 1 [899/938]  Loss: 0.1248  Acc: 96.88%\n",
      "Epoch 1 [900/938]  Loss: 0.1619  Acc: 93.75%\n",
      "Epoch 1 [901/938]  Loss: 0.0991  Acc: 98.44%\n",
      "Epoch 1 [902/938]  Loss: 0.1956  Acc: 92.19%\n",
      "Epoch 1 [903/938]  Loss: 0.1952  Acc: 95.31%\n",
      "Epoch 1 [904/938]  Loss: 0.1730  Acc: 93.75%\n",
      "Epoch 1 [905/938]  Loss: 0.0893  Acc: 96.88%\n",
      "Epoch 1 [906/938]  Loss: 0.3449  Acc: 90.62%\n",
      "Epoch 1 [907/938]  Loss: 0.1119  Acc: 96.88%\n",
      "Epoch 1 [908/938]  Loss: 0.1633  Acc: 95.31%\n",
      "Epoch 1 [909/938]  Loss: 0.3067  Acc: 89.06%\n",
      "Epoch 1 [910/938]  Loss: 0.1141  Acc: 95.31%\n",
      "Epoch 1 [911/938]  Loss: 0.2013  Acc: 95.31%\n",
      "Epoch 1 [912/938]  Loss: 0.1162  Acc: 95.31%\n",
      "Epoch 1 [913/938]  Loss: 0.1890  Acc: 93.75%\n",
      "Epoch 1 [914/938]  Loss: 0.1828  Acc: 93.75%\n",
      "Epoch 1 [915/938]  Loss: 0.2996  Acc: 95.31%\n",
      "Epoch 1 [916/938]  Loss: 0.1826  Acc: 93.75%\n",
      "Epoch 1 [917/938]  Loss: 0.1896  Acc: 92.19%\n",
      "Epoch 1 [918/938]  Loss: 0.1806  Acc: 96.88%\n",
      "Epoch 1 [919/938]  Loss: 0.1616  Acc: 95.31%\n",
      "Epoch 1 [920/938]  Loss: 0.1279  Acc: 96.88%\n",
      "Epoch 1 [921/938]  Loss: 0.2511  Acc: 92.19%\n",
      "Epoch 1 [922/938]  Loss: 0.1045  Acc: 95.31%\n",
      "Epoch 1 [923/938]  Loss: 0.2360  Acc: 89.06%\n",
      "Epoch 1 [924/938]  Loss: 0.3519  Acc: 93.75%\n",
      "Epoch 1 [869/938]  Loss: 0.0370  Acc: 100.00%\n",
      "Epoch 1 [870/938]  Loss: 0.1077  Acc: 98.44%\n",
      "Epoch 1 [871/938]  Loss: 0.2795  Acc: 90.62%\n",
      "Epoch 1 [872/938]  Loss: 0.0566  Acc: 98.44%\n",
      "Epoch 1 [873/938]  Loss: 0.0968  Acc: 96.88%\n",
      "Epoch 1 [874/938]  Loss: 0.1319  Acc: 95.31%\n",
      "Epoch 1 [875/938]  Loss: 0.2782  Acc: 89.06%\n",
      "Epoch 1 [876/938]  Loss: 0.3329  Acc: 93.75%\n",
      "Epoch 1 [877/938]  Loss: 0.1615  Acc: 95.31%\n",
      "Epoch 1 [878/938]  Loss: 0.1018  Acc: 96.88%\n",
      "Epoch 1 [879/938]  Loss: 0.1766  Acc: 98.44%\n",
      "Epoch 1 [880/938]  Loss: 0.0867  Acc: 98.44%\n",
      "Epoch 1 [881/938]  Loss: 0.0657  Acc: 100.00%\n",
      "Epoch 1 [882/938]  Loss: 0.0964  Acc: 98.44%\n",
      "Epoch 1 [883/938]  Loss: 0.3198  Acc: 90.62%\n",
      "Epoch 1 [884/938]  Loss: 0.1607  Acc: 95.31%\n",
      "Epoch 1 [885/938]  Loss: 0.1543  Acc: 93.75%\n",
      "Epoch 1 [886/938]  Loss: 0.2498  Acc: 92.19%\n",
      "Epoch 1 [887/938]  Loss: 0.0883  Acc: 98.44%\n",
      "Epoch 1 [888/938]  Loss: 0.3365  Acc: 92.19%\n",
      "Epoch 1 [889/938]  Loss: 0.1937  Acc: 92.19%\n",
      "Epoch 1 [890/938]  Loss: 0.3086  Acc: 90.62%\n",
      "Epoch 1 [891/938]  Loss: 0.1489  Acc: 95.31%\n",
      "Epoch 1 [892/938]  Loss: 0.2901  Acc: 93.75%\n",
      "Epoch 1 [893/938]  Loss: 0.2042  Acc: 96.88%\n",
      "Epoch 1 [894/938]  Loss: 0.2529  Acc: 92.19%\n",
      "Epoch 1 [895/938]  Loss: 0.1356  Acc: 95.31%\n",
      "Epoch 1 [896/938]  Loss: 0.1124  Acc: 95.31%\n",
      "Epoch 1 [897/938]  Loss: 0.2299  Acc: 92.19%\n",
      "Epoch 1 [898/938]  Loss: 0.1908  Acc: 92.19%\n",
      "Epoch 1 [899/938]  Loss: 0.1248  Acc: 96.88%\n",
      "Epoch 1 [900/938]  Loss: 0.1619  Acc: 93.75%\n",
      "Epoch 1 [901/938]  Loss: 0.0991  Acc: 98.44%\n",
      "Epoch 1 [902/938]  Loss: 0.1956  Acc: 92.19%\n",
      "Epoch 1 [903/938]  Loss: 0.1952  Acc: 95.31%\n",
      "Epoch 1 [904/938]  Loss: 0.1730  Acc: 93.75%\n",
      "Epoch 1 [905/938]  Loss: 0.0893  Acc: 96.88%\n",
      "Epoch 1 [906/938]  Loss: 0.3449  Acc: 90.62%\n",
      "Epoch 1 [907/938]  Loss: 0.1119  Acc: 96.88%\n",
      "Epoch 1 [908/938]  Loss: 0.1633  Acc: 95.31%\n",
      "Epoch 1 [909/938]  Loss: 0.3067  Acc: 89.06%\n",
      "Epoch 1 [910/938]  Loss: 0.1141  Acc: 95.31%\n",
      "Epoch 1 [911/938]  Loss: 0.2013  Acc: 95.31%\n",
      "Epoch 1 [912/938]  Loss: 0.1162  Acc: 95.31%\n",
      "Epoch 1 [913/938]  Loss: 0.1890  Acc: 93.75%\n",
      "Epoch 1 [914/938]  Loss: 0.1828  Acc: 93.75%\n",
      "Epoch 1 [915/938]  Loss: 0.2996  Acc: 95.31%\n",
      "Epoch 1 [916/938]  Loss: 0.1826  Acc: 93.75%\n",
      "Epoch 1 [917/938]  Loss: 0.1896  Acc: 92.19%\n",
      "Epoch 1 [918/938]  Loss: 0.1806  Acc: 96.88%\n",
      "Epoch 1 [919/938]  Loss: 0.1616  Acc: 95.31%\n",
      "Epoch 1 [920/938]  Loss: 0.1279  Acc: 96.88%\n",
      "Epoch 1 [921/938]  Loss: 0.2511  Acc: 92.19%\n",
      "Epoch 1 [922/938]  Loss: 0.1045  Acc: 95.31%\n",
      "Epoch 1 [923/938]  Loss: 0.2360  Acc: 89.06%\n",
      "Epoch 1 [924/938]  Loss: 0.3519  Acc: 93.75%\n",
      "Epoch 1 [925/938]  Loss: 0.0807  Acc: 98.44%\n",
      "Epoch 1 [926/938]  Loss: 0.1959  Acc: 90.62%\n",
      "Epoch 1 [927/938]  Loss: 0.2168  Acc: 95.31%\n",
      "Epoch 1 [928/938]  Loss: 0.1373  Acc: 93.75%\n",
      "Epoch 1 [929/938]  Loss: 0.1541  Acc: 95.31%\n",
      "Epoch 1 [930/938]  Loss: 0.2592  Acc: 93.75%\n",
      "Epoch 1 [931/938]  Loss: 0.1437  Acc: 96.88%\n",
      "Epoch 1 [932/938]  Loss: 0.0927  Acc: 95.31%\n",
      "Epoch 1 [933/938]  Loss: 0.1778  Acc: 95.31%\n",
      "Epoch 1 [934/938]  Loss: 0.2314  Acc: 90.62%\n",
      "Epoch 1 [935/938]  Loss: 0.2732  Acc: 90.62%\n",
      "Epoch 1 [936/938]  Loss: 0.1751  Acc: 93.75%\n",
      "Epoch 1 [937/938]  Loss: 0.0763  Acc: 100.00%\n",
      "Epoch 1 [938/938]  Loss: 0.0563  Acc: 100.00%\n",
      "Epoch 1 [925/938]  Loss: 0.0807  Acc: 98.44%\n",
      "Epoch 1 [926/938]  Loss: 0.1959  Acc: 90.62%\n",
      "Epoch 1 [927/938]  Loss: 0.2168  Acc: 95.31%\n",
      "Epoch 1 [928/938]  Loss: 0.1373  Acc: 93.75%\n",
      "Epoch 1 [929/938]  Loss: 0.1541  Acc: 95.31%\n",
      "Epoch 1 [930/938]  Loss: 0.2592  Acc: 93.75%\n",
      "Epoch 1 [931/938]  Loss: 0.1437  Acc: 96.88%\n",
      "Epoch 1 [932/938]  Loss: 0.0927  Acc: 95.31%\n",
      "Epoch 1 [933/938]  Loss: 0.1778  Acc: 95.31%\n",
      "Epoch 1 [934/938]  Loss: 0.2314  Acc: 90.62%\n",
      "Epoch 1 [935/938]  Loss: 0.2732  Acc: 90.62%\n",
      "Epoch 1 [936/938]  Loss: 0.1751  Acc: 93.75%\n",
      "Epoch 1 [937/938]  Loss: 0.0763  Acc: 100.00%\n",
      "Epoch 1 [938/938]  Loss: 0.0563  Acc: 100.00%\n",
      "\n",
      "Test set: Average loss: 0.1638, Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Epoch 1 finished in 13.3s\n",
      "\n",
      "Test set: Average loss: 0.1638, Accuracy: 9500/10000 (95.00%)\n",
      "\n",
      "Epoch 1 finished in 13.3s\n",
      "Epoch 2 [1/938]  Loss: 0.1607  Acc: 95.31%\n",
      "Epoch 2 [2/938]  Loss: 0.0472  Acc: 98.44%\n",
      "Epoch 2 [3/938]  Loss: 0.0999  Acc: 96.88%\n",
      "Epoch 2 [4/938]  Loss: 0.1434  Acc: 93.75%\n",
      "Epoch 2 [5/938]  Loss: 0.3639  Acc: 92.19%\n",
      "Epoch 2 [6/938]  Loss: 0.2003  Acc: 93.75%\n",
      "Epoch 2 [7/938]  Loss: 0.2001  Acc: 96.88%\n",
      "Epoch 2 [8/938]  Loss: 0.1716  Acc: 92.19%\n",
      "Epoch 2 [9/938]  Loss: 0.3775  Acc: 89.06%\n",
      "Epoch 2 [10/938]  Loss: 0.2249  Acc: 92.19%\n",
      "Epoch 2 [11/938]  Loss: 0.0911  Acc: 96.88%\n",
      "Epoch 2 [12/938]  Loss: 0.1663  Acc: 92.19%\n",
      "Epoch 2 [13/938]  Loss: 0.1891  Acc: 93.75%\n",
      "Epoch 2 [14/938]  Loss: 0.1449  Acc: 96.88%\n",
      "Epoch 2 [15/938]  Loss: 0.1531  Acc: 92.19%\n",
      "Epoch 2 [16/938]  Loss: 0.2386  Acc: 92.19%\n",
      "Epoch 2 [17/938]  Loss: 0.0483  Acc: 100.00%\n",
      "Epoch 2 [18/938]  Loss: 0.1704  Acc: 90.62%\n",
      "Epoch 2 [19/938]  Loss: 0.1663  Acc: 92.19%\n",
      "Epoch 2 [20/938]  Loss: 0.1711  Acc: 95.31%\n",
      "Epoch 2 [21/938]  Loss: 0.2538  Acc: 93.75%\n",
      "Epoch 2 [22/938]  Loss: 0.1992  Acc: 96.88%\n",
      "Epoch 2 [23/938]  Loss: 0.2117  Acc: 92.19%\n",
      "Epoch 2 [1/938]  Loss: 0.1607  Acc: 95.31%\n",
      "Epoch 2 [2/938]  Loss: 0.0472  Acc: 98.44%\n",
      "Epoch 2 [3/938]  Loss: 0.0999  Acc: 96.88%\n",
      "Epoch 2 [4/938]  Loss: 0.1434  Acc: 93.75%\n",
      "Epoch 2 [5/938]  Loss: 0.3639  Acc: 92.19%\n",
      "Epoch 2 [6/938]  Loss: 0.2003  Acc: 93.75%\n",
      "Epoch 2 [7/938]  Loss: 0.2001  Acc: 96.88%\n",
      "Epoch 2 [8/938]  Loss: 0.1716  Acc: 92.19%\n",
      "Epoch 2 [9/938]  Loss: 0.3775  Acc: 89.06%\n",
      "Epoch 2 [10/938]  Loss: 0.2249  Acc: 92.19%\n",
      "Epoch 2 [11/938]  Loss: 0.0911  Acc: 96.88%\n",
      "Epoch 2 [12/938]  Loss: 0.1663  Acc: 92.19%\n",
      "Epoch 2 [13/938]  Loss: 0.1891  Acc: 93.75%\n",
      "Epoch 2 [14/938]  Loss: 0.1449  Acc: 96.88%\n",
      "Epoch 2 [15/938]  Loss: 0.1531  Acc: 92.19%\n",
      "Epoch 2 [16/938]  Loss: 0.2386  Acc: 92.19%\n",
      "Epoch 2 [17/938]  Loss: 0.0483  Acc: 100.00%\n",
      "Epoch 2 [18/938]  Loss: 0.1704  Acc: 90.62%\n",
      "Epoch 2 [19/938]  Loss: 0.1663  Acc: 92.19%\n",
      "Epoch 2 [20/938]  Loss: 0.1711  Acc: 95.31%\n",
      "Epoch 2 [21/938]  Loss: 0.2538  Acc: 93.75%\n",
      "Epoch 2 [22/938]  Loss: 0.1992  Acc: 96.88%\n",
      "Epoch 2 [23/938]  Loss: 0.2117  Acc: 92.19%\n",
      "Epoch 2 [24/938]  Loss: 0.0562  Acc: 98.44%\n",
      "Epoch 2 [25/938]  Loss: 0.1818  Acc: 95.31%\n",
      "Epoch 2 [26/938]  Loss: 0.1045  Acc: 96.88%\n",
      "Epoch 2 [27/938]  Loss: 0.1709  Acc: 95.31%\n",
      "Epoch 2 [28/938]  Loss: 0.2518  Acc: 93.75%\n",
      "Epoch 2 [29/938]  Loss: 0.1521  Acc: 95.31%\n",
      "Epoch 2 [30/938]  Loss: 0.1357  Acc: 95.31%\n",
      "Epoch 2 [31/938]  Loss: 0.1969  Acc: 93.75%\n",
      "Epoch 2 [32/938]  Loss: 0.2581  Acc: 92.19%\n",
      "Epoch 2 [33/938]  Loss: 0.1635  Acc: 95.31%\n",
      "Epoch 2 [34/938]  Loss: 0.0912  Acc: 96.88%\n",
      "Epoch 2 [35/938]  Loss: 0.1256  Acc: 96.88%\n",
      "Epoch 2 [36/938]  Loss: 0.3368  Acc: 87.50%\n",
      "Epoch 2 [37/938]  Loss: 0.1012  Acc: 98.44%\n",
      "Epoch 2 [38/938]  Loss: 0.0548  Acc: 100.00%\n",
      "Epoch 2 [39/938]  Loss: 0.1613  Acc: 93.75%\n",
      "Epoch 2 [40/938]  Loss: 0.2577  Acc: 95.31%\n",
      "Epoch 2 [41/938]  Loss: 0.0838  Acc: 96.88%\n",
      "Epoch 2 [42/938]  Loss: 0.0511  Acc: 100.00%\n",
      "Epoch 2 [43/938]  Loss: 0.2042  Acc: 95.31%\n",
      "Epoch 2 [44/938]  Loss: 0.1474  Acc: 93.75%\n",
      "Epoch 2 [45/938]  Loss: 0.2400  Acc: 92.19%\n",
      "Epoch 2 [46/938]  Loss: 0.2376  Acc: 93.75%\n",
      "Epoch 2 [47/938]  Loss: 0.1368  Acc: 98.44%\n",
      "Epoch 2 [48/938]  Loss: 0.1387  Acc: 93.75%\n",
      "Epoch 2 [49/938]  Loss: 0.1106  Acc: 95.31%\n",
      "Epoch 2 [50/938]  Loss: 0.1529  Acc: 92.19%\n",
      "Epoch 2 [51/938]  Loss: 0.1962  Acc: 95.31%\n",
      "Epoch 2 [52/938]  Loss: 0.1447  Acc: 95.31%\n",
      "Epoch 2 [53/938]  Loss: 0.0637  Acc: 98.44%\n",
      "Epoch 2 [54/938]  Loss: 0.0863  Acc: 96.88%\n",
      "Epoch 2 [55/938]  Loss: 0.1337  Acc: 95.31%\n",
      "Epoch 2 [56/938]  Loss: 0.1151  Acc: 95.31%\n",
      "Epoch 2 [57/938]  Loss: 0.0775  Acc: 100.00%\n",
      "Epoch 2 [58/938]  Loss: 0.1471  Acc: 96.88%\n",
      "Epoch 2 [59/938]  Loss: 0.1598  Acc: 95.31%\n",
      "Epoch 2 [60/938]  Loss: 0.0911  Acc: 98.44%\n",
      "Epoch 2 [61/938]  Loss: 0.2698  Acc: 93.75%\n",
      "Epoch 2 [62/938]  Loss: 0.0669  Acc: 100.00%\n",
      "Epoch 2 [63/938]  Loss: 0.2115  Acc: 92.19%\n",
      "Epoch 2 [64/938]  Loss: 0.0872  Acc: 98.44%\n",
      "Epoch 2 [65/938]  Loss: 0.3392  Acc: 92.19%\n",
      "Epoch 2 [66/938]  Loss: 0.0846  Acc: 96.88%\n",
      "Epoch 2 [67/938]  Loss: 0.2494  Acc: 90.62%\n",
      "Epoch 2 [68/938]  Loss: 0.2785  Acc: 92.19%\n",
      "Epoch 2 [69/938]  Loss: 0.1019  Acc: 95.31%\n",
      "Epoch 2 [70/938]  Loss: 0.2164  Acc: 90.62%\n",
      "Epoch 2 [71/938]  Loss: 0.2139  Acc: 96.88%\n",
      "Epoch 2 [72/938]  Loss: 0.1058  Acc: 98.44%\n",
      "Epoch 2 [73/938]  Loss: 0.1800  Acc: 90.62%\n",
      "Epoch 2 [74/938]  Loss: 0.2091  Acc: 95.31%\n",
      "Epoch 2 [75/938]  Loss: 0.1397  Acc: 96.88%\n",
      "Epoch 2 [76/938]  Loss: 0.1310  Acc: 98.44%\n",
      "Epoch 2 [77/938]  Loss: 0.0819  Acc: 98.44%\n",
      "Epoch 2 [78/938]  Loss: 0.1588  Acc: 95.31%\n",
      "Epoch 2 [79/938]  Loss: 0.2848  Acc: 92.19%\n",
      "Epoch 2 [80/938]  Loss: 0.1673  Acc: 93.75%\n",
      "Epoch 2 [81/938]  Loss: 0.1088  Acc: 95.31%\n",
      "Epoch 2 [82/938]  Loss: 0.0785  Acc: 100.00%\n",
      "Epoch 2 [83/938]  Loss: 0.0757  Acc: 98.44%\n",
      "Epoch 2 [84/938]  Loss: 0.1022  Acc: 98.44%\n",
      "Epoch 2 [85/938]  Loss: 0.2121  Acc: 92.19%\n",
      "Epoch 2 [86/938]  Loss: 0.0825  Acc: 98.44%\n",
      "Epoch 2 [87/938]  Loss: 0.1910  Acc: 95.31%\n",
      "Epoch 2 [88/938]  Loss: 0.1366  Acc: 96.88%\n",
      "Epoch 2 [24/938]  Loss: 0.0562  Acc: 98.44%\n",
      "Epoch 2 [25/938]  Loss: 0.1818  Acc: 95.31%\n",
      "Epoch 2 [26/938]  Loss: 0.1045  Acc: 96.88%\n",
      "Epoch 2 [27/938]  Loss: 0.1709  Acc: 95.31%\n",
      "Epoch 2 [28/938]  Loss: 0.2518  Acc: 93.75%\n",
      "Epoch 2 [29/938]  Loss: 0.1521  Acc: 95.31%\n",
      "Epoch 2 [30/938]  Loss: 0.1357  Acc: 95.31%\n",
      "Epoch 2 [31/938]  Loss: 0.1969  Acc: 93.75%\n",
      "Epoch 2 [32/938]  Loss: 0.2581  Acc: 92.19%\n",
      "Epoch 2 [33/938]  Loss: 0.1635  Acc: 95.31%\n",
      "Epoch 2 [34/938]  Loss: 0.0912  Acc: 96.88%\n",
      "Epoch 2 [35/938]  Loss: 0.1256  Acc: 96.88%\n",
      "Epoch 2 [36/938]  Loss: 0.3368  Acc: 87.50%\n",
      "Epoch 2 [37/938]  Loss: 0.1012  Acc: 98.44%\n",
      "Epoch 2 [38/938]  Loss: 0.0548  Acc: 100.00%\n",
      "Epoch 2 [39/938]  Loss: 0.1613  Acc: 93.75%\n",
      "Epoch 2 [40/938]  Loss: 0.2577  Acc: 95.31%\n",
      "Epoch 2 [41/938]  Loss: 0.0838  Acc: 96.88%\n",
      "Epoch 2 [42/938]  Loss: 0.0511  Acc: 100.00%\n",
      "Epoch 2 [43/938]  Loss: 0.2042  Acc: 95.31%\n",
      "Epoch 2 [44/938]  Loss: 0.1474  Acc: 93.75%\n",
      "Epoch 2 [45/938]  Loss: 0.2400  Acc: 92.19%\n",
      "Epoch 2 [46/938]  Loss: 0.2376  Acc: 93.75%\n",
      "Epoch 2 [47/938]  Loss: 0.1368  Acc: 98.44%\n",
      "Epoch 2 [48/938]  Loss: 0.1387  Acc: 93.75%\n",
      "Epoch 2 [49/938]  Loss: 0.1106  Acc: 95.31%\n",
      "Epoch 2 [50/938]  Loss: 0.1529  Acc: 92.19%\n",
      "Epoch 2 [51/938]  Loss: 0.1962  Acc: 95.31%\n",
      "Epoch 2 [52/938]  Loss: 0.1447  Acc: 95.31%\n",
      "Epoch 2 [53/938]  Loss: 0.0637  Acc: 98.44%\n",
      "Epoch 2 [54/938]  Loss: 0.0863  Acc: 96.88%\n",
      "Epoch 2 [55/938]  Loss: 0.1337  Acc: 95.31%\n",
      "Epoch 2 [56/938]  Loss: 0.1151  Acc: 95.31%\n",
      "Epoch 2 [57/938]  Loss: 0.0775  Acc: 100.00%\n",
      "Epoch 2 [58/938]  Loss: 0.1471  Acc: 96.88%\n",
      "Epoch 2 [59/938]  Loss: 0.1598  Acc: 95.31%\n",
      "Epoch 2 [60/938]  Loss: 0.0911  Acc: 98.44%\n",
      "Epoch 2 [61/938]  Loss: 0.2698  Acc: 93.75%\n",
      "Epoch 2 [62/938]  Loss: 0.0669  Acc: 100.00%\n",
      "Epoch 2 [63/938]  Loss: 0.2115  Acc: 92.19%\n",
      "Epoch 2 [64/938]  Loss: 0.0872  Acc: 98.44%\n",
      "Epoch 2 [65/938]  Loss: 0.3392  Acc: 92.19%\n",
      "Epoch 2 [66/938]  Loss: 0.0846  Acc: 96.88%\n",
      "Epoch 2 [67/938]  Loss: 0.2494  Acc: 90.62%\n",
      "Epoch 2 [68/938]  Loss: 0.2785  Acc: 92.19%\n",
      "Epoch 2 [69/938]  Loss: 0.1019  Acc: 95.31%\n",
      "Epoch 2 [70/938]  Loss: 0.2164  Acc: 90.62%\n",
      "Epoch 2 [71/938]  Loss: 0.2139  Acc: 96.88%\n",
      "Epoch 2 [72/938]  Loss: 0.1058  Acc: 98.44%\n",
      "Epoch 2 [73/938]  Loss: 0.1800  Acc: 90.62%\n",
      "Epoch 2 [74/938]  Loss: 0.2091  Acc: 95.31%\n",
      "Epoch 2 [75/938]  Loss: 0.1397  Acc: 96.88%\n",
      "Epoch 2 [76/938]  Loss: 0.1310  Acc: 98.44%\n",
      "Epoch 2 [77/938]  Loss: 0.0819  Acc: 98.44%\n",
      "Epoch 2 [78/938]  Loss: 0.1588  Acc: 95.31%\n",
      "Epoch 2 [79/938]  Loss: 0.2848  Acc: 92.19%\n",
      "Epoch 2 [80/938]  Loss: 0.1673  Acc: 93.75%\n",
      "Epoch 2 [81/938]  Loss: 0.1088  Acc: 95.31%\n",
      "Epoch 2 [82/938]  Loss: 0.0785  Acc: 100.00%\n",
      "Epoch 2 [83/938]  Loss: 0.0757  Acc: 98.44%\n",
      "Epoch 2 [84/938]  Loss: 0.1022  Acc: 98.44%\n",
      "Epoch 2 [85/938]  Loss: 0.2121  Acc: 92.19%\n",
      "Epoch 2 [86/938]  Loss: 0.0825  Acc: 98.44%\n",
      "Epoch 2 [87/938]  Loss: 0.1910  Acc: 95.31%\n",
      "Epoch 2 [88/938]  Loss: 0.1366  Acc: 96.88%\n",
      "Epoch 2 [89/938]  Loss: 0.0839  Acc: 98.44%\n",
      "Epoch 2 [90/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [91/938]  Loss: 0.1437  Acc: 98.44%\n",
      "Epoch 2 [92/938]  Loss: 0.1906  Acc: 92.19%\n",
      "Epoch 2 [93/938]  Loss: 0.2100  Acc: 92.19%\n",
      "Epoch 2 [94/938]  Loss: 0.1258  Acc: 95.31%\n",
      "Epoch 2 [95/938]  Loss: 0.0984  Acc: 98.44%\n",
      "Epoch 2 [96/938]  Loss: 0.2641  Acc: 90.62%\n",
      "Epoch 2 [97/938]  Loss: 0.0536  Acc: 100.00%\n",
      "Epoch 2 [98/938]  Loss: 0.1551  Acc: 95.31%\n",
      "Epoch 2 [99/938]  Loss: 0.1354  Acc: 95.31%\n",
      "Epoch 2 [100/938]  Loss: 0.1976  Acc: 92.19%\n",
      "Epoch 2 [101/938]  Loss: 0.1482  Acc: 93.75%\n",
      "Epoch 2 [102/938]  Loss: 0.3049  Acc: 90.62%\n",
      "Epoch 2 [103/938]  Loss: 0.1630  Acc: 96.88%\n",
      "Epoch 2 [104/938]  Loss: 0.1748  Acc: 95.31%\n",
      "Epoch 2 [105/938]  Loss: 0.1799  Acc: 93.75%\n",
      "Epoch 2 [106/938]  Loss: 0.0948  Acc: 98.44%\n",
      "Epoch 2 [107/938]  Loss: 0.0855  Acc: 96.88%\n",
      "Epoch 2 [108/938]  Loss: 0.1843  Acc: 92.19%\n",
      "Epoch 2 [109/938]  Loss: 0.0596  Acc: 98.44%\n",
      "Epoch 2 [110/938]  Loss: 0.1395  Acc: 95.31%\n",
      "Epoch 2 [111/938]  Loss: 0.0947  Acc: 96.88%\n",
      "Epoch 2 [112/938]  Loss: 0.1445  Acc: 93.75%\n",
      "Epoch 2 [113/938]  Loss: 0.3037  Acc: 84.38%\n",
      "Epoch 2 [114/938]  Loss: 0.1361  Acc: 95.31%\n",
      "Epoch 2 [115/938]  Loss: 0.3711  Acc: 90.62%\n",
      "Epoch 2 [116/938]  Loss: 0.1553  Acc: 93.75%\n",
      "Epoch 2 [117/938]  Loss: 0.1961  Acc: 95.31%\n",
      "Epoch 2 [118/938]  Loss: 0.1649  Acc: 93.75%\n",
      "Epoch 2 [119/938]  Loss: 0.2433  Acc: 89.06%\n",
      "Epoch 2 [120/938]  Loss: 0.2404  Acc: 92.19%\n",
      "Epoch 2 [121/938]  Loss: 0.3038  Acc: 89.06%\n",
      "Epoch 2 [122/938]  Loss: 0.1251  Acc: 95.31%\n",
      "Epoch 2 [123/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [124/938]  Loss: 0.1538  Acc: 98.44%\n",
      "Epoch 2 [125/938]  Loss: 0.1087  Acc: 96.88%\n",
      "Epoch 2 [126/938]  Loss: 0.0706  Acc: 96.88%\n",
      "Epoch 2 [127/938]  Loss: 0.1309  Acc: 96.88%\n",
      "Epoch 2 [128/938]  Loss: 0.2135  Acc: 93.75%\n",
      "Epoch 2 [129/938]  Loss: 0.1199  Acc: 95.31%\n",
      "Epoch 2 [130/938]  Loss: 0.1528  Acc: 95.31%\n",
      "Epoch 2 [131/938]  Loss: 0.1160  Acc: 96.88%\n",
      "Epoch 2 [132/938]  Loss: 0.1120  Acc: 98.44%\n",
      "Epoch 2 [133/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [134/938]  Loss: 0.1839  Acc: 95.31%\n",
      "Epoch 2 [135/938]  Loss: 0.0432  Acc: 100.00%\n",
      "Epoch 2 [136/938]  Loss: 0.2329  Acc: 90.62%\n",
      "Epoch 2 [137/938]  Loss: 0.2123  Acc: 93.75%\n",
      "Epoch 2 [138/938]  Loss: 0.1273  Acc: 96.88%\n",
      "Epoch 2 [139/938]  Loss: 0.3285  Acc: 95.31%\n",
      "Epoch 2 [140/938]  Loss: 0.0937  Acc: 96.88%\n",
      "Epoch 2 [141/938]  Loss: 0.2082  Acc: 96.88%\n",
      "Epoch 2 [142/938]  Loss: 0.2339  Acc: 95.31%\n",
      "Epoch 2 [143/938]  Loss: 0.1358  Acc: 95.31%\n",
      "Epoch 2 [144/938]  Loss: 0.0840  Acc: 96.88%\n",
      "Epoch 2 [145/938]  Loss: 0.1627  Acc: 95.31%\n",
      "Epoch 2 [89/938]  Loss: 0.0839  Acc: 98.44%\n",
      "Epoch 2 [90/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [91/938]  Loss: 0.1437  Acc: 98.44%\n",
      "Epoch 2 [92/938]  Loss: 0.1906  Acc: 92.19%\n",
      "Epoch 2 [93/938]  Loss: 0.2100  Acc: 92.19%\n",
      "Epoch 2 [94/938]  Loss: 0.1258  Acc: 95.31%\n",
      "Epoch 2 [95/938]  Loss: 0.0984  Acc: 98.44%\n",
      "Epoch 2 [96/938]  Loss: 0.2641  Acc: 90.62%\n",
      "Epoch 2 [97/938]  Loss: 0.0536  Acc: 100.00%\n",
      "Epoch 2 [98/938]  Loss: 0.1551  Acc: 95.31%\n",
      "Epoch 2 [99/938]  Loss: 0.1354  Acc: 95.31%\n",
      "Epoch 2 [100/938]  Loss: 0.1976  Acc: 92.19%\n",
      "Epoch 2 [101/938]  Loss: 0.1482  Acc: 93.75%\n",
      "Epoch 2 [102/938]  Loss: 0.3049  Acc: 90.62%\n",
      "Epoch 2 [103/938]  Loss: 0.1630  Acc: 96.88%\n",
      "Epoch 2 [104/938]  Loss: 0.1748  Acc: 95.31%\n",
      "Epoch 2 [105/938]  Loss: 0.1799  Acc: 93.75%\n",
      "Epoch 2 [106/938]  Loss: 0.0948  Acc: 98.44%\n",
      "Epoch 2 [107/938]  Loss: 0.0855  Acc: 96.88%\n",
      "Epoch 2 [108/938]  Loss: 0.1843  Acc: 92.19%\n",
      "Epoch 2 [109/938]  Loss: 0.0596  Acc: 98.44%\n",
      "Epoch 2 [110/938]  Loss: 0.1395  Acc: 95.31%\n",
      "Epoch 2 [111/938]  Loss: 0.0947  Acc: 96.88%\n",
      "Epoch 2 [112/938]  Loss: 0.1445  Acc: 93.75%\n",
      "Epoch 2 [113/938]  Loss: 0.3037  Acc: 84.38%\n",
      "Epoch 2 [114/938]  Loss: 0.1361  Acc: 95.31%\n",
      "Epoch 2 [115/938]  Loss: 0.3711  Acc: 90.62%\n",
      "Epoch 2 [116/938]  Loss: 0.1553  Acc: 93.75%\n",
      "Epoch 2 [117/938]  Loss: 0.1961  Acc: 95.31%\n",
      "Epoch 2 [118/938]  Loss: 0.1649  Acc: 93.75%\n",
      "Epoch 2 [119/938]  Loss: 0.2433  Acc: 89.06%\n",
      "Epoch 2 [120/938]  Loss: 0.2404  Acc: 92.19%\n",
      "Epoch 2 [121/938]  Loss: 0.3038  Acc: 89.06%\n",
      "Epoch 2 [122/938]  Loss: 0.1251  Acc: 95.31%\n",
      "Epoch 2 [123/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [124/938]  Loss: 0.1538  Acc: 98.44%\n",
      "Epoch 2 [125/938]  Loss: 0.1087  Acc: 96.88%\n",
      "Epoch 2 [126/938]  Loss: 0.0706  Acc: 96.88%\n",
      "Epoch 2 [127/938]  Loss: 0.1309  Acc: 96.88%\n",
      "Epoch 2 [128/938]  Loss: 0.2135  Acc: 93.75%\n",
      "Epoch 2 [129/938]  Loss: 0.1199  Acc: 95.31%\n",
      "Epoch 2 [130/938]  Loss: 0.1528  Acc: 95.31%\n",
      "Epoch 2 [131/938]  Loss: 0.1160  Acc: 96.88%\n",
      "Epoch 2 [132/938]  Loss: 0.1120  Acc: 98.44%\n",
      "Epoch 2 [133/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [134/938]  Loss: 0.1839  Acc: 95.31%\n",
      "Epoch 2 [135/938]  Loss: 0.0432  Acc: 100.00%\n",
      "Epoch 2 [136/938]  Loss: 0.2329  Acc: 90.62%\n",
      "Epoch 2 [137/938]  Loss: 0.2123  Acc: 93.75%\n",
      "Epoch 2 [138/938]  Loss: 0.1273  Acc: 96.88%\n",
      "Epoch 2 [139/938]  Loss: 0.3285  Acc: 95.31%\n",
      "Epoch 2 [140/938]  Loss: 0.0937  Acc: 96.88%\n",
      "Epoch 2 [141/938]  Loss: 0.2082  Acc: 96.88%\n",
      "Epoch 2 [142/938]  Loss: 0.2339  Acc: 95.31%\n",
      "Epoch 2 [143/938]  Loss: 0.1358  Acc: 95.31%\n",
      "Epoch 2 [144/938]  Loss: 0.0840  Acc: 96.88%\n",
      "Epoch 2 [145/938]  Loss: 0.1627  Acc: 95.31%\n",
      "Epoch 2 [146/938]  Loss: 0.1622  Acc: 90.62%\n",
      "Epoch 2 [147/938]  Loss: 0.1428  Acc: 95.31%\n",
      "Epoch 2 [148/938]  Loss: 0.1523  Acc: 95.31%\n",
      "Epoch 2 [149/938]  Loss: 0.1419  Acc: 96.88%\n",
      "Epoch 2 [150/938]  Loss: 0.1145  Acc: 98.44%\n",
      "Epoch 2 [151/938]  Loss: 0.0934  Acc: 96.88%\n",
      "Epoch 2 [152/938]  Loss: 0.0410  Acc: 98.44%\n",
      "Epoch 2 [153/938]  Loss: 0.2605  Acc: 93.75%\n",
      "Epoch 2 [154/938]  Loss: 0.1895  Acc: 92.19%\n",
      "Epoch 2 [155/938]  Loss: 0.2701  Acc: 90.62%\n",
      "Epoch 2 [156/938]  Loss: 0.1700  Acc: 95.31%\n",
      "Epoch 2 [157/938]  Loss: 0.3126  Acc: 87.50%\n",
      "Epoch 2 [158/938]  Loss: 0.0661  Acc: 100.00%\n",
      "Epoch 2 [159/938]  Loss: 0.1485  Acc: 93.75%\n",
      "Epoch 2 [160/938]  Loss: 0.1384  Acc: 93.75%\n",
      "Epoch 2 [161/938]  Loss: 0.1446  Acc: 95.31%\n",
      "Epoch 2 [162/938]  Loss: 0.1717  Acc: 95.31%\n",
      "Epoch 2 [163/938]  Loss: 0.1865  Acc: 93.75%\n",
      "Epoch 2 [164/938]  Loss: 0.1448  Acc: 93.75%\n",
      "Epoch 2 [165/938]  Loss: 0.1755  Acc: 96.88%\n",
      "Epoch 2 [166/938]  Loss: 0.3469  Acc: 90.62%\n",
      "Epoch 2 [167/938]  Loss: 0.2319  Acc: 90.62%\n",
      "Epoch 2 [168/938]  Loss: 0.1673  Acc: 92.19%\n",
      "Epoch 2 [169/938]  Loss: 0.2064  Acc: 92.19%\n",
      "Epoch 2 [170/938]  Loss: 0.0486  Acc: 98.44%\n",
      "Epoch 2 [171/938]  Loss: 0.1700  Acc: 96.88%\n",
      "Epoch 2 [172/938]  Loss: 0.0712  Acc: 98.44%\n",
      "Epoch 2 [173/938]  Loss: 0.2507  Acc: 90.62%\n",
      "Epoch 2 [174/938]  Loss: 0.1008  Acc: 96.88%\n",
      "Epoch 2 [175/938]  Loss: 0.0471  Acc: 98.44%\n",
      "Epoch 2 [176/938]  Loss: 0.1524  Acc: 92.19%\n",
      "Epoch 2 [177/938]  Loss: 0.0591  Acc: 98.44%\n",
      "Epoch 2 [178/938]  Loss: 0.1041  Acc: 95.31%\n",
      "Epoch 2 [179/938]  Loss: 0.0953  Acc: 95.31%\n",
      "Epoch 2 [180/938]  Loss: 0.1538  Acc: 95.31%\n",
      "Epoch 2 [181/938]  Loss: 0.0552  Acc: 98.44%\n",
      "Epoch 2 [182/938]  Loss: 0.1791  Acc: 92.19%\n",
      "Epoch 2 [183/938]  Loss: 0.0690  Acc: 98.44%\n",
      "Epoch 2 [184/938]  Loss: 0.1480  Acc: 93.75%\n",
      "Epoch 2 [185/938]  Loss: 0.1303  Acc: 95.31%\n",
      "Epoch 2 [186/938]  Loss: 0.1249  Acc: 93.75%\n",
      "Epoch 2 [187/938]  Loss: 0.1706  Acc: 93.75%\n",
      "Epoch 2 [188/938]  Loss: 0.1149  Acc: 96.88%\n",
      "Epoch 2 [189/938]  Loss: 0.1054  Acc: 96.88%\n",
      "Epoch 2 [190/938]  Loss: 0.1213  Acc: 93.75%\n",
      "Epoch 2 [191/938]  Loss: 0.0642  Acc: 98.44%\n",
      "Epoch 2 [192/938]  Loss: 0.2127  Acc: 92.19%\n",
      "Epoch 2 [193/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [194/938]  Loss: 0.1317  Acc: 96.88%\n",
      "Epoch 2 [195/938]  Loss: 0.0590  Acc: 98.44%\n",
      "Epoch 2 [196/938]  Loss: 0.2456  Acc: 95.31%\n",
      "Epoch 2 [197/938]  Loss: 0.1023  Acc: 96.88%\n",
      "Epoch 2 [198/938]  Loss: 0.2021  Acc: 93.75%\n",
      "Epoch 2 [199/938]  Loss: 0.0985  Acc: 100.00%\n",
      "Epoch 2 [146/938]  Loss: 0.1622  Acc: 90.62%\n",
      "Epoch 2 [147/938]  Loss: 0.1428  Acc: 95.31%\n",
      "Epoch 2 [148/938]  Loss: 0.1523  Acc: 95.31%\n",
      "Epoch 2 [149/938]  Loss: 0.1419  Acc: 96.88%\n",
      "Epoch 2 [150/938]  Loss: 0.1145  Acc: 98.44%\n",
      "Epoch 2 [151/938]  Loss: 0.0934  Acc: 96.88%\n",
      "Epoch 2 [152/938]  Loss: 0.0410  Acc: 98.44%\n",
      "Epoch 2 [153/938]  Loss: 0.2605  Acc: 93.75%\n",
      "Epoch 2 [154/938]  Loss: 0.1895  Acc: 92.19%\n",
      "Epoch 2 [155/938]  Loss: 0.2701  Acc: 90.62%\n",
      "Epoch 2 [156/938]  Loss: 0.1700  Acc: 95.31%\n",
      "Epoch 2 [157/938]  Loss: 0.3126  Acc: 87.50%\n",
      "Epoch 2 [158/938]  Loss: 0.0661  Acc: 100.00%\n",
      "Epoch 2 [159/938]  Loss: 0.1485  Acc: 93.75%\n",
      "Epoch 2 [160/938]  Loss: 0.1384  Acc: 93.75%\n",
      "Epoch 2 [161/938]  Loss: 0.1446  Acc: 95.31%\n",
      "Epoch 2 [162/938]  Loss: 0.1717  Acc: 95.31%\n",
      "Epoch 2 [163/938]  Loss: 0.1865  Acc: 93.75%\n",
      "Epoch 2 [164/938]  Loss: 0.1448  Acc: 93.75%\n",
      "Epoch 2 [165/938]  Loss: 0.1755  Acc: 96.88%\n",
      "Epoch 2 [166/938]  Loss: 0.3469  Acc: 90.62%\n",
      "Epoch 2 [167/938]  Loss: 0.2319  Acc: 90.62%\n",
      "Epoch 2 [168/938]  Loss: 0.1673  Acc: 92.19%\n",
      "Epoch 2 [169/938]  Loss: 0.2064  Acc: 92.19%\n",
      "Epoch 2 [170/938]  Loss: 0.0486  Acc: 98.44%\n",
      "Epoch 2 [171/938]  Loss: 0.1700  Acc: 96.88%\n",
      "Epoch 2 [172/938]  Loss: 0.0712  Acc: 98.44%\n",
      "Epoch 2 [173/938]  Loss: 0.2507  Acc: 90.62%\n",
      "Epoch 2 [174/938]  Loss: 0.1008  Acc: 96.88%\n",
      "Epoch 2 [175/938]  Loss: 0.0471  Acc: 98.44%\n",
      "Epoch 2 [176/938]  Loss: 0.1524  Acc: 92.19%\n",
      "Epoch 2 [177/938]  Loss: 0.0591  Acc: 98.44%\n",
      "Epoch 2 [178/938]  Loss: 0.1041  Acc: 95.31%\n",
      "Epoch 2 [179/938]  Loss: 0.0953  Acc: 95.31%\n",
      "Epoch 2 [180/938]  Loss: 0.1538  Acc: 95.31%\n",
      "Epoch 2 [181/938]  Loss: 0.0552  Acc: 98.44%\n",
      "Epoch 2 [182/938]  Loss: 0.1791  Acc: 92.19%\n",
      "Epoch 2 [183/938]  Loss: 0.0690  Acc: 98.44%\n",
      "Epoch 2 [184/938]  Loss: 0.1480  Acc: 93.75%\n",
      "Epoch 2 [185/938]  Loss: 0.1303  Acc: 95.31%\n",
      "Epoch 2 [186/938]  Loss: 0.1249  Acc: 93.75%\n",
      "Epoch 2 [187/938]  Loss: 0.1706  Acc: 93.75%\n",
      "Epoch 2 [188/938]  Loss: 0.1149  Acc: 96.88%\n",
      "Epoch 2 [189/938]  Loss: 0.1054  Acc: 96.88%\n",
      "Epoch 2 [190/938]  Loss: 0.1213  Acc: 93.75%\n",
      "Epoch 2 [191/938]  Loss: 0.0642  Acc: 98.44%\n",
      "Epoch 2 [192/938]  Loss: 0.2127  Acc: 92.19%\n",
      "Epoch 2 [193/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [194/938]  Loss: 0.1317  Acc: 96.88%\n",
      "Epoch 2 [195/938]  Loss: 0.0590  Acc: 98.44%\n",
      "Epoch 2 [196/938]  Loss: 0.2456  Acc: 95.31%\n",
      "Epoch 2 [197/938]  Loss: 0.1023  Acc: 96.88%\n",
      "Epoch 2 [198/938]  Loss: 0.2021  Acc: 93.75%\n",
      "Epoch 2 [199/938]  Loss: 0.0985  Acc: 100.00%\n",
      "Epoch 2 [200/938]  Loss: 0.0909  Acc: 98.44%\n",
      "Epoch 2 [201/938]  Loss: 0.1281  Acc: 96.88%\n",
      "Epoch 2 [202/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [203/938]  Loss: 0.0790  Acc: 98.44%\n",
      "Epoch 2 [204/938]  Loss: 0.0978  Acc: 98.44%\n",
      "Epoch 2 [205/938]  Loss: 0.0681  Acc: 96.88%\n",
      "Epoch 2 [206/938]  Loss: 0.1637  Acc: 95.31%\n",
      "Epoch 2 [207/938]  Loss: 0.1302  Acc: 95.31%\n",
      "Epoch 2 [208/938]  Loss: 0.0323  Acc: 100.00%\n",
      "Epoch 2 [209/938]  Loss: 0.0694  Acc: 98.44%\n",
      "Epoch 2 [210/938]  Loss: 0.0838  Acc: 98.44%\n",
      "Epoch 2 [211/938]  Loss: 0.1907  Acc: 93.75%\n",
      "Epoch 2 [212/938]  Loss: 0.0476  Acc: 100.00%\n",
      "Epoch 2 [213/938]  Loss: 0.0543  Acc: 98.44%\n",
      "Epoch 2 [214/938]  Loss: 0.1528  Acc: 92.19%\n",
      "Epoch 2 [215/938]  Loss: 0.0958  Acc: 96.88%\n",
      "Epoch 2 [216/938]  Loss: 0.1330  Acc: 95.31%\n",
      "Epoch 2 [217/938]  Loss: 0.2246  Acc: 95.31%\n",
      "Epoch 2 [218/938]  Loss: 0.1193  Acc: 98.44%\n",
      "Epoch 2 [219/938]  Loss: 0.1751  Acc: 93.75%\n",
      "Epoch 2 [220/938]  Loss: 0.1856  Acc: 95.31%\n",
      "Epoch 2 [221/938]  Loss: 0.1528  Acc: 95.31%\n",
      "Epoch 2 [222/938]  Loss: 0.1049  Acc: 96.88%\n",
      "Epoch 2 [223/938]  Loss: 0.0573  Acc: 100.00%\n",
      "Epoch 2 [224/938]  Loss: 0.1122  Acc: 96.88%\n",
      "Epoch 2 [225/938]  Loss: 0.0500  Acc: 98.44%\n",
      "Epoch 2 [226/938]  Loss: 0.1700  Acc: 95.31%\n",
      "Epoch 2 [227/938]  Loss: 0.1439  Acc: 95.31%\n",
      "Epoch 2 [228/938]  Loss: 0.1282  Acc: 95.31%\n",
      "Epoch 2 [229/938]  Loss: 0.1060  Acc: 96.88%\n",
      "Epoch 2 [230/938]  Loss: 0.0768  Acc: 98.44%\n",
      "Epoch 2 [231/938]  Loss: 0.0945  Acc: 95.31%\n",
      "Epoch 2 [232/938]  Loss: 0.0279  Acc: 100.00%\n",
      "Epoch 2 [233/938]  Loss: 0.3074  Acc: 89.06%\n",
      "Epoch 2 [234/938]  Loss: 0.1047  Acc: 96.88%\n",
      "Epoch 2 [235/938]  Loss: 0.1073  Acc: 95.31%\n",
      "Epoch 2 [236/938]  Loss: 0.1076  Acc: 96.88%\n",
      "Epoch 2 [237/938]  Loss: 0.0999  Acc: 96.88%\n",
      "Epoch 2 [238/938]  Loss: 0.1211  Acc: 98.44%\n",
      "Epoch 2 [239/938]  Loss: 0.1811  Acc: 92.19%\n",
      "Epoch 2 [240/938]  Loss: 0.0839  Acc: 98.44%\n",
      "Epoch 2 [241/938]  Loss: 0.1148  Acc: 95.31%\n",
      "Epoch 2 [242/938]  Loss: 0.0906  Acc: 98.44%\n",
      "Epoch 2 [243/938]  Loss: 0.1843  Acc: 95.31%\n",
      "Epoch 2 [244/938]  Loss: 0.1266  Acc: 95.31%\n",
      "Epoch 2 [245/938]  Loss: 0.1527  Acc: 95.31%\n",
      "Epoch 2 [246/938]  Loss: 0.1626  Acc: 95.31%\n",
      "Epoch 2 [247/938]  Loss: 0.1845  Acc: 95.31%\n",
      "Epoch 2 [248/938]  Loss: 0.1319  Acc: 96.88%\n",
      "Epoch 2 [249/938]  Loss: 0.1249  Acc: 96.88%\n",
      "Epoch 2 [250/938]  Loss: 0.1197  Acc: 95.31%\n",
      "Epoch 2 [251/938]  Loss: 0.0923  Acc: 96.88%\n",
      "Epoch 2 [252/938]  Loss: 0.2576  Acc: 87.50%\n",
      "Epoch 2 [253/938]  Loss: 0.0981  Acc: 96.88%\n",
      "Epoch 2 [254/938]  Loss: 0.0858  Acc: 96.88%\n",
      "Epoch 2 [255/938]  Loss: 0.2310  Acc: 95.31%\n",
      "Epoch 2 [256/938]  Loss: 0.0596  Acc: 98.44%\n",
      "Epoch 2 [200/938]  Loss: 0.0909  Acc: 98.44%\n",
      "Epoch 2 [201/938]  Loss: 0.1281  Acc: 96.88%\n",
      "Epoch 2 [202/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [203/938]  Loss: 0.0790  Acc: 98.44%\n",
      "Epoch 2 [204/938]  Loss: 0.0978  Acc: 98.44%\n",
      "Epoch 2 [205/938]  Loss: 0.0681  Acc: 96.88%\n",
      "Epoch 2 [206/938]  Loss: 0.1637  Acc: 95.31%\n",
      "Epoch 2 [207/938]  Loss: 0.1302  Acc: 95.31%\n",
      "Epoch 2 [208/938]  Loss: 0.0323  Acc: 100.00%\n",
      "Epoch 2 [209/938]  Loss: 0.0694  Acc: 98.44%\n",
      "Epoch 2 [210/938]  Loss: 0.0838  Acc: 98.44%\n",
      "Epoch 2 [211/938]  Loss: 0.1907  Acc: 93.75%\n",
      "Epoch 2 [212/938]  Loss: 0.0476  Acc: 100.00%\n",
      "Epoch 2 [213/938]  Loss: 0.0543  Acc: 98.44%\n",
      "Epoch 2 [214/938]  Loss: 0.1528  Acc: 92.19%\n",
      "Epoch 2 [215/938]  Loss: 0.0958  Acc: 96.88%\n",
      "Epoch 2 [216/938]  Loss: 0.1330  Acc: 95.31%\n",
      "Epoch 2 [217/938]  Loss: 0.2246  Acc: 95.31%\n",
      "Epoch 2 [218/938]  Loss: 0.1193  Acc: 98.44%\n",
      "Epoch 2 [219/938]  Loss: 0.1751  Acc: 93.75%\n",
      "Epoch 2 [220/938]  Loss: 0.1856  Acc: 95.31%\n",
      "Epoch 2 [221/938]  Loss: 0.1528  Acc: 95.31%\n",
      "Epoch 2 [222/938]  Loss: 0.1049  Acc: 96.88%\n",
      "Epoch 2 [223/938]  Loss: 0.0573  Acc: 100.00%\n",
      "Epoch 2 [224/938]  Loss: 0.1122  Acc: 96.88%\n",
      "Epoch 2 [225/938]  Loss: 0.0500  Acc: 98.44%\n",
      "Epoch 2 [226/938]  Loss: 0.1700  Acc: 95.31%\n",
      "Epoch 2 [227/938]  Loss: 0.1439  Acc: 95.31%\n",
      "Epoch 2 [228/938]  Loss: 0.1282  Acc: 95.31%\n",
      "Epoch 2 [229/938]  Loss: 0.1060  Acc: 96.88%\n",
      "Epoch 2 [230/938]  Loss: 0.0768  Acc: 98.44%\n",
      "Epoch 2 [231/938]  Loss: 0.0945  Acc: 95.31%\n",
      "Epoch 2 [232/938]  Loss: 0.0279  Acc: 100.00%\n",
      "Epoch 2 [233/938]  Loss: 0.3074  Acc: 89.06%\n",
      "Epoch 2 [234/938]  Loss: 0.1047  Acc: 96.88%\n",
      "Epoch 2 [235/938]  Loss: 0.1073  Acc: 95.31%\n",
      "Epoch 2 [236/938]  Loss: 0.1076  Acc: 96.88%\n",
      "Epoch 2 [237/938]  Loss: 0.0999  Acc: 96.88%\n",
      "Epoch 2 [238/938]  Loss: 0.1211  Acc: 98.44%\n",
      "Epoch 2 [239/938]  Loss: 0.1811  Acc: 92.19%\n",
      "Epoch 2 [240/938]  Loss: 0.0839  Acc: 98.44%\n",
      "Epoch 2 [241/938]  Loss: 0.1148  Acc: 95.31%\n",
      "Epoch 2 [242/938]  Loss: 0.0906  Acc: 98.44%\n",
      "Epoch 2 [243/938]  Loss: 0.1843  Acc: 95.31%\n",
      "Epoch 2 [244/938]  Loss: 0.1266  Acc: 95.31%\n",
      "Epoch 2 [245/938]  Loss: 0.1527  Acc: 95.31%\n",
      "Epoch 2 [246/938]  Loss: 0.1626  Acc: 95.31%\n",
      "Epoch 2 [247/938]  Loss: 0.1845  Acc: 95.31%\n",
      "Epoch 2 [248/938]  Loss: 0.1319  Acc: 96.88%\n",
      "Epoch 2 [249/938]  Loss: 0.1249  Acc: 96.88%\n",
      "Epoch 2 [250/938]  Loss: 0.1197  Acc: 95.31%\n",
      "Epoch 2 [251/938]  Loss: 0.0923  Acc: 96.88%\n",
      "Epoch 2 [252/938]  Loss: 0.2576  Acc: 87.50%\n",
      "Epoch 2 [253/938]  Loss: 0.0981  Acc: 96.88%\n",
      "Epoch 2 [254/938]  Loss: 0.0858  Acc: 96.88%\n",
      "Epoch 2 [255/938]  Loss: 0.2310  Acc: 95.31%\n",
      "Epoch 2 [256/938]  Loss: 0.0596  Acc: 98.44%\n",
      "Epoch 2 [257/938]  Loss: 0.1398  Acc: 96.88%\n",
      "Epoch 2 [258/938]  Loss: 0.1740  Acc: 93.75%\n",
      "Epoch 2 [259/938]  Loss: 0.0840  Acc: 95.31%\n",
      "Epoch 2 [260/938]  Loss: 0.0772  Acc: 95.31%\n",
      "Epoch 2 [261/938]  Loss: 0.0572  Acc: 98.44%\n",
      "Epoch 2 [262/938]  Loss: 0.1078  Acc: 98.44%\n",
      "Epoch 2 [263/938]  Loss: 0.1064  Acc: 93.75%\n",
      "Epoch 2 [264/938]  Loss: 0.1611  Acc: 92.19%\n",
      "Epoch 2 [265/938]  Loss: 0.1283  Acc: 96.88%\n",
      "Epoch 2 [266/938]  Loss: 0.1687  Acc: 93.75%\n",
      "Epoch 2 [267/938]  Loss: 0.1512  Acc: 96.88%\n",
      "Epoch 2 [268/938]  Loss: 0.0895  Acc: 96.88%\n",
      "Epoch 2 [269/938]  Loss: 0.3255  Acc: 87.50%\n",
      "Epoch 2 [270/938]  Loss: 0.1315  Acc: 96.88%\n",
      "Epoch 2 [271/938]  Loss: 0.1469  Acc: 93.75%\n",
      "Epoch 2 [272/938]  Loss: 0.0570  Acc: 100.00%\n",
      "Epoch 2 [273/938]  Loss: 0.0418  Acc: 100.00%\n",
      "Epoch 2 [274/938]  Loss: 0.0983  Acc: 96.88%\n",
      "Epoch 2 [275/938]  Loss: 0.3327  Acc: 90.62%\n",
      "Epoch 2 [276/938]  Loss: 0.0432  Acc: 100.00%\n",
      "Epoch 2 [277/938]  Loss: 0.2094  Acc: 92.19%\n",
      "Epoch 2 [278/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [279/938]  Loss: 0.1327  Acc: 93.75%\n",
      "Epoch 2 [280/938]  Loss: 0.1968  Acc: 95.31%\n",
      "Epoch 2 [281/938]  Loss: 0.0718  Acc: 98.44%\n",
      "Epoch 2 [282/938]  Loss: 0.2985  Acc: 89.06%\n",
      "Epoch 2 [283/938]  Loss: 0.1052  Acc: 96.88%\n",
      "Epoch 2 [284/938]  Loss: 0.0767  Acc: 98.44%\n",
      "Epoch 2 [285/938]  Loss: 0.0788  Acc: 96.88%\n",
      "Epoch 2 [286/938]  Loss: 0.0564  Acc: 96.88%\n",
      "Epoch 2 [287/938]  Loss: 0.1263  Acc: 98.44%\n",
      "Epoch 2 [288/938]  Loss: 0.1129  Acc: 95.31%\n",
      "Epoch 2 [289/938]  Loss: 0.1742  Acc: 93.75%\n",
      "Epoch 2 [290/938]  Loss: 0.1124  Acc: 95.31%\n",
      "Epoch 2 [291/938]  Loss: 0.1000  Acc: 96.88%\n",
      "Epoch 2 [292/938]  Loss: 0.1482  Acc: 96.88%\n",
      "Epoch 2 [293/938]  Loss: 0.0786  Acc: 96.88%\n",
      "Epoch 2 [257/938]  Loss: 0.1398  Acc: 96.88%\n",
      "Epoch 2 [258/938]  Loss: 0.1740  Acc: 93.75%\n",
      "Epoch 2 [259/938]  Loss: 0.0840  Acc: 95.31%\n",
      "Epoch 2 [260/938]  Loss: 0.0772  Acc: 95.31%\n",
      "Epoch 2 [261/938]  Loss: 0.0572  Acc: 98.44%\n",
      "Epoch 2 [262/938]  Loss: 0.1078  Acc: 98.44%\n",
      "Epoch 2 [263/938]  Loss: 0.1064  Acc: 93.75%\n",
      "Epoch 2 [264/938]  Loss: 0.1611  Acc: 92.19%\n",
      "Epoch 2 [265/938]  Loss: 0.1283  Acc: 96.88%\n",
      "Epoch 2 [266/938]  Loss: 0.1687  Acc: 93.75%\n",
      "Epoch 2 [267/938]  Loss: 0.1512  Acc: 96.88%\n",
      "Epoch 2 [268/938]  Loss: 0.0895  Acc: 96.88%\n",
      "Epoch 2 [269/938]  Loss: 0.3255  Acc: 87.50%\n",
      "Epoch 2 [270/938]  Loss: 0.1315  Acc: 96.88%\n",
      "Epoch 2 [271/938]  Loss: 0.1469  Acc: 93.75%\n",
      "Epoch 2 [272/938]  Loss: 0.0570  Acc: 100.00%\n",
      "Epoch 2 [273/938]  Loss: 0.0418  Acc: 100.00%\n",
      "Epoch 2 [274/938]  Loss: 0.0983  Acc: 96.88%\n",
      "Epoch 2 [275/938]  Loss: 0.3327  Acc: 90.62%\n",
      "Epoch 2 [276/938]  Loss: 0.0432  Acc: 100.00%\n",
      "Epoch 2 [277/938]  Loss: 0.2094  Acc: 92.19%\n",
      "Epoch 2 [278/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [279/938]  Loss: 0.1327  Acc: 93.75%\n",
      "Epoch 2 [280/938]  Loss: 0.1968  Acc: 95.31%\n",
      "Epoch 2 [281/938]  Loss: 0.0718  Acc: 98.44%\n",
      "Epoch 2 [282/938]  Loss: 0.2985  Acc: 89.06%\n",
      "Epoch 2 [283/938]  Loss: 0.1052  Acc: 96.88%\n",
      "Epoch 2 [284/938]  Loss: 0.0767  Acc: 98.44%\n",
      "Epoch 2 [285/938]  Loss: 0.0788  Acc: 96.88%\n",
      "Epoch 2 [286/938]  Loss: 0.0564  Acc: 96.88%\n",
      "Epoch 2 [287/938]  Loss: 0.1263  Acc: 98.44%\n",
      "Epoch 2 [288/938]  Loss: 0.1129  Acc: 95.31%\n",
      "Epoch 2 [289/938]  Loss: 0.1742  Acc: 93.75%\n",
      "Epoch 2 [290/938]  Loss: 0.1124  Acc: 95.31%\n",
      "Epoch 2 [291/938]  Loss: 0.1000  Acc: 96.88%\n",
      "Epoch 2 [292/938]  Loss: 0.1482  Acc: 96.88%\n",
      "Epoch 2 [293/938]  Loss: 0.0786  Acc: 96.88%\n",
      "Epoch 2 [294/938]  Loss: 0.2659  Acc: 92.19%\n",
      "Epoch 2 [295/938]  Loss: 0.1485  Acc: 92.19%\n",
      "Epoch 2 [296/938]  Loss: 0.0862  Acc: 96.88%\n",
      "Epoch 2 [297/938]  Loss: 0.0563  Acc: 98.44%\n",
      "Epoch 2 [298/938]  Loss: 0.2798  Acc: 92.19%\n",
      "Epoch 2 [299/938]  Loss: 0.1387  Acc: 96.88%\n",
      "Epoch 2 [300/938]  Loss: 0.1311  Acc: 95.31%\n",
      "Epoch 2 [301/938]  Loss: 0.2726  Acc: 93.75%\n",
      "Epoch 2 [302/938]  Loss: 0.0635  Acc: 100.00%\n",
      "Epoch 2 [303/938]  Loss: 0.1249  Acc: 96.88%\n",
      "Epoch 2 [304/938]  Loss: 0.0583  Acc: 98.44%\n",
      "Epoch 2 [305/938]  Loss: 0.1697  Acc: 93.75%\n",
      "Epoch 2 [306/938]  Loss: 0.1166  Acc: 96.88%\n",
      "Epoch 2 [307/938]  Loss: 0.1208  Acc: 93.75%\n",
      "Epoch 2 [308/938]  Loss: 0.0565  Acc: 98.44%\n",
      "Epoch 2 [309/938]  Loss: 0.2251  Acc: 93.75%\n",
      "Epoch 2 [310/938]  Loss: 0.2403  Acc: 89.06%\n",
      "Epoch 2 [311/938]  Loss: 0.1552  Acc: 96.88%\n",
      "Epoch 2 [312/938]  Loss: 0.1552  Acc: 95.31%\n",
      "Epoch 2 [313/938]  Loss: 0.3231  Acc: 92.19%\n",
      "Epoch 2 [314/938]  Loss: 0.2842  Acc: 90.62%\n",
      "Epoch 2 [315/938]  Loss: 0.0866  Acc: 98.44%\n",
      "Epoch 2 [316/938]  Loss: 0.1327  Acc: 96.88%\n",
      "Epoch 2 [317/938]  Loss: 0.2468  Acc: 95.31%\n",
      "Epoch 2 [318/938]  Loss: 0.0987  Acc: 96.88%\n",
      "Epoch 2 [319/938]  Loss: 0.1036  Acc: 95.31%\n",
      "Epoch 2 [320/938]  Loss: 0.0690  Acc: 98.44%\n",
      "Epoch 2 [321/938]  Loss: 0.1238  Acc: 96.88%\n",
      "Epoch 2 [322/938]  Loss: 0.1020  Acc: 96.88%\n",
      "Epoch 2 [323/938]  Loss: 0.1553  Acc: 96.88%\n",
      "Epoch 2 [324/938]  Loss: 0.0564  Acc: 100.00%\n",
      "Epoch 2 [325/938]  Loss: 0.1661  Acc: 96.88%\n",
      "Epoch 2 [326/938]  Loss: 0.0598  Acc: 98.44%\n",
      "Epoch 2 [327/938]  Loss: 0.0906  Acc: 98.44%\n",
      "Epoch 2 [328/938]  Loss: 0.1629  Acc: 93.75%\n",
      "Epoch 2 [329/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [330/938]  Loss: 0.0875  Acc: 98.44%\n",
      "Epoch 2 [331/938]  Loss: 0.1090  Acc: 96.88%\n",
      "Epoch 2 [332/938]  Loss: 0.0517  Acc: 98.44%\n",
      "Epoch 2 [333/938]  Loss: 0.0423  Acc: 100.00%\n",
      "Epoch 2 [334/938]  Loss: 0.0926  Acc: 98.44%\n",
      "Epoch 2 [335/938]  Loss: 0.1492  Acc: 96.88%\n",
      "Epoch 2 [336/938]  Loss: 0.1085  Acc: 96.88%\n",
      "Epoch 2 [337/938]  Loss: 0.1396  Acc: 96.88%\n",
      "Epoch 2 [338/938]  Loss: 0.1279  Acc: 95.31%\n",
      "Epoch 2 [339/938]  Loss: 0.0485  Acc: 98.44%\n",
      "Epoch 2 [340/938]  Loss: 0.1270  Acc: 96.88%\n",
      "Epoch 2 [341/938]  Loss: 0.1002  Acc: 95.31%\n",
      "Epoch 2 [342/938]  Loss: 0.2837  Acc: 92.19%\n",
      "Epoch 2 [343/938]  Loss: 0.1665  Acc: 93.75%\n",
      "Epoch 2 [344/938]  Loss: 0.2276  Acc: 93.75%\n",
      "Epoch 2 [345/938]  Loss: 0.1648  Acc: 96.88%\n",
      "Epoch 2 [346/938]  Loss: 0.0913  Acc: 96.88%\n",
      "Epoch 2 [347/938]  Loss: 0.0970  Acc: 96.88%\n",
      "Epoch 2 [348/938]  Loss: 0.0443  Acc: 98.44%\n",
      "Epoch 2 [349/938]  Loss: 0.1663  Acc: 90.62%\n",
      "Epoch 2 [350/938]  Loss: 0.1102  Acc: 95.31%\n",
      "Epoch 2 [351/938]  Loss: 0.0699  Acc: 96.88%\n",
      "Epoch 2 [294/938]  Loss: 0.2659  Acc: 92.19%\n",
      "Epoch 2 [295/938]  Loss: 0.1485  Acc: 92.19%\n",
      "Epoch 2 [296/938]  Loss: 0.0862  Acc: 96.88%\n",
      "Epoch 2 [297/938]  Loss: 0.0563  Acc: 98.44%\n",
      "Epoch 2 [298/938]  Loss: 0.2798  Acc: 92.19%\n",
      "Epoch 2 [299/938]  Loss: 0.1387  Acc: 96.88%\n",
      "Epoch 2 [300/938]  Loss: 0.1311  Acc: 95.31%\n",
      "Epoch 2 [301/938]  Loss: 0.2726  Acc: 93.75%\n",
      "Epoch 2 [302/938]  Loss: 0.0635  Acc: 100.00%\n",
      "Epoch 2 [303/938]  Loss: 0.1249  Acc: 96.88%\n",
      "Epoch 2 [304/938]  Loss: 0.0583  Acc: 98.44%\n",
      "Epoch 2 [305/938]  Loss: 0.1697  Acc: 93.75%\n",
      "Epoch 2 [306/938]  Loss: 0.1166  Acc: 96.88%\n",
      "Epoch 2 [307/938]  Loss: 0.1208  Acc: 93.75%\n",
      "Epoch 2 [308/938]  Loss: 0.0565  Acc: 98.44%\n",
      "Epoch 2 [309/938]  Loss: 0.2251  Acc: 93.75%\n",
      "Epoch 2 [310/938]  Loss: 0.2403  Acc: 89.06%\n",
      "Epoch 2 [311/938]  Loss: 0.1552  Acc: 96.88%\n",
      "Epoch 2 [312/938]  Loss: 0.1552  Acc: 95.31%\n",
      "Epoch 2 [313/938]  Loss: 0.3231  Acc: 92.19%\n",
      "Epoch 2 [314/938]  Loss: 0.2842  Acc: 90.62%\n",
      "Epoch 2 [315/938]  Loss: 0.0866  Acc: 98.44%\n",
      "Epoch 2 [316/938]  Loss: 0.1327  Acc: 96.88%\n",
      "Epoch 2 [317/938]  Loss: 0.2468  Acc: 95.31%\n",
      "Epoch 2 [318/938]  Loss: 0.0987  Acc: 96.88%\n",
      "Epoch 2 [319/938]  Loss: 0.1036  Acc: 95.31%\n",
      "Epoch 2 [320/938]  Loss: 0.0690  Acc: 98.44%\n",
      "Epoch 2 [321/938]  Loss: 0.1238  Acc: 96.88%\n",
      "Epoch 2 [322/938]  Loss: 0.1020  Acc: 96.88%\n",
      "Epoch 2 [323/938]  Loss: 0.1553  Acc: 96.88%\n",
      "Epoch 2 [324/938]  Loss: 0.0564  Acc: 100.00%\n",
      "Epoch 2 [325/938]  Loss: 0.1661  Acc: 96.88%\n",
      "Epoch 2 [326/938]  Loss: 0.0598  Acc: 98.44%\n",
      "Epoch 2 [327/938]  Loss: 0.0906  Acc: 98.44%\n",
      "Epoch 2 [328/938]  Loss: 0.1629  Acc: 93.75%\n",
      "Epoch 2 [329/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [330/938]  Loss: 0.0875  Acc: 98.44%\n",
      "Epoch 2 [331/938]  Loss: 0.1090  Acc: 96.88%\n",
      "Epoch 2 [332/938]  Loss: 0.0517  Acc: 98.44%\n",
      "Epoch 2 [333/938]  Loss: 0.0423  Acc: 100.00%\n",
      "Epoch 2 [334/938]  Loss: 0.0926  Acc: 98.44%\n",
      "Epoch 2 [335/938]  Loss: 0.1492  Acc: 96.88%\n",
      "Epoch 2 [336/938]  Loss: 0.1085  Acc: 96.88%\n",
      "Epoch 2 [337/938]  Loss: 0.1396  Acc: 96.88%\n",
      "Epoch 2 [338/938]  Loss: 0.1279  Acc: 95.31%\n",
      "Epoch 2 [339/938]  Loss: 0.0485  Acc: 98.44%\n",
      "Epoch 2 [340/938]  Loss: 0.1270  Acc: 96.88%\n",
      "Epoch 2 [341/938]  Loss: 0.1002  Acc: 95.31%\n",
      "Epoch 2 [342/938]  Loss: 0.2837  Acc: 92.19%\n",
      "Epoch 2 [343/938]  Loss: 0.1665  Acc: 93.75%\n",
      "Epoch 2 [344/938]  Loss: 0.2276  Acc: 93.75%\n",
      "Epoch 2 [345/938]  Loss: 0.1648  Acc: 96.88%\n",
      "Epoch 2 [346/938]  Loss: 0.0913  Acc: 96.88%\n",
      "Epoch 2 [347/938]  Loss: 0.0970  Acc: 96.88%\n",
      "Epoch 2 [348/938]  Loss: 0.0443  Acc: 98.44%\n",
      "Epoch 2 [349/938]  Loss: 0.1663  Acc: 90.62%\n",
      "Epoch 2 [350/938]  Loss: 0.1102  Acc: 95.31%\n",
      "Epoch 2 [351/938]  Loss: 0.0699  Acc: 96.88%\n",
      "Epoch 2 [352/938]  Loss: 0.0502  Acc: 96.88%\n",
      "Epoch 2 [353/938]  Loss: 0.0970  Acc: 96.88%\n",
      "Epoch 2 [354/938]  Loss: 0.1364  Acc: 95.31%\n",
      "Epoch 2 [355/938]  Loss: 0.1378  Acc: 93.75%\n",
      "Epoch 2 [356/938]  Loss: 0.2484  Acc: 93.75%\n",
      "Epoch 2 [357/938]  Loss: 0.1488  Acc: 93.75%\n",
      "Epoch 2 [358/938]  Loss: 0.0813  Acc: 96.88%\n",
      "Epoch 2 [359/938]  Loss: 0.3356  Acc: 92.19%\n",
      "Epoch 2 [360/938]  Loss: 0.1831  Acc: 92.19%\n",
      "Epoch 2 [361/938]  Loss: 0.0194  Acc: 100.00%\n",
      "Epoch 2 [362/938]  Loss: 0.0222  Acc: 100.00%\n",
      "Epoch 2 [363/938]  Loss: 0.0583  Acc: 98.44%\n",
      "Epoch 2 [364/938]  Loss: 0.0488  Acc: 98.44%\n",
      "Epoch 2 [365/938]  Loss: 0.1700  Acc: 93.75%\n",
      "Epoch 2 [366/938]  Loss: 0.2086  Acc: 93.75%\n",
      "Epoch 2 [367/938]  Loss: 0.0726  Acc: 98.44%\n",
      "Epoch 2 [368/938]  Loss: 0.1880  Acc: 95.31%\n",
      "Epoch 2 [369/938]  Loss: 0.1888  Acc: 96.88%\n",
      "Epoch 2 [370/938]  Loss: 0.1085  Acc: 96.88%\n",
      "Epoch 2 [371/938]  Loss: 0.2055  Acc: 92.19%\n",
      "Epoch 2 [372/938]  Loss: 0.0660  Acc: 100.00%\n",
      "Epoch 2 [373/938]  Loss: 0.0969  Acc: 96.88%\n",
      "Epoch 2 [374/938]  Loss: 0.0465  Acc: 100.00%\n",
      "Epoch 2 [375/938]  Loss: 0.0623  Acc: 100.00%\n",
      "Epoch 2 [376/938]  Loss: 0.1423  Acc: 93.75%\n",
      "Epoch 2 [377/938]  Loss: 0.1096  Acc: 96.88%\n",
      "Epoch 2 [378/938]  Loss: 0.0459  Acc: 100.00%\n",
      "Epoch 2 [379/938]  Loss: 0.0373  Acc: 100.00%\n",
      "Epoch 2 [380/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [381/938]  Loss: 0.0396  Acc: 100.00%\n",
      "Epoch 2 [382/938]  Loss: 0.0407  Acc: 100.00%\n",
      "Epoch 2 [383/938]  Loss: 0.1138  Acc: 96.88%\n",
      "Epoch 2 [384/938]  Loss: 0.0793  Acc: 98.44%\n",
      "Epoch 2 [385/938]  Loss: 0.1818  Acc: 93.75%\n",
      "Epoch 2 [386/938]  Loss: 0.1406  Acc: 93.75%\n",
      "Epoch 2 [387/938]  Loss: 0.2485  Acc: 92.19%\n",
      "Epoch 2 [388/938]  Loss: 0.1179  Acc: 95.31%\n",
      "Epoch 2 [389/938]  Loss: 0.0606  Acc: 98.44%\n",
      "Epoch 2 [390/938]  Loss: 0.1306  Acc: 95.31%\n",
      "Epoch 2 [391/938]  Loss: 0.1105  Acc: 96.88%\n",
      "Epoch 2 [392/938]  Loss: 0.1762  Acc: 93.75%\n",
      "Epoch 2 [393/938]  Loss: 0.1314  Acc: 92.19%\n",
      "Epoch 2 [394/938]  Loss: 0.1548  Acc: 96.88%\n",
      "Epoch 2 [395/938]  Loss: 0.1875  Acc: 92.19%\n",
      "Epoch 2 [396/938]  Loss: 0.1970  Acc: 92.19%\n",
      "Epoch 2 [397/938]  Loss: 0.0940  Acc: 98.44%\n",
      "Epoch 2 [398/938]  Loss: 0.1408  Acc: 95.31%\n",
      "Epoch 2 [399/938]  Loss: 0.0352  Acc: 98.44%\n",
      "Epoch 2 [400/938]  Loss: 0.1980  Acc: 92.19%\n",
      "Epoch 2 [401/938]  Loss: 0.0406  Acc: 98.44%\n",
      "Epoch 2 [402/938]  Loss: 0.1981  Acc: 93.75%\n",
      "Epoch 2 [403/938]  Loss: 0.1184  Acc: 96.88%\n",
      "Epoch 2 [404/938]  Loss: 0.1150  Acc: 98.44%\n",
      "Epoch 2 [405/938]  Loss: 0.1626  Acc: 92.19%\n",
      "Epoch 2 [406/938]  Loss: 0.0718  Acc: 96.88%\n",
      "Epoch 2 [407/938]  Loss: 0.0778  Acc: 98.44%\n",
      "Epoch 2 [408/938]  Loss: 0.1324  Acc: 95.31%\n",
      "Epoch 2 [352/938]  Loss: 0.0502  Acc: 96.88%\n",
      "Epoch 2 [353/938]  Loss: 0.0970  Acc: 96.88%\n",
      "Epoch 2 [354/938]  Loss: 0.1364  Acc: 95.31%\n",
      "Epoch 2 [355/938]  Loss: 0.1378  Acc: 93.75%\n",
      "Epoch 2 [356/938]  Loss: 0.2484  Acc: 93.75%\n",
      "Epoch 2 [357/938]  Loss: 0.1488  Acc: 93.75%\n",
      "Epoch 2 [358/938]  Loss: 0.0813  Acc: 96.88%\n",
      "Epoch 2 [359/938]  Loss: 0.3356  Acc: 92.19%\n",
      "Epoch 2 [360/938]  Loss: 0.1831  Acc: 92.19%\n",
      "Epoch 2 [361/938]  Loss: 0.0194  Acc: 100.00%\n",
      "Epoch 2 [362/938]  Loss: 0.0222  Acc: 100.00%\n",
      "Epoch 2 [363/938]  Loss: 0.0583  Acc: 98.44%\n",
      "Epoch 2 [364/938]  Loss: 0.0488  Acc: 98.44%\n",
      "Epoch 2 [365/938]  Loss: 0.1700  Acc: 93.75%\n",
      "Epoch 2 [366/938]  Loss: 0.2086  Acc: 93.75%\n",
      "Epoch 2 [367/938]  Loss: 0.0726  Acc: 98.44%\n",
      "Epoch 2 [368/938]  Loss: 0.1880  Acc: 95.31%\n",
      "Epoch 2 [369/938]  Loss: 0.1888  Acc: 96.88%\n",
      "Epoch 2 [370/938]  Loss: 0.1085  Acc: 96.88%\n",
      "Epoch 2 [371/938]  Loss: 0.2055  Acc: 92.19%\n",
      "Epoch 2 [372/938]  Loss: 0.0660  Acc: 100.00%\n",
      "Epoch 2 [373/938]  Loss: 0.0969  Acc: 96.88%\n",
      "Epoch 2 [374/938]  Loss: 0.0465  Acc: 100.00%\n",
      "Epoch 2 [375/938]  Loss: 0.0623  Acc: 100.00%\n",
      "Epoch 2 [376/938]  Loss: 0.1423  Acc: 93.75%\n",
      "Epoch 2 [377/938]  Loss: 0.1096  Acc: 96.88%\n",
      "Epoch 2 [378/938]  Loss: 0.0459  Acc: 100.00%\n",
      "Epoch 2 [379/938]  Loss: 0.0373  Acc: 100.00%\n",
      "Epoch 2 [380/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [381/938]  Loss: 0.0396  Acc: 100.00%\n",
      "Epoch 2 [382/938]  Loss: 0.0407  Acc: 100.00%\n",
      "Epoch 2 [383/938]  Loss: 0.1138  Acc: 96.88%\n",
      "Epoch 2 [384/938]  Loss: 0.0793  Acc: 98.44%\n",
      "Epoch 2 [385/938]  Loss: 0.1818  Acc: 93.75%\n",
      "Epoch 2 [386/938]  Loss: 0.1406  Acc: 93.75%\n",
      "Epoch 2 [387/938]  Loss: 0.2485  Acc: 92.19%\n",
      "Epoch 2 [388/938]  Loss: 0.1179  Acc: 95.31%\n",
      "Epoch 2 [389/938]  Loss: 0.0606  Acc: 98.44%\n",
      "Epoch 2 [390/938]  Loss: 0.1306  Acc: 95.31%\n",
      "Epoch 2 [391/938]  Loss: 0.1105  Acc: 96.88%\n",
      "Epoch 2 [392/938]  Loss: 0.1762  Acc: 93.75%\n",
      "Epoch 2 [393/938]  Loss: 0.1314  Acc: 92.19%\n",
      "Epoch 2 [394/938]  Loss: 0.1548  Acc: 96.88%\n",
      "Epoch 2 [395/938]  Loss: 0.1875  Acc: 92.19%\n",
      "Epoch 2 [396/938]  Loss: 0.1970  Acc: 92.19%\n",
      "Epoch 2 [397/938]  Loss: 0.0940  Acc: 98.44%\n",
      "Epoch 2 [398/938]  Loss: 0.1408  Acc: 95.31%\n",
      "Epoch 2 [399/938]  Loss: 0.0352  Acc: 98.44%\n",
      "Epoch 2 [400/938]  Loss: 0.1980  Acc: 92.19%\n",
      "Epoch 2 [401/938]  Loss: 0.0406  Acc: 98.44%\n",
      "Epoch 2 [402/938]  Loss: 0.1981  Acc: 93.75%\n",
      "Epoch 2 [403/938]  Loss: 0.1184  Acc: 96.88%\n",
      "Epoch 2 [404/938]  Loss: 0.1150  Acc: 98.44%\n",
      "Epoch 2 [405/938]  Loss: 0.1626  Acc: 92.19%\n",
      "Epoch 2 [406/938]  Loss: 0.0718  Acc: 96.88%\n",
      "Epoch 2 [407/938]  Loss: 0.0778  Acc: 98.44%\n",
      "Epoch 2 [408/938]  Loss: 0.1324  Acc: 95.31%\n",
      "Epoch 2 [409/938]  Loss: 0.0996  Acc: 98.44%\n",
      "Epoch 2 [410/938]  Loss: 0.1518  Acc: 93.75%\n",
      "Epoch 2 [411/938]  Loss: 0.1291  Acc: 96.88%\n",
      "Epoch 2 [412/938]  Loss: 0.1031  Acc: 98.44%\n",
      "Epoch 2 [413/938]  Loss: 0.1360  Acc: 93.75%\n",
      "Epoch 2 [414/938]  Loss: 0.1978  Acc: 93.75%\n",
      "Epoch 2 [415/938]  Loss: 0.1038  Acc: 96.88%\n",
      "Epoch 2 [416/938]  Loss: 0.1705  Acc: 98.44%\n",
      "Epoch 2 [417/938]  Loss: 0.2274  Acc: 93.75%\n",
      "Epoch 2 [418/938]  Loss: 0.0705  Acc: 96.88%\n",
      "Epoch 2 [419/938]  Loss: 0.1575  Acc: 96.88%\n",
      "Epoch 2 [420/938]  Loss: 0.1381  Acc: 95.31%\n",
      "Epoch 2 [421/938]  Loss: 0.1563  Acc: 93.75%\n",
      "Epoch 2 [422/938]  Loss: 0.0882  Acc: 96.88%\n",
      "Epoch 2 [423/938]  Loss: 0.1105  Acc: 95.31%\n",
      "Epoch 2 [424/938]  Loss: 0.2570  Acc: 92.19%\n",
      "Epoch 2 [425/938]  Loss: 0.0763  Acc: 95.31%\n",
      "Epoch 2 [426/938]  Loss: 0.1266  Acc: 98.44%\n",
      "Epoch 2 [427/938]  Loss: 0.0965  Acc: 96.88%\n",
      "Epoch 2 [428/938]  Loss: 0.0523  Acc: 98.44%\n",
      "Epoch 2 [429/938]  Loss: 0.1107  Acc: 93.75%\n",
      "Epoch 2 [430/938]  Loss: 0.0498  Acc: 100.00%\n",
      "Epoch 2 [431/938]  Loss: 0.0847  Acc: 98.44%\n",
      "Epoch 2 [432/938]  Loss: 0.2055  Acc: 92.19%\n",
      "Epoch 2 [433/938]  Loss: 0.1088  Acc: 96.88%\n",
      "Epoch 2 [434/938]  Loss: 0.1188  Acc: 95.31%\n",
      "Epoch 2 [435/938]  Loss: 0.1459  Acc: 93.75%\n",
      "Epoch 2 [436/938]  Loss: 0.1340  Acc: 95.31%\n",
      "Epoch 2 [437/938]  Loss: 0.0620  Acc: 98.44%\n",
      "Epoch 2 [438/938]  Loss: 0.2574  Acc: 92.19%\n",
      "Epoch 2 [439/938]  Loss: 0.0815  Acc: 98.44%\n",
      "Epoch 2 [440/938]  Loss: 0.0332  Acc: 100.00%\n",
      "Epoch 2 [441/938]  Loss: 0.1897  Acc: 93.75%\n",
      "Epoch 2 [442/938]  Loss: 0.0703  Acc: 98.44%\n",
      "Epoch 2 [443/938]  Loss: 0.1552  Acc: 95.31%\n",
      "Epoch 2 [444/938]  Loss: 0.1098  Acc: 95.31%\n",
      "Epoch 2 [445/938]  Loss: 0.1104  Acc: 96.88%\n",
      "Epoch 2 [446/938]  Loss: 0.1040  Acc: 95.31%\n",
      "Epoch 2 [447/938]  Loss: 0.1268  Acc: 96.88%\n",
      "Epoch 2 [448/938]  Loss: 0.1221  Acc: 96.88%\n",
      "Epoch 2 [449/938]  Loss: 0.1340  Acc: 93.75%\n",
      "Epoch 2 [450/938]  Loss: 0.0403  Acc: 100.00%\n",
      "Epoch 2 [451/938]  Loss: 0.1187  Acc: 95.31%\n",
      "Epoch 2 [452/938]  Loss: 0.2625  Acc: 92.19%\n",
      "Epoch 2 [453/938]  Loss: 0.0468  Acc: 100.00%\n",
      "Epoch 2 [454/938]  Loss: 0.2061  Acc: 92.19%\n",
      "Epoch 2 [455/938]  Loss: 0.0780  Acc: 96.88%\n",
      "Epoch 2 [456/938]  Loss: 0.0545  Acc: 98.44%\n",
      "Epoch 2 [457/938]  Loss: 0.1977  Acc: 95.31%\n",
      "Epoch 2 [458/938]  Loss: 0.2464  Acc: 96.88%\n",
      "Epoch 2 [409/938]  Loss: 0.0996  Acc: 98.44%\n",
      "Epoch 2 [410/938]  Loss: 0.1518  Acc: 93.75%\n",
      "Epoch 2 [411/938]  Loss: 0.1291  Acc: 96.88%\n",
      "Epoch 2 [412/938]  Loss: 0.1031  Acc: 98.44%\n",
      "Epoch 2 [413/938]  Loss: 0.1360  Acc: 93.75%\n",
      "Epoch 2 [414/938]  Loss: 0.1978  Acc: 93.75%\n",
      "Epoch 2 [415/938]  Loss: 0.1038  Acc: 96.88%\n",
      "Epoch 2 [416/938]  Loss: 0.1705  Acc: 98.44%\n",
      "Epoch 2 [417/938]  Loss: 0.2274  Acc: 93.75%\n",
      "Epoch 2 [418/938]  Loss: 0.0705  Acc: 96.88%\n",
      "Epoch 2 [419/938]  Loss: 0.1575  Acc: 96.88%\n",
      "Epoch 2 [420/938]  Loss: 0.1381  Acc: 95.31%\n",
      "Epoch 2 [421/938]  Loss: 0.1563  Acc: 93.75%\n",
      "Epoch 2 [422/938]  Loss: 0.0882  Acc: 96.88%\n",
      "Epoch 2 [423/938]  Loss: 0.1105  Acc: 95.31%\n",
      "Epoch 2 [424/938]  Loss: 0.2570  Acc: 92.19%\n",
      "Epoch 2 [425/938]  Loss: 0.0763  Acc: 95.31%\n",
      "Epoch 2 [426/938]  Loss: 0.1266  Acc: 98.44%\n",
      "Epoch 2 [427/938]  Loss: 0.0965  Acc: 96.88%\n",
      "Epoch 2 [428/938]  Loss: 0.0523  Acc: 98.44%\n",
      "Epoch 2 [429/938]  Loss: 0.1107  Acc: 93.75%\n",
      "Epoch 2 [430/938]  Loss: 0.0498  Acc: 100.00%\n",
      "Epoch 2 [431/938]  Loss: 0.0847  Acc: 98.44%\n",
      "Epoch 2 [432/938]  Loss: 0.2055  Acc: 92.19%\n",
      "Epoch 2 [433/938]  Loss: 0.1088  Acc: 96.88%\n",
      "Epoch 2 [434/938]  Loss: 0.1188  Acc: 95.31%\n",
      "Epoch 2 [435/938]  Loss: 0.1459  Acc: 93.75%\n",
      "Epoch 2 [436/938]  Loss: 0.1340  Acc: 95.31%\n",
      "Epoch 2 [437/938]  Loss: 0.0620  Acc: 98.44%\n",
      "Epoch 2 [438/938]  Loss: 0.2574  Acc: 92.19%\n",
      "Epoch 2 [439/938]  Loss: 0.0815  Acc: 98.44%\n",
      "Epoch 2 [440/938]  Loss: 0.0332  Acc: 100.00%\n",
      "Epoch 2 [441/938]  Loss: 0.1897  Acc: 93.75%\n",
      "Epoch 2 [442/938]  Loss: 0.0703  Acc: 98.44%\n",
      "Epoch 2 [443/938]  Loss: 0.1552  Acc: 95.31%\n",
      "Epoch 2 [444/938]  Loss: 0.1098  Acc: 95.31%\n",
      "Epoch 2 [445/938]  Loss: 0.1104  Acc: 96.88%\n",
      "Epoch 2 [446/938]  Loss: 0.1040  Acc: 95.31%\n",
      "Epoch 2 [447/938]  Loss: 0.1268  Acc: 96.88%\n",
      "Epoch 2 [448/938]  Loss: 0.1221  Acc: 96.88%\n",
      "Epoch 2 [449/938]  Loss: 0.1340  Acc: 93.75%\n",
      "Epoch 2 [450/938]  Loss: 0.0403  Acc: 100.00%\n",
      "Epoch 2 [451/938]  Loss: 0.1187  Acc: 95.31%\n",
      "Epoch 2 [452/938]  Loss: 0.2625  Acc: 92.19%\n",
      "Epoch 2 [453/938]  Loss: 0.0468  Acc: 100.00%\n",
      "Epoch 2 [454/938]  Loss: 0.2061  Acc: 92.19%\n",
      "Epoch 2 [455/938]  Loss: 0.0780  Acc: 96.88%\n",
      "Epoch 2 [456/938]  Loss: 0.0545  Acc: 98.44%\n",
      "Epoch 2 [457/938]  Loss: 0.1977  Acc: 95.31%\n",
      "Epoch 2 [458/938]  Loss: 0.2464  Acc: 96.88%\n",
      "Epoch 2 [459/938]  Loss: 0.2818  Acc: 90.62%\n",
      "Epoch 2 [460/938]  Loss: 0.0500  Acc: 98.44%\n",
      "Epoch 2 [461/938]  Loss: 0.1304  Acc: 96.88%\n",
      "Epoch 2 [462/938]  Loss: 0.1008  Acc: 96.88%\n",
      "Epoch 2 [463/938]  Loss: 0.0749  Acc: 96.88%\n",
      "Epoch 2 [464/938]  Loss: 0.0635  Acc: 100.00%\n",
      "Epoch 2 [465/938]  Loss: 0.1220  Acc: 95.31%\n",
      "Epoch 2 [466/938]  Loss: 0.1230  Acc: 96.88%\n",
      "Epoch 2 [467/938]  Loss: 0.1701  Acc: 93.75%\n",
      "Epoch 2 [468/938]  Loss: 0.0550  Acc: 98.44%\n",
      "Epoch 2 [469/938]  Loss: 0.1130  Acc: 95.31%\n",
      "Epoch 2 [470/938]  Loss: 0.0924  Acc: 98.44%\n",
      "Epoch 2 [471/938]  Loss: 0.1483  Acc: 96.88%\n",
      "Epoch 2 [472/938]  Loss: 0.1297  Acc: 98.44%\n",
      "Epoch 2 [473/938]  Loss: 0.1834  Acc: 92.19%\n",
      "Epoch 2 [474/938]  Loss: 0.0933  Acc: 98.44%\n",
      "Epoch 2 [475/938]  Loss: 0.1879  Acc: 92.19%\n",
      "Epoch 2 [476/938]  Loss: 0.0699  Acc: 98.44%\n",
      "Epoch 2 [477/938]  Loss: 0.1084  Acc: 96.88%\n",
      "Epoch 2 [478/938]  Loss: 0.1853  Acc: 93.75%\n",
      "Epoch 2 [479/938]  Loss: 0.0434  Acc: 100.00%\n",
      "Epoch 2 [480/938]  Loss: 0.1185  Acc: 98.44%\n",
      "Epoch 2 [481/938]  Loss: 0.2034  Acc: 93.75%\n",
      "Epoch 2 [482/938]  Loss: 0.0858  Acc: 98.44%\n",
      "Epoch 2 [483/938]  Loss: 0.0689  Acc: 98.44%\n",
      "Epoch 2 [484/938]  Loss: 0.0382  Acc: 100.00%\n",
      "Epoch 2 [485/938]  Loss: 0.1767  Acc: 93.75%\n",
      "Epoch 2 [486/938]  Loss: 0.0759  Acc: 96.88%\n",
      "Epoch 2 [487/938]  Loss: 0.2485  Acc: 92.19%\n",
      "Epoch 2 [488/938]  Loss: 0.0736  Acc: 98.44%\n",
      "Epoch 2 [489/938]  Loss: 0.3348  Acc: 92.19%\n",
      "Epoch 2 [490/938]  Loss: 0.1955  Acc: 95.31%\n",
      "Epoch 2 [491/938]  Loss: 0.0768  Acc: 98.44%\n",
      "Epoch 2 [492/938]  Loss: 0.1372  Acc: 93.75%\n",
      "Epoch 2 [493/938]  Loss: 0.0957  Acc: 96.88%\n",
      "Epoch 2 [494/938]  Loss: 0.0704  Acc: 98.44%\n",
      "Epoch 2 [495/938]  Loss: 0.0499  Acc: 98.44%\n",
      "Epoch 2 [496/938]  Loss: 0.0599  Acc: 98.44%\n",
      "Epoch 2 [497/938]  Loss: 0.0731  Acc: 96.88%\n",
      "Epoch 2 [498/938]  Loss: 0.1733  Acc: 92.19%\n",
      "Epoch 2 [499/938]  Loss: 0.2069  Acc: 95.31%\n",
      "Epoch 2 [500/938]  Loss: 0.0453  Acc: 98.44%\n",
      "Epoch 2 [501/938]  Loss: 0.1753  Acc: 90.62%\n",
      "Epoch 2 [502/938]  Loss: 0.1933  Acc: 93.75%\n",
      "Epoch 2 [503/938]  Loss: 0.0749  Acc: 96.88%\n",
      "Epoch 2 [504/938]  Loss: 0.0471  Acc: 98.44%\n",
      "Epoch 2 [505/938]  Loss: 0.0579  Acc: 100.00%\n",
      "Epoch 2 [506/938]  Loss: 0.0302  Acc: 100.00%\n",
      "Epoch 2 [507/938]  Loss: 0.0858  Acc: 93.75%\n",
      "Epoch 2 [508/938]  Loss: 0.1324  Acc: 93.75%\n",
      "Epoch 2 [509/938]  Loss: 0.2870  Acc: 92.19%\n",
      "Epoch 2 [510/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [511/938]  Loss: 0.1069  Acc: 98.44%\n",
      "Epoch 2 [512/938]  Loss: 0.0603  Acc: 98.44%\n",
      "Epoch 2 [513/938]  Loss: 0.1831  Acc: 92.19%\n",
      "Epoch 2 [514/938]  Loss: 0.1004  Acc: 96.88%\n",
      "Epoch 2 [515/938]  Loss: 0.1589  Acc: 96.88%\n",
      "Epoch 2 [459/938]  Loss: 0.2818  Acc: 90.62%\n",
      "Epoch 2 [460/938]  Loss: 0.0500  Acc: 98.44%\n",
      "Epoch 2 [461/938]  Loss: 0.1304  Acc: 96.88%\n",
      "Epoch 2 [462/938]  Loss: 0.1008  Acc: 96.88%\n",
      "Epoch 2 [463/938]  Loss: 0.0749  Acc: 96.88%\n",
      "Epoch 2 [464/938]  Loss: 0.0635  Acc: 100.00%\n",
      "Epoch 2 [465/938]  Loss: 0.1220  Acc: 95.31%\n",
      "Epoch 2 [466/938]  Loss: 0.1230  Acc: 96.88%\n",
      "Epoch 2 [467/938]  Loss: 0.1701  Acc: 93.75%\n",
      "Epoch 2 [468/938]  Loss: 0.0550  Acc: 98.44%\n",
      "Epoch 2 [469/938]  Loss: 0.1130  Acc: 95.31%\n",
      "Epoch 2 [470/938]  Loss: 0.0924  Acc: 98.44%\n",
      "Epoch 2 [471/938]  Loss: 0.1483  Acc: 96.88%\n",
      "Epoch 2 [472/938]  Loss: 0.1297  Acc: 98.44%\n",
      "Epoch 2 [473/938]  Loss: 0.1834  Acc: 92.19%\n",
      "Epoch 2 [474/938]  Loss: 0.0933  Acc: 98.44%\n",
      "Epoch 2 [475/938]  Loss: 0.1879  Acc: 92.19%\n",
      "Epoch 2 [476/938]  Loss: 0.0699  Acc: 98.44%\n",
      "Epoch 2 [477/938]  Loss: 0.1084  Acc: 96.88%\n",
      "Epoch 2 [478/938]  Loss: 0.1853  Acc: 93.75%\n",
      "Epoch 2 [479/938]  Loss: 0.0434  Acc: 100.00%\n",
      "Epoch 2 [480/938]  Loss: 0.1185  Acc: 98.44%\n",
      "Epoch 2 [481/938]  Loss: 0.2034  Acc: 93.75%\n",
      "Epoch 2 [482/938]  Loss: 0.0858  Acc: 98.44%\n",
      "Epoch 2 [483/938]  Loss: 0.0689  Acc: 98.44%\n",
      "Epoch 2 [484/938]  Loss: 0.0382  Acc: 100.00%\n",
      "Epoch 2 [485/938]  Loss: 0.1767  Acc: 93.75%\n",
      "Epoch 2 [486/938]  Loss: 0.0759  Acc: 96.88%\n",
      "Epoch 2 [487/938]  Loss: 0.2485  Acc: 92.19%\n",
      "Epoch 2 [488/938]  Loss: 0.0736  Acc: 98.44%\n",
      "Epoch 2 [489/938]  Loss: 0.3348  Acc: 92.19%\n",
      "Epoch 2 [490/938]  Loss: 0.1955  Acc: 95.31%\n",
      "Epoch 2 [491/938]  Loss: 0.0768  Acc: 98.44%\n",
      "Epoch 2 [492/938]  Loss: 0.1372  Acc: 93.75%\n",
      "Epoch 2 [493/938]  Loss: 0.0957  Acc: 96.88%\n",
      "Epoch 2 [494/938]  Loss: 0.0704  Acc: 98.44%\n",
      "Epoch 2 [495/938]  Loss: 0.0499  Acc: 98.44%\n",
      "Epoch 2 [496/938]  Loss: 0.0599  Acc: 98.44%\n",
      "Epoch 2 [497/938]  Loss: 0.0731  Acc: 96.88%\n",
      "Epoch 2 [498/938]  Loss: 0.1733  Acc: 92.19%\n",
      "Epoch 2 [499/938]  Loss: 0.2069  Acc: 95.31%\n",
      "Epoch 2 [500/938]  Loss: 0.0453  Acc: 98.44%\n",
      "Epoch 2 [501/938]  Loss: 0.1753  Acc: 90.62%\n",
      "Epoch 2 [502/938]  Loss: 0.1933  Acc: 93.75%\n",
      "Epoch 2 [503/938]  Loss: 0.0749  Acc: 96.88%\n",
      "Epoch 2 [504/938]  Loss: 0.0471  Acc: 98.44%\n",
      "Epoch 2 [505/938]  Loss: 0.0579  Acc: 100.00%\n",
      "Epoch 2 [506/938]  Loss: 0.0302  Acc: 100.00%\n",
      "Epoch 2 [507/938]  Loss: 0.0858  Acc: 93.75%\n",
      "Epoch 2 [508/938]  Loss: 0.1324  Acc: 93.75%\n",
      "Epoch 2 [509/938]  Loss: 0.2870  Acc: 92.19%\n",
      "Epoch 2 [510/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [511/938]  Loss: 0.1069  Acc: 98.44%\n",
      "Epoch 2 [512/938]  Loss: 0.0603  Acc: 98.44%\n",
      "Epoch 2 [513/938]  Loss: 0.1831  Acc: 92.19%\n",
      "Epoch 2 [514/938]  Loss: 0.1004  Acc: 96.88%\n",
      "Epoch 2 [515/938]  Loss: 0.1589  Acc: 96.88%\n",
      "Epoch 2 [516/938]  Loss: 0.2156  Acc: 96.88%\n",
      "Epoch 2 [517/938]  Loss: 0.1454  Acc: 95.31%\n",
      "Epoch 2 [518/938]  Loss: 0.0942  Acc: 98.44%\n",
      "Epoch 2 [519/938]  Loss: 0.1196  Acc: 95.31%\n",
      "Epoch 2 [520/938]  Loss: 0.1112  Acc: 98.44%\n",
      "Epoch 2 [521/938]  Loss: 0.1054  Acc: 95.31%\n",
      "Epoch 2 [522/938]  Loss: 0.0981  Acc: 98.44%\n",
      "Epoch 2 [523/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [524/938]  Loss: 0.1282  Acc: 92.19%\n",
      "Epoch 2 [525/938]  Loss: 0.1323  Acc: 95.31%\n",
      "Epoch 2 [526/938]  Loss: 0.0650  Acc: 98.44%\n",
      "Epoch 2 [527/938]  Loss: 0.0430  Acc: 100.00%\n",
      "Epoch 2 [528/938]  Loss: 0.1228  Acc: 95.31%\n",
      "Epoch 2 [529/938]  Loss: 0.1509  Acc: 96.88%\n",
      "Epoch 2 [530/938]  Loss: 0.0349  Acc: 100.00%\n",
      "Epoch 2 [531/938]  Loss: 0.0411  Acc: 98.44%\n",
      "Epoch 2 [532/938]  Loss: 0.0997  Acc: 98.44%\n",
      "Epoch 2 [533/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [534/938]  Loss: 0.0639  Acc: 100.00%\n",
      "Epoch 2 [535/938]  Loss: 0.2514  Acc: 92.19%\n",
      "Epoch 2 [536/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [537/938]  Loss: 0.2372  Acc: 92.19%\n",
      "Epoch 2 [538/938]  Loss: 0.0262  Acc: 100.00%\n",
      "Epoch 2 [539/938]  Loss: 0.1985  Acc: 95.31%\n",
      "Epoch 2 [540/938]  Loss: 0.0728  Acc: 98.44%\n",
      "Epoch 2 [541/938]  Loss: 0.2294  Acc: 92.19%\n",
      "Epoch 2 [542/938]  Loss: 0.0347  Acc: 98.44%\n",
      "Epoch 2 [543/938]  Loss: 0.0713  Acc: 98.44%\n",
      "Epoch 2 [544/938]  Loss: 0.0395  Acc: 98.44%\n",
      "Epoch 2 [545/938]  Loss: 0.0431  Acc: 100.00%\n",
      "Epoch 2 [546/938]  Loss: 0.1619  Acc: 92.19%\n",
      "Epoch 2 [547/938]  Loss: 0.0839  Acc: 96.88%\n",
      "Epoch 2 [548/938]  Loss: 0.0658  Acc: 96.88%\n",
      "Epoch 2 [549/938]  Loss: 0.0574  Acc: 98.44%\n",
      "Epoch 2 [550/938]  Loss: 0.1257  Acc: 96.88%\n",
      "Epoch 2 [551/938]  Loss: 0.0764  Acc: 96.88%\n",
      "Epoch 2 [552/938]  Loss: 0.0981  Acc: 96.88%\n",
      "Epoch 2 [553/938]  Loss: 0.1162  Acc: 95.31%\n",
      "Epoch 2 [554/938]  Loss: 0.2020  Acc: 95.31%\n",
      "Epoch 2 [555/938]  Loss: 0.0735  Acc: 96.88%\n",
      "Epoch 2 [556/938]  Loss: 0.1213  Acc: 95.31%\n",
      "Epoch 2 [557/938]  Loss: 0.0734  Acc: 96.88%\n",
      "Epoch 2 [558/938]  Loss: 0.1017  Acc: 96.88%\n",
      "Epoch 2 [559/938]  Loss: 0.0379  Acc: 100.00%\n",
      "Epoch 2 [560/938]  Loss: 0.0301  Acc: 100.00%\n",
      "Epoch 2 [561/938]  Loss: 0.0252  Acc: 100.00%\n",
      "Epoch 2 [562/938]  Loss: 0.0393  Acc: 98.44%\n",
      "Epoch 2 [563/938]  Loss: 0.0586  Acc: 96.88%\n",
      "Epoch 2 [564/938]  Loss: 0.1634  Acc: 95.31%\n",
      "Epoch 2 [565/938]  Loss: 0.0529  Acc: 98.44%\n",
      "Epoch 2 [566/938]  Loss: 0.1053  Acc: 98.44%\n",
      "Epoch 2 [567/938]  Loss: 0.0396  Acc: 98.44%\n",
      "Epoch 2 [568/938]  Loss: 0.1093  Acc: 96.88%\n",
      "Epoch 2 [569/938]  Loss: 0.1259  Acc: 96.88%\n",
      "Epoch 2 [570/938]  Loss: 0.2124  Acc: 95.31%\n",
      "Epoch 2 [571/938]  Loss: 0.1465  Acc: 96.88%\n",
      "Epoch 2 [572/938]  Loss: 0.0798  Acc: 98.44%\n",
      "Epoch 2 [573/938]  Loss: 0.1033  Acc: 95.31%\n",
      "Epoch 2 [574/938]  Loss: 0.1708  Acc: 95.31%\n",
      "Epoch 2 [575/938]  Loss: 0.0410  Acc: 98.44%\n",
      "Epoch 2 [516/938]  Loss: 0.2156  Acc: 96.88%\n",
      "Epoch 2 [517/938]  Loss: 0.1454  Acc: 95.31%\n",
      "Epoch 2 [518/938]  Loss: 0.0942  Acc: 98.44%\n",
      "Epoch 2 [519/938]  Loss: 0.1196  Acc: 95.31%\n",
      "Epoch 2 [520/938]  Loss: 0.1112  Acc: 98.44%\n",
      "Epoch 2 [521/938]  Loss: 0.1054  Acc: 95.31%\n",
      "Epoch 2 [522/938]  Loss: 0.0981  Acc: 98.44%\n",
      "Epoch 2 [523/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [524/938]  Loss: 0.1282  Acc: 92.19%\n",
      "Epoch 2 [525/938]  Loss: 0.1323  Acc: 95.31%\n",
      "Epoch 2 [526/938]  Loss: 0.0650  Acc: 98.44%\n",
      "Epoch 2 [527/938]  Loss: 0.0430  Acc: 100.00%\n",
      "Epoch 2 [528/938]  Loss: 0.1228  Acc: 95.31%\n",
      "Epoch 2 [529/938]  Loss: 0.1509  Acc: 96.88%\n",
      "Epoch 2 [530/938]  Loss: 0.0349  Acc: 100.00%\n",
      "Epoch 2 [531/938]  Loss: 0.0411  Acc: 98.44%\n",
      "Epoch 2 [532/938]  Loss: 0.0997  Acc: 98.44%\n",
      "Epoch 2 [533/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [534/938]  Loss: 0.0639  Acc: 100.00%\n",
      "Epoch 2 [535/938]  Loss: 0.2514  Acc: 92.19%\n",
      "Epoch 2 [536/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [537/938]  Loss: 0.2372  Acc: 92.19%\n",
      "Epoch 2 [538/938]  Loss: 0.0262  Acc: 100.00%\n",
      "Epoch 2 [539/938]  Loss: 0.1985  Acc: 95.31%\n",
      "Epoch 2 [540/938]  Loss: 0.0728  Acc: 98.44%\n",
      "Epoch 2 [541/938]  Loss: 0.2294  Acc: 92.19%\n",
      "Epoch 2 [542/938]  Loss: 0.0347  Acc: 98.44%\n",
      "Epoch 2 [543/938]  Loss: 0.0713  Acc: 98.44%\n",
      "Epoch 2 [544/938]  Loss: 0.0395  Acc: 98.44%\n",
      "Epoch 2 [545/938]  Loss: 0.0431  Acc: 100.00%\n",
      "Epoch 2 [546/938]  Loss: 0.1619  Acc: 92.19%\n",
      "Epoch 2 [547/938]  Loss: 0.0839  Acc: 96.88%\n",
      "Epoch 2 [548/938]  Loss: 0.0658  Acc: 96.88%\n",
      "Epoch 2 [549/938]  Loss: 0.0574  Acc: 98.44%\n",
      "Epoch 2 [550/938]  Loss: 0.1257  Acc: 96.88%\n",
      "Epoch 2 [551/938]  Loss: 0.0764  Acc: 96.88%\n",
      "Epoch 2 [552/938]  Loss: 0.0981  Acc: 96.88%\n",
      "Epoch 2 [553/938]  Loss: 0.1162  Acc: 95.31%\n",
      "Epoch 2 [554/938]  Loss: 0.2020  Acc: 95.31%\n",
      "Epoch 2 [555/938]  Loss: 0.0735  Acc: 96.88%\n",
      "Epoch 2 [556/938]  Loss: 0.1213  Acc: 95.31%\n",
      "Epoch 2 [557/938]  Loss: 0.0734  Acc: 96.88%\n",
      "Epoch 2 [558/938]  Loss: 0.1017  Acc: 96.88%\n",
      "Epoch 2 [559/938]  Loss: 0.0379  Acc: 100.00%\n",
      "Epoch 2 [560/938]  Loss: 0.0301  Acc: 100.00%\n",
      "Epoch 2 [561/938]  Loss: 0.0252  Acc: 100.00%\n",
      "Epoch 2 [562/938]  Loss: 0.0393  Acc: 98.44%\n",
      "Epoch 2 [563/938]  Loss: 0.0586  Acc: 96.88%\n",
      "Epoch 2 [564/938]  Loss: 0.1634  Acc: 95.31%\n",
      "Epoch 2 [565/938]  Loss: 0.0529  Acc: 98.44%\n",
      "Epoch 2 [566/938]  Loss: 0.1053  Acc: 98.44%\n",
      "Epoch 2 [567/938]  Loss: 0.0396  Acc: 98.44%\n",
      "Epoch 2 [568/938]  Loss: 0.1093  Acc: 96.88%\n",
      "Epoch 2 [569/938]  Loss: 0.1259  Acc: 96.88%\n",
      "Epoch 2 [570/938]  Loss: 0.2124  Acc: 95.31%\n",
      "Epoch 2 [571/938]  Loss: 0.1465  Acc: 96.88%\n",
      "Epoch 2 [572/938]  Loss: 0.0798  Acc: 98.44%\n",
      "Epoch 2 [573/938]  Loss: 0.1033  Acc: 95.31%\n",
      "Epoch 2 [574/938]  Loss: 0.1708  Acc: 95.31%\n",
      "Epoch 2 [575/938]  Loss: 0.0410  Acc: 98.44%\n",
      "Epoch 2 [576/938]  Loss: 0.1032  Acc: 96.88%\n",
      "Epoch 2 [577/938]  Loss: 0.0738  Acc: 98.44%\n",
      "Epoch 2 [578/938]  Loss: 0.1078  Acc: 96.88%\n",
      "Epoch 2 [579/938]  Loss: 0.0515  Acc: 98.44%\n",
      "Epoch 2 [580/938]  Loss: 0.0433  Acc: 100.00%\n",
      "Epoch 2 [581/938]  Loss: 0.1184  Acc: 95.31%\n",
      "Epoch 2 [582/938]  Loss: 0.1279  Acc: 93.75%\n",
      "Epoch 2 [583/938]  Loss: 0.0784  Acc: 96.88%\n",
      "Epoch 2 [584/938]  Loss: 0.1034  Acc: 95.31%\n",
      "Epoch 2 [585/938]  Loss: 0.0417  Acc: 98.44%\n",
      "Epoch 2 [586/938]  Loss: 0.0882  Acc: 96.88%\n",
      "Epoch 2 [587/938]  Loss: 0.0682  Acc: 98.44%\n",
      "Epoch 2 [588/938]  Loss: 0.1195  Acc: 95.31%\n",
      "Epoch 2 [589/938]  Loss: 0.1258  Acc: 96.88%\n",
      "Epoch 2 [590/938]  Loss: 0.0901  Acc: 95.31%\n",
      "Epoch 2 [591/938]  Loss: 0.1134  Acc: 93.75%\n",
      "Epoch 2 [592/938]  Loss: 0.1747  Acc: 95.31%\n",
      "Epoch 2 [593/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [594/938]  Loss: 0.0964  Acc: 95.31%\n",
      "Epoch 2 [595/938]  Loss: 0.0214  Acc: 100.00%\n",
      "Epoch 2 [596/938]  Loss: 0.1820  Acc: 96.88%\n",
      "Epoch 2 [597/938]  Loss: 0.1177  Acc: 96.88%\n",
      "Epoch 2 [598/938]  Loss: 0.1102  Acc: 95.31%\n",
      "Epoch 2 [599/938]  Loss: 0.0998  Acc: 96.88%\n",
      "Epoch 2 [600/938]  Loss: 0.1730  Acc: 95.31%\n",
      "Epoch 2 [601/938]  Loss: 0.0436  Acc: 98.44%\n",
      "Epoch 2 [602/938]  Loss: 0.0280  Acc: 100.00%\n",
      "Epoch 2 [603/938]  Loss: 0.0417  Acc: 98.44%\n",
      "Epoch 2 [604/938]  Loss: 0.1299  Acc: 93.75%\n",
      "Epoch 2 [605/938]  Loss: 0.1071  Acc: 96.88%\n",
      "Epoch 2 [606/938]  Loss: 0.1335  Acc: 95.31%\n",
      "Epoch 2 [607/938]  Loss: 0.1336  Acc: 95.31%\n",
      "Epoch 2 [608/938]  Loss: 0.0475  Acc: 100.00%\n",
      "Epoch 2 [609/938]  Loss: 0.0387  Acc: 100.00%\n",
      "Epoch 2 [610/938]  Loss: 0.0887  Acc: 95.31%\n",
      "Epoch 2 [611/938]  Loss: 0.0776  Acc: 96.88%\n",
      "Epoch 2 [612/938]  Loss: 0.1726  Acc: 92.19%\n",
      "Epoch 2 [613/938]  Loss: 0.0887  Acc: 96.88%\n",
      "Epoch 2 [614/938]  Loss: 0.1810  Acc: 96.88%\n",
      "Epoch 2 [615/938]  Loss: 0.0949  Acc: 98.44%\n",
      "Epoch 2 [616/938]  Loss: 0.0209  Acc: 100.00%\n",
      "Epoch 2 [617/938]  Loss: 0.1584  Acc: 93.75%\n",
      "Epoch 2 [618/938]  Loss: 0.2121  Acc: 93.75%\n",
      "Epoch 2 [619/938]  Loss: 0.1643  Acc: 93.75%\n",
      "Epoch 2 [620/938]  Loss: 0.0634  Acc: 96.88%\n",
      "Epoch 2 [621/938]  Loss: 0.0944  Acc: 96.88%\n",
      "Epoch 2 [622/938]  Loss: 0.3347  Acc: 90.62%\n",
      "Epoch 2 [623/938]  Loss: 0.1888  Acc: 95.31%\n",
      "Epoch 2 [624/938]  Loss: 0.0474  Acc: 98.44%\n",
      "Epoch 2 [625/938]  Loss: 0.2029  Acc: 96.88%\n",
      "Epoch 2 [626/938]  Loss: 0.0585  Acc: 96.88%\n",
      "Epoch 2 [627/938]  Loss: 0.1189  Acc: 98.44%\n",
      "Epoch 2 [628/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [629/938]  Loss: 0.0310  Acc: 100.00%\n",
      "Epoch 2 [630/938]  Loss: 0.1223  Acc: 93.75%\n",
      "Epoch 2 [631/938]  Loss: 0.0411  Acc: 98.44%\n",
      "Epoch 2 [632/938]  Loss: 0.1457  Acc: 93.75%\n",
      "Epoch 2 [633/938]  Loss: 0.0711  Acc: 96.88%\n",
      "Epoch 2 [634/938]  Loss: 0.0608  Acc: 98.44%\n",
      "Epoch 2 [635/938]  Loss: 0.0555  Acc: 98.44%\n",
      "Epoch 2 [576/938]  Loss: 0.1032  Acc: 96.88%\n",
      "Epoch 2 [577/938]  Loss: 0.0738  Acc: 98.44%\n",
      "Epoch 2 [578/938]  Loss: 0.1078  Acc: 96.88%\n",
      "Epoch 2 [579/938]  Loss: 0.0515  Acc: 98.44%\n",
      "Epoch 2 [580/938]  Loss: 0.0433  Acc: 100.00%\n",
      "Epoch 2 [581/938]  Loss: 0.1184  Acc: 95.31%\n",
      "Epoch 2 [582/938]  Loss: 0.1279  Acc: 93.75%\n",
      "Epoch 2 [583/938]  Loss: 0.0784  Acc: 96.88%\n",
      "Epoch 2 [584/938]  Loss: 0.1034  Acc: 95.31%\n",
      "Epoch 2 [585/938]  Loss: 0.0417  Acc: 98.44%\n",
      "Epoch 2 [586/938]  Loss: 0.0882  Acc: 96.88%\n",
      "Epoch 2 [587/938]  Loss: 0.0682  Acc: 98.44%\n",
      "Epoch 2 [588/938]  Loss: 0.1195  Acc: 95.31%\n",
      "Epoch 2 [589/938]  Loss: 0.1258  Acc: 96.88%\n",
      "Epoch 2 [590/938]  Loss: 0.0901  Acc: 95.31%\n",
      "Epoch 2 [591/938]  Loss: 0.1134  Acc: 93.75%\n",
      "Epoch 2 [592/938]  Loss: 0.1747  Acc: 95.31%\n",
      "Epoch 2 [593/938]  Loss: 0.0686  Acc: 98.44%\n",
      "Epoch 2 [594/938]  Loss: 0.0964  Acc: 95.31%\n",
      "Epoch 2 [595/938]  Loss: 0.0214  Acc: 100.00%\n",
      "Epoch 2 [596/938]  Loss: 0.1820  Acc: 96.88%\n",
      "Epoch 2 [597/938]  Loss: 0.1177  Acc: 96.88%\n",
      "Epoch 2 [598/938]  Loss: 0.1102  Acc: 95.31%\n",
      "Epoch 2 [599/938]  Loss: 0.0998  Acc: 96.88%\n",
      "Epoch 2 [600/938]  Loss: 0.1730  Acc: 95.31%\n",
      "Epoch 2 [601/938]  Loss: 0.0436  Acc: 98.44%\n",
      "Epoch 2 [602/938]  Loss: 0.0280  Acc: 100.00%\n",
      "Epoch 2 [603/938]  Loss: 0.0417  Acc: 98.44%\n",
      "Epoch 2 [604/938]  Loss: 0.1299  Acc: 93.75%\n",
      "Epoch 2 [605/938]  Loss: 0.1071  Acc: 96.88%\n",
      "Epoch 2 [606/938]  Loss: 0.1335  Acc: 95.31%\n",
      "Epoch 2 [607/938]  Loss: 0.1336  Acc: 95.31%\n",
      "Epoch 2 [608/938]  Loss: 0.0475  Acc: 100.00%\n",
      "Epoch 2 [609/938]  Loss: 0.0387  Acc: 100.00%\n",
      "Epoch 2 [610/938]  Loss: 0.0887  Acc: 95.31%\n",
      "Epoch 2 [611/938]  Loss: 0.0776  Acc: 96.88%\n",
      "Epoch 2 [612/938]  Loss: 0.1726  Acc: 92.19%\n",
      "Epoch 2 [613/938]  Loss: 0.0887  Acc: 96.88%\n",
      "Epoch 2 [614/938]  Loss: 0.1810  Acc: 96.88%\n",
      "Epoch 2 [615/938]  Loss: 0.0949  Acc: 98.44%\n",
      "Epoch 2 [616/938]  Loss: 0.0209  Acc: 100.00%\n",
      "Epoch 2 [617/938]  Loss: 0.1584  Acc: 93.75%\n",
      "Epoch 2 [618/938]  Loss: 0.2121  Acc: 93.75%\n",
      "Epoch 2 [619/938]  Loss: 0.1643  Acc: 93.75%\n",
      "Epoch 2 [620/938]  Loss: 0.0634  Acc: 96.88%\n",
      "Epoch 2 [621/938]  Loss: 0.0944  Acc: 96.88%\n",
      "Epoch 2 [622/938]  Loss: 0.3347  Acc: 90.62%\n",
      "Epoch 2 [623/938]  Loss: 0.1888  Acc: 95.31%\n",
      "Epoch 2 [624/938]  Loss: 0.0474  Acc: 98.44%\n",
      "Epoch 2 [625/938]  Loss: 0.2029  Acc: 96.88%\n",
      "Epoch 2 [626/938]  Loss: 0.0585  Acc: 96.88%\n",
      "Epoch 2 [627/938]  Loss: 0.1189  Acc: 98.44%\n",
      "Epoch 2 [628/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [629/938]  Loss: 0.0310  Acc: 100.00%\n",
      "Epoch 2 [630/938]  Loss: 0.1223  Acc: 93.75%\n",
      "Epoch 2 [631/938]  Loss: 0.0411  Acc: 98.44%\n",
      "Epoch 2 [632/938]  Loss: 0.1457  Acc: 93.75%\n",
      "Epoch 2 [633/938]  Loss: 0.0711  Acc: 96.88%\n",
      "Epoch 2 [634/938]  Loss: 0.0608  Acc: 98.44%\n",
      "Epoch 2 [635/938]  Loss: 0.0555  Acc: 98.44%\n",
      "Epoch 2 [636/938]  Loss: 0.1477  Acc: 95.31%\n",
      "Epoch 2 [637/938]  Loss: 0.2422  Acc: 93.75%\n",
      "Epoch 2 [638/938]  Loss: 0.0817  Acc: 98.44%\n",
      "Epoch 2 [639/938]  Loss: 0.2233  Acc: 93.75%\n",
      "Epoch 2 [640/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [641/938]  Loss: 0.1194  Acc: 98.44%\n",
      "Epoch 2 [642/938]  Loss: 0.0940  Acc: 96.88%\n",
      "Epoch 2 [643/938]  Loss: 0.0862  Acc: 96.88%\n",
      "Epoch 2 [644/938]  Loss: 0.0479  Acc: 98.44%\n",
      "Epoch 2 [645/938]  Loss: 0.1412  Acc: 95.31%\n",
      "Epoch 2 [646/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [647/938]  Loss: 0.1764  Acc: 92.19%\n",
      "Epoch 2 [648/938]  Loss: 0.1573  Acc: 98.44%\n",
      "Epoch 2 [649/938]  Loss: 0.0777  Acc: 96.88%\n",
      "Epoch 2 [650/938]  Loss: 0.0524  Acc: 98.44%\n",
      "Epoch 2 [651/938]  Loss: 0.0606  Acc: 98.44%\n",
      "Epoch 2 [652/938]  Loss: 0.1512  Acc: 95.31%\n",
      "Epoch 2 [653/938]  Loss: 0.0295  Acc: 100.00%\n",
      "Epoch 2 [654/938]  Loss: 0.1201  Acc: 96.88%\n",
      "Epoch 2 [655/938]  Loss: 0.1896  Acc: 95.31%\n",
      "Epoch 2 [656/938]  Loss: 0.0561  Acc: 98.44%\n",
      "Epoch 2 [657/938]  Loss: 0.0782  Acc: 96.88%\n",
      "Epoch 2 [658/938]  Loss: 0.0824  Acc: 98.44%\n",
      "Epoch 2 [659/938]  Loss: 0.0342  Acc: 100.00%\n",
      "Epoch 2 [660/938]  Loss: 0.0671  Acc: 98.44%\n",
      "Epoch 2 [661/938]  Loss: 0.1762  Acc: 96.88%\n",
      "Epoch 2 [662/938]  Loss: 0.0996  Acc: 95.31%\n",
      "Epoch 2 [663/938]  Loss: 0.1104  Acc: 96.88%\n",
      "Epoch 2 [664/938]  Loss: 0.1066  Acc: 98.44%\n",
      "Epoch 2 [665/938]  Loss: 0.1892  Acc: 95.31%\n",
      "Epoch 2 [666/938]  Loss: 0.0805  Acc: 96.88%\n",
      "Epoch 2 [667/938]  Loss: 0.0598  Acc: 98.44%\n",
      "Epoch 2 [668/938]  Loss: 0.1427  Acc: 95.31%\n",
      "Epoch 2 [669/938]  Loss: 0.0298  Acc: 100.00%\n",
      "Epoch 2 [670/938]  Loss: 0.0299  Acc: 100.00%\n",
      "Epoch 2 [671/938]  Loss: 0.0409  Acc: 98.44%\n",
      "Epoch 2 [672/938]  Loss: 0.1468  Acc: 95.31%\n",
      "Epoch 2 [673/938]  Loss: 0.1340  Acc: 98.44%\n",
      "Epoch 2 [674/938]  Loss: 0.0552  Acc: 98.44%\n",
      "Epoch 2 [675/938]  Loss: 0.0792  Acc: 98.44%\n",
      "Epoch 2 [676/938]  Loss: 0.0801  Acc: 96.88%\n",
      "Epoch 2 [677/938]  Loss: 0.2219  Acc: 93.75%\n",
      "Epoch 2 [678/938]  Loss: 0.1206  Acc: 96.88%\n",
      "Epoch 2 [679/938]  Loss: 0.0918  Acc: 96.88%\n",
      "Epoch 2 [680/938]  Loss: 0.0849  Acc: 96.88%\n",
      "Epoch 2 [681/938]  Loss: 0.1145  Acc: 93.75%\n",
      "Epoch 2 [682/938]  Loss: 0.0574  Acc: 96.88%\n",
      "Epoch 2 [683/938]  Loss: 0.1814  Acc: 92.19%\n",
      "Epoch 2 [684/938]  Loss: 0.0348  Acc: 100.00%\n",
      "Epoch 2 [685/938]  Loss: 0.0594  Acc: 98.44%\n",
      "Epoch 2 [686/938]  Loss: 0.1280  Acc: 95.31%\n",
      "Epoch 2 [687/938]  Loss: 0.0443  Acc: 100.00%\n",
      "Epoch 2 [688/938]  Loss: 0.1503  Acc: 92.19%\n",
      "Epoch 2 [689/938]  Loss: 0.0682  Acc: 98.44%\n",
      "Epoch 2 [690/938]  Loss: 0.0733  Acc: 98.44%\n",
      "Epoch 2 [691/938]  Loss: 0.0343  Acc: 100.00%\n",
      "Epoch 2 [692/938]  Loss: 0.0751  Acc: 96.88%\n",
      "Epoch 2 [693/938]  Loss: 0.0620  Acc: 96.88%\n",
      "Epoch 2 [694/938]  Loss: 0.1666  Acc: 95.31%\n",
      "Epoch 2 [695/938]  Loss: 0.1078  Acc: 98.44%\n",
      "Epoch 2 [696/938]  Loss: 0.1279  Acc: 93.75%\n",
      "Epoch 2 [636/938]  Loss: 0.1477  Acc: 95.31%\n",
      "Epoch 2 [637/938]  Loss: 0.2422  Acc: 93.75%\n",
      "Epoch 2 [638/938]  Loss: 0.0817  Acc: 98.44%\n",
      "Epoch 2 [639/938]  Loss: 0.2233  Acc: 93.75%\n",
      "Epoch 2 [640/938]  Loss: 0.1397  Acc: 95.31%\n",
      "Epoch 2 [641/938]  Loss: 0.1194  Acc: 98.44%\n",
      "Epoch 2 [642/938]  Loss: 0.0940  Acc: 96.88%\n",
      "Epoch 2 [643/938]  Loss: 0.0862  Acc: 96.88%\n",
      "Epoch 2 [644/938]  Loss: 0.0479  Acc: 98.44%\n",
      "Epoch 2 [645/938]  Loss: 0.1412  Acc: 95.31%\n",
      "Epoch 2 [646/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [647/938]  Loss: 0.1764  Acc: 92.19%\n",
      "Epoch 2 [648/938]  Loss: 0.1573  Acc: 98.44%\n",
      "Epoch 2 [649/938]  Loss: 0.0777  Acc: 96.88%\n",
      "Epoch 2 [650/938]  Loss: 0.0524  Acc: 98.44%\n",
      "Epoch 2 [651/938]  Loss: 0.0606  Acc: 98.44%\n",
      "Epoch 2 [652/938]  Loss: 0.1512  Acc: 95.31%\n",
      "Epoch 2 [653/938]  Loss: 0.0295  Acc: 100.00%\n",
      "Epoch 2 [654/938]  Loss: 0.1201  Acc: 96.88%\n",
      "Epoch 2 [655/938]  Loss: 0.1896  Acc: 95.31%\n",
      "Epoch 2 [656/938]  Loss: 0.0561  Acc: 98.44%\n",
      "Epoch 2 [657/938]  Loss: 0.0782  Acc: 96.88%\n",
      "Epoch 2 [658/938]  Loss: 0.0824  Acc: 98.44%\n",
      "Epoch 2 [659/938]  Loss: 0.0342  Acc: 100.00%\n",
      "Epoch 2 [660/938]  Loss: 0.0671  Acc: 98.44%\n",
      "Epoch 2 [661/938]  Loss: 0.1762  Acc: 96.88%\n",
      "Epoch 2 [662/938]  Loss: 0.0996  Acc: 95.31%\n",
      "Epoch 2 [663/938]  Loss: 0.1104  Acc: 96.88%\n",
      "Epoch 2 [664/938]  Loss: 0.1066  Acc: 98.44%\n",
      "Epoch 2 [665/938]  Loss: 0.1892  Acc: 95.31%\n",
      "Epoch 2 [666/938]  Loss: 0.0805  Acc: 96.88%\n",
      "Epoch 2 [667/938]  Loss: 0.0598  Acc: 98.44%\n",
      "Epoch 2 [668/938]  Loss: 0.1427  Acc: 95.31%\n",
      "Epoch 2 [669/938]  Loss: 0.0298  Acc: 100.00%\n",
      "Epoch 2 [670/938]  Loss: 0.0299  Acc: 100.00%\n",
      "Epoch 2 [671/938]  Loss: 0.0409  Acc: 98.44%\n",
      "Epoch 2 [672/938]  Loss: 0.1468  Acc: 95.31%\n",
      "Epoch 2 [673/938]  Loss: 0.1340  Acc: 98.44%\n",
      "Epoch 2 [674/938]  Loss: 0.0552  Acc: 98.44%\n",
      "Epoch 2 [675/938]  Loss: 0.0792  Acc: 98.44%\n",
      "Epoch 2 [676/938]  Loss: 0.0801  Acc: 96.88%\n",
      "Epoch 2 [677/938]  Loss: 0.2219  Acc: 93.75%\n",
      "Epoch 2 [678/938]  Loss: 0.1206  Acc: 96.88%\n",
      "Epoch 2 [679/938]  Loss: 0.0918  Acc: 96.88%\n",
      "Epoch 2 [680/938]  Loss: 0.0849  Acc: 96.88%\n",
      "Epoch 2 [681/938]  Loss: 0.1145  Acc: 93.75%\n",
      "Epoch 2 [682/938]  Loss: 0.0574  Acc: 96.88%\n",
      "Epoch 2 [683/938]  Loss: 0.1814  Acc: 92.19%\n",
      "Epoch 2 [684/938]  Loss: 0.0348  Acc: 100.00%\n",
      "Epoch 2 [685/938]  Loss: 0.0594  Acc: 98.44%\n",
      "Epoch 2 [686/938]  Loss: 0.1280  Acc: 95.31%\n",
      "Epoch 2 [687/938]  Loss: 0.0443  Acc: 100.00%\n",
      "Epoch 2 [688/938]  Loss: 0.1503  Acc: 92.19%\n",
      "Epoch 2 [689/938]  Loss: 0.0682  Acc: 98.44%\n",
      "Epoch 2 [690/938]  Loss: 0.0733  Acc: 98.44%\n",
      "Epoch 2 [691/938]  Loss: 0.0343  Acc: 100.00%\n",
      "Epoch 2 [692/938]  Loss: 0.0751  Acc: 96.88%\n",
      "Epoch 2 [693/938]  Loss: 0.0620  Acc: 96.88%\n",
      "Epoch 2 [694/938]  Loss: 0.1666  Acc: 95.31%\n",
      "Epoch 2 [695/938]  Loss: 0.1078  Acc: 98.44%\n",
      "Epoch 2 [696/938]  Loss: 0.1279  Acc: 93.75%\n",
      "Epoch 2 [697/938]  Loss: 0.0777  Acc: 96.88%\n",
      "Epoch 2 [698/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [699/938]  Loss: 0.1021  Acc: 95.31%\n",
      "Epoch 2 [700/938]  Loss: 0.0271  Acc: 100.00%\n",
      "Epoch 2 [701/938]  Loss: 0.2870  Acc: 93.75%\n",
      "Epoch 2 [702/938]  Loss: 0.0875  Acc: 96.88%\n",
      "Epoch 2 [703/938]  Loss: 0.1392  Acc: 96.88%\n",
      "Epoch 2 [704/938]  Loss: 0.0761  Acc: 96.88%\n",
      "Epoch 2 [705/938]  Loss: 0.0638  Acc: 96.88%\n",
      "Epoch 2 [706/938]  Loss: 0.0741  Acc: 96.88%\n",
      "Epoch 2 [707/938]  Loss: 0.2878  Acc: 95.31%\n",
      "Epoch 2 [708/938]  Loss: 0.0920  Acc: 96.88%\n",
      "Epoch 2 [709/938]  Loss: 0.0830  Acc: 96.88%\n",
      "Epoch 2 [710/938]  Loss: 0.0285  Acc: 100.00%\n",
      "Epoch 2 [711/938]  Loss: 0.0656  Acc: 98.44%\n",
      "Epoch 2 [712/938]  Loss: 0.0889  Acc: 98.44%\n",
      "Epoch 2 [713/938]  Loss: 0.1980  Acc: 93.75%\n",
      "Epoch 2 [714/938]  Loss: 0.1938  Acc: 93.75%\n",
      "Epoch 2 [715/938]  Loss: 0.1583  Acc: 95.31%\n",
      "Epoch 2 [716/938]  Loss: 0.3185  Acc: 95.31%\n",
      "Epoch 2 [717/938]  Loss: 0.0725  Acc: 98.44%\n",
      "Epoch 2 [718/938]  Loss: 0.1379  Acc: 96.88%\n",
      "Epoch 2 [719/938]  Loss: 0.2110  Acc: 96.88%\n",
      "Epoch 2 [720/938]  Loss: 0.0236  Acc: 100.00%\n",
      "Epoch 2 [721/938]  Loss: 0.0611  Acc: 98.44%\n",
      "Epoch 2 [722/938]  Loss: 0.0800  Acc: 98.44%\n",
      "Epoch 2 [723/938]  Loss: 0.0300  Acc: 100.00%\n",
      "Epoch 2 [724/938]  Loss: 0.1411  Acc: 98.44%\n",
      "Epoch 2 [725/938]  Loss: 0.1579  Acc: 93.75%\n",
      "Epoch 2 [726/938]  Loss: 0.2005  Acc: 93.75%\n",
      "Epoch 2 [727/938]  Loss: 0.0316  Acc: 100.00%\n",
      "Epoch 2 [728/938]  Loss: 0.1728  Acc: 96.88%\n",
      "Epoch 2 [729/938]  Loss: 0.0907  Acc: 98.44%\n",
      "Epoch 2 [730/938]  Loss: 0.0668  Acc: 98.44%\n",
      "Epoch 2 [731/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [732/938]  Loss: 0.0591  Acc: 98.44%\n",
      "Epoch 2 [733/938]  Loss: 0.0435  Acc: 98.44%\n",
      "Epoch 2 [734/938]  Loss: 0.2434  Acc: 93.75%\n",
      "Epoch 2 [735/938]  Loss: 0.1756  Acc: 92.19%\n",
      "Epoch 2 [736/938]  Loss: 0.1483  Acc: 95.31%\n",
      "Epoch 2 [737/938]  Loss: 0.0198  Acc: 100.00%\n",
      "Epoch 2 [738/938]  Loss: 0.1594  Acc: 96.88%\n",
      "Epoch 2 [739/938]  Loss: 0.0604  Acc: 98.44%\n",
      "Epoch 2 [740/938]  Loss: 0.1042  Acc: 93.75%\n",
      "Epoch 2 [741/938]  Loss: 0.1612  Acc: 98.44%\n",
      "Epoch 2 [742/938]  Loss: 0.0434  Acc: 100.00%\n",
      "Epoch 2 [743/938]  Loss: 0.0496  Acc: 98.44%\n",
      "Epoch 2 [744/938]  Loss: 0.0712  Acc: 95.31%\n",
      "Epoch 2 [745/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [746/938]  Loss: 0.1204  Acc: 96.88%\n",
      "Epoch 2 [747/938]  Loss: 0.1859  Acc: 93.75%\n",
      "Epoch 2 [748/938]  Loss: 0.1227  Acc: 95.31%\n",
      "Epoch 2 [749/938]  Loss: 0.1046  Acc: 95.31%\n",
      "Epoch 2 [750/938]  Loss: 0.0791  Acc: 96.88%\n",
      "Epoch 2 [751/938]  Loss: 0.0706  Acc: 95.31%\n",
      "Epoch 2 [752/938]  Loss: 0.1288  Acc: 96.88%\n",
      "Epoch 2 [753/938]  Loss: 0.1388  Acc: 96.88%\n",
      "Epoch 2 [754/938]  Loss: 0.1153  Acc: 93.75%\n",
      "Epoch 2 [755/938]  Loss: 0.0406  Acc: 100.00%\n",
      "Epoch 2 [756/938]  Loss: 0.1430  Acc: 95.31%\n",
      "Epoch 2 [757/938]  Loss: 0.1039  Acc: 95.31%\n",
      "Epoch 2 [697/938]  Loss: 0.0777  Acc: 96.88%\n",
      "Epoch 2 [698/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [699/938]  Loss: 0.1021  Acc: 95.31%\n",
      "Epoch 2 [700/938]  Loss: 0.0271  Acc: 100.00%\n",
      "Epoch 2 [701/938]  Loss: 0.2870  Acc: 93.75%\n",
      "Epoch 2 [702/938]  Loss: 0.0875  Acc: 96.88%\n",
      "Epoch 2 [703/938]  Loss: 0.1392  Acc: 96.88%\n",
      "Epoch 2 [704/938]  Loss: 0.0761  Acc: 96.88%\n",
      "Epoch 2 [705/938]  Loss: 0.0638  Acc: 96.88%\n",
      "Epoch 2 [706/938]  Loss: 0.0741  Acc: 96.88%\n",
      "Epoch 2 [707/938]  Loss: 0.2878  Acc: 95.31%\n",
      "Epoch 2 [708/938]  Loss: 0.0920  Acc: 96.88%\n",
      "Epoch 2 [709/938]  Loss: 0.0830  Acc: 96.88%\n",
      "Epoch 2 [710/938]  Loss: 0.0285  Acc: 100.00%\n",
      "Epoch 2 [711/938]  Loss: 0.0656  Acc: 98.44%\n",
      "Epoch 2 [712/938]  Loss: 0.0889  Acc: 98.44%\n",
      "Epoch 2 [713/938]  Loss: 0.1980  Acc: 93.75%\n",
      "Epoch 2 [714/938]  Loss: 0.1938  Acc: 93.75%\n",
      "Epoch 2 [715/938]  Loss: 0.1583  Acc: 95.31%\n",
      "Epoch 2 [716/938]  Loss: 0.3185  Acc: 95.31%\n",
      "Epoch 2 [717/938]  Loss: 0.0725  Acc: 98.44%\n",
      "Epoch 2 [718/938]  Loss: 0.1379  Acc: 96.88%\n",
      "Epoch 2 [719/938]  Loss: 0.2110  Acc: 96.88%\n",
      "Epoch 2 [720/938]  Loss: 0.0236  Acc: 100.00%\n",
      "Epoch 2 [721/938]  Loss: 0.0611  Acc: 98.44%\n",
      "Epoch 2 [722/938]  Loss: 0.0800  Acc: 98.44%\n",
      "Epoch 2 [723/938]  Loss: 0.0300  Acc: 100.00%\n",
      "Epoch 2 [724/938]  Loss: 0.1411  Acc: 98.44%\n",
      "Epoch 2 [725/938]  Loss: 0.1579  Acc: 93.75%\n",
      "Epoch 2 [726/938]  Loss: 0.2005  Acc: 93.75%\n",
      "Epoch 2 [727/938]  Loss: 0.0316  Acc: 100.00%\n",
      "Epoch 2 [728/938]  Loss: 0.1728  Acc: 96.88%\n",
      "Epoch 2 [729/938]  Loss: 0.0907  Acc: 98.44%\n",
      "Epoch 2 [730/938]  Loss: 0.0668  Acc: 98.44%\n",
      "Epoch 2 [731/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [732/938]  Loss: 0.0591  Acc: 98.44%\n",
      "Epoch 2 [733/938]  Loss: 0.0435  Acc: 98.44%\n",
      "Epoch 2 [734/938]  Loss: 0.2434  Acc: 93.75%\n",
      "Epoch 2 [735/938]  Loss: 0.1756  Acc: 92.19%\n",
      "Epoch 2 [736/938]  Loss: 0.1483  Acc: 95.31%\n",
      "Epoch 2 [737/938]  Loss: 0.0198  Acc: 100.00%\n",
      "Epoch 2 [738/938]  Loss: 0.1594  Acc: 96.88%\n",
      "Epoch 2 [739/938]  Loss: 0.0604  Acc: 98.44%\n",
      "Epoch 2 [740/938]  Loss: 0.1042  Acc: 93.75%\n",
      "Epoch 2 [741/938]  Loss: 0.1612  Acc: 98.44%\n",
      "Epoch 2 [742/938]  Loss: 0.0434  Acc: 100.00%\n",
      "Epoch 2 [743/938]  Loss: 0.0496  Acc: 98.44%\n",
      "Epoch 2 [744/938]  Loss: 0.0712  Acc: 95.31%\n",
      "Epoch 2 [745/938]  Loss: 0.0710  Acc: 98.44%\n",
      "Epoch 2 [746/938]  Loss: 0.1204  Acc: 96.88%\n",
      "Epoch 2 [747/938]  Loss: 0.1859  Acc: 93.75%\n",
      "Epoch 2 [748/938]  Loss: 0.1227  Acc: 95.31%\n",
      "Epoch 2 [749/938]  Loss: 0.1046  Acc: 95.31%\n",
      "Epoch 2 [750/938]  Loss: 0.0791  Acc: 96.88%\n",
      "Epoch 2 [751/938]  Loss: 0.0706  Acc: 95.31%\n",
      "Epoch 2 [752/938]  Loss: 0.1288  Acc: 96.88%\n",
      "Epoch 2 [753/938]  Loss: 0.1388  Acc: 96.88%\n",
      "Epoch 2 [754/938]  Loss: 0.1153  Acc: 93.75%\n",
      "Epoch 2 [755/938]  Loss: 0.0406  Acc: 100.00%\n",
      "Epoch 2 [756/938]  Loss: 0.1430  Acc: 95.31%\n",
      "Epoch 2 [757/938]  Loss: 0.1039  Acc: 95.31%\n",
      "Epoch 2 [758/938]  Loss: 0.0545  Acc: 98.44%\n",
      "Epoch 2 [759/938]  Loss: 0.1292  Acc: 95.31%\n",
      "Epoch 2 [760/938]  Loss: 0.0467  Acc: 98.44%\n",
      "Epoch 2 [761/938]  Loss: 0.0676  Acc: 98.44%\n",
      "Epoch 2 [762/938]  Loss: 0.0975  Acc: 96.88%\n",
      "Epoch 2 [763/938]  Loss: 0.0677  Acc: 96.88%\n",
      "Epoch 2 [764/938]  Loss: 0.0648  Acc: 98.44%\n",
      "Epoch 2 [765/938]  Loss: 0.2956  Acc: 93.75%\n",
      "Epoch 2 [766/938]  Loss: 0.2564  Acc: 87.50%\n",
      "Epoch 2 [767/938]  Loss: 0.0425  Acc: 98.44%\n",
      "Epoch 2 [768/938]  Loss: 0.0769  Acc: 98.44%\n",
      "Epoch 2 [769/938]  Loss: 0.1360  Acc: 95.31%\n",
      "Epoch 2 [770/938]  Loss: 0.1111  Acc: 96.88%\n",
      "Epoch 2 [771/938]  Loss: 0.1187  Acc: 96.88%\n",
      "Epoch 2 [772/938]  Loss: 0.0805  Acc: 96.88%\n",
      "Epoch 2 [773/938]  Loss: 0.1122  Acc: 96.88%\n",
      "Epoch 2 [774/938]  Loss: 0.0607  Acc: 100.00%\n",
      "Epoch 2 [775/938]  Loss: 0.1503  Acc: 96.88%\n",
      "Epoch 2 [776/938]  Loss: 0.2366  Acc: 95.31%\n",
      "Epoch 2 [777/938]  Loss: 0.1140  Acc: 96.88%\n",
      "Epoch 2 [778/938]  Loss: 0.0987  Acc: 96.88%\n",
      "Epoch 2 [779/938]  Loss: 0.1266  Acc: 92.19%\n",
      "Epoch 2 [780/938]  Loss: 0.1679  Acc: 96.88%\n",
      "Epoch 2 [781/938]  Loss: 0.0789  Acc: 95.31%\n",
      "Epoch 2 [782/938]  Loss: 0.0523  Acc: 98.44%\n",
      "Epoch 2 [783/938]  Loss: 0.1612  Acc: 95.31%\n",
      "Epoch 2 [784/938]  Loss: 0.0335  Acc: 100.00%\n",
      "Epoch 2 [785/938]  Loss: 0.0279  Acc: 100.00%\n",
      "Epoch 2 [786/938]  Loss: 0.0989  Acc: 95.31%\n",
      "Epoch 2 [787/938]  Loss: 0.1557  Acc: 93.75%\n",
      "Epoch 2 [788/938]  Loss: 0.1689  Acc: 95.31%\n",
      "Epoch 2 [789/938]  Loss: 0.1537  Acc: 93.75%\n",
      "Epoch 2 [790/938]  Loss: 0.0766  Acc: 96.88%\n",
      "Epoch 2 [791/938]  Loss: 0.0419  Acc: 98.44%\n",
      "Epoch 2 [792/938]  Loss: 0.2526  Acc: 96.88%\n",
      "Epoch 2 [793/938]  Loss: 0.0556  Acc: 96.88%\n",
      "Epoch 2 [794/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 2 [795/938]  Loss: 0.0202  Acc: 100.00%\n",
      "Epoch 2 [796/938]  Loss: 0.1458  Acc: 95.31%\n",
      "Epoch 2 [797/938]  Loss: 0.1709  Acc: 96.88%\n",
      "Epoch 2 [798/938]  Loss: 0.0772  Acc: 98.44%\n",
      "Epoch 2 [799/938]  Loss: 0.0462  Acc: 100.00%\n",
      "Epoch 2 [800/938]  Loss: 0.0741  Acc: 96.88%\n",
      "Epoch 2 [801/938]  Loss: 0.0575  Acc: 98.44%\n",
      "Epoch 2 [802/938]  Loss: 0.0444  Acc: 100.00%\n",
      "Epoch 2 [803/938]  Loss: 0.1265  Acc: 95.31%\n",
      "Epoch 2 [804/938]  Loss: 0.0766  Acc: 95.31%\n",
      "Epoch 2 [805/938]  Loss: 0.1316  Acc: 93.75%\n",
      "Epoch 2 [806/938]  Loss: 0.1486  Acc: 96.88%\n",
      "Epoch 2 [807/938]  Loss: 0.0742  Acc: 98.44%\n",
      "Epoch 2 [808/938]  Loss: 0.0382  Acc: 100.00%\n",
      "Epoch 2 [809/938]  Loss: 0.1565  Acc: 93.75%\n",
      "Epoch 2 [810/938]  Loss: 0.0533  Acc: 100.00%\n",
      "Epoch 2 [811/938]  Loss: 0.2882  Acc: 92.19%\n",
      "Epoch 2 [812/938]  Loss: 0.0340  Acc: 100.00%\n",
      "Epoch 2 [813/938]  Loss: 0.1492  Acc: 95.31%\n",
      "Epoch 2 [814/938]  Loss: 0.2184  Acc: 92.19%\n",
      "Epoch 2 [815/938]  Loss: 0.0575  Acc: 98.44%\n",
      "Epoch 2 [816/938]  Loss: 0.0460  Acc: 98.44%\n",
      "Epoch 2 [817/938]  Loss: 0.0343  Acc: 98.44%\n",
      "Epoch 2 [818/938]  Loss: 0.0234  Acc: 100.00%\n",
      "Epoch 2 [819/938]  Loss: 0.1147  Acc: 96.88%\n",
      "Epoch 2 [758/938]  Loss: 0.0545  Acc: 98.44%\n",
      "Epoch 2 [759/938]  Loss: 0.1292  Acc: 95.31%\n",
      "Epoch 2 [760/938]  Loss: 0.0467  Acc: 98.44%\n",
      "Epoch 2 [761/938]  Loss: 0.0676  Acc: 98.44%\n",
      "Epoch 2 [762/938]  Loss: 0.0975  Acc: 96.88%\n",
      "Epoch 2 [763/938]  Loss: 0.0677  Acc: 96.88%\n",
      "Epoch 2 [764/938]  Loss: 0.0648  Acc: 98.44%\n",
      "Epoch 2 [765/938]  Loss: 0.2956  Acc: 93.75%\n",
      "Epoch 2 [766/938]  Loss: 0.2564  Acc: 87.50%\n",
      "Epoch 2 [767/938]  Loss: 0.0425  Acc: 98.44%\n",
      "Epoch 2 [768/938]  Loss: 0.0769  Acc: 98.44%\n",
      "Epoch 2 [769/938]  Loss: 0.1360  Acc: 95.31%\n",
      "Epoch 2 [770/938]  Loss: 0.1111  Acc: 96.88%\n",
      "Epoch 2 [771/938]  Loss: 0.1187  Acc: 96.88%\n",
      "Epoch 2 [772/938]  Loss: 0.0805  Acc: 96.88%\n",
      "Epoch 2 [773/938]  Loss: 0.1122  Acc: 96.88%\n",
      "Epoch 2 [774/938]  Loss: 0.0607  Acc: 100.00%\n",
      "Epoch 2 [775/938]  Loss: 0.1503  Acc: 96.88%\n",
      "Epoch 2 [776/938]  Loss: 0.2366  Acc: 95.31%\n",
      "Epoch 2 [777/938]  Loss: 0.1140  Acc: 96.88%\n",
      "Epoch 2 [778/938]  Loss: 0.0987  Acc: 96.88%\n",
      "Epoch 2 [779/938]  Loss: 0.1266  Acc: 92.19%\n",
      "Epoch 2 [780/938]  Loss: 0.1679  Acc: 96.88%\n",
      "Epoch 2 [781/938]  Loss: 0.0789  Acc: 95.31%\n",
      "Epoch 2 [782/938]  Loss: 0.0523  Acc: 98.44%\n",
      "Epoch 2 [783/938]  Loss: 0.1612  Acc: 95.31%\n",
      "Epoch 2 [784/938]  Loss: 0.0335  Acc: 100.00%\n",
      "Epoch 2 [785/938]  Loss: 0.0279  Acc: 100.00%\n",
      "Epoch 2 [786/938]  Loss: 0.0989  Acc: 95.31%\n",
      "Epoch 2 [787/938]  Loss: 0.1557  Acc: 93.75%\n",
      "Epoch 2 [788/938]  Loss: 0.1689  Acc: 95.31%\n",
      "Epoch 2 [789/938]  Loss: 0.1537  Acc: 93.75%\n",
      "Epoch 2 [790/938]  Loss: 0.0766  Acc: 96.88%\n",
      "Epoch 2 [791/938]  Loss: 0.0419  Acc: 98.44%\n",
      "Epoch 2 [792/938]  Loss: 0.2526  Acc: 96.88%\n",
      "Epoch 2 [793/938]  Loss: 0.0556  Acc: 96.88%\n",
      "Epoch 2 [794/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 2 [795/938]  Loss: 0.0202  Acc: 100.00%\n",
      "Epoch 2 [796/938]  Loss: 0.1458  Acc: 95.31%\n",
      "Epoch 2 [797/938]  Loss: 0.1709  Acc: 96.88%\n",
      "Epoch 2 [798/938]  Loss: 0.0772  Acc: 98.44%\n",
      "Epoch 2 [799/938]  Loss: 0.0462  Acc: 100.00%\n",
      "Epoch 2 [800/938]  Loss: 0.0741  Acc: 96.88%\n",
      "Epoch 2 [801/938]  Loss: 0.0575  Acc: 98.44%\n",
      "Epoch 2 [802/938]  Loss: 0.0444  Acc: 100.00%\n",
      "Epoch 2 [803/938]  Loss: 0.1265  Acc: 95.31%\n",
      "Epoch 2 [804/938]  Loss: 0.0766  Acc: 95.31%\n",
      "Epoch 2 [805/938]  Loss: 0.1316  Acc: 93.75%\n",
      "Epoch 2 [806/938]  Loss: 0.1486  Acc: 96.88%\n",
      "Epoch 2 [807/938]  Loss: 0.0742  Acc: 98.44%\n",
      "Epoch 2 [808/938]  Loss: 0.0382  Acc: 100.00%\n",
      "Epoch 2 [809/938]  Loss: 0.1565  Acc: 93.75%\n",
      "Epoch 2 [810/938]  Loss: 0.0533  Acc: 100.00%\n",
      "Epoch 2 [811/938]  Loss: 0.2882  Acc: 92.19%\n",
      "Epoch 2 [812/938]  Loss: 0.0340  Acc: 100.00%\n",
      "Epoch 2 [813/938]  Loss: 0.1492  Acc: 95.31%\n",
      "Epoch 2 [814/938]  Loss: 0.2184  Acc: 92.19%\n",
      "Epoch 2 [815/938]  Loss: 0.0575  Acc: 98.44%\n",
      "Epoch 2 [816/938]  Loss: 0.0460  Acc: 98.44%\n",
      "Epoch 2 [817/938]  Loss: 0.0343  Acc: 98.44%\n",
      "Epoch 2 [818/938]  Loss: 0.0234  Acc: 100.00%\n",
      "Epoch 2 [819/938]  Loss: 0.1147  Acc: 96.88%\n",
      "Epoch 2 [820/938]  Loss: 0.1027  Acc: 98.44%\n",
      "Epoch 2 [821/938]  Loss: 0.0675  Acc: 96.88%\n",
      "Epoch 2 [822/938]  Loss: 0.1055  Acc: 95.31%\n",
      "Epoch 2 [823/938]  Loss: 0.0647  Acc: 98.44%\n",
      "Epoch 2 [824/938]  Loss: 0.2691  Acc: 95.31%\n",
      "Epoch 2 [825/938]  Loss: 0.0681  Acc: 98.44%\n",
      "Epoch 2 [826/938]  Loss: 0.0651  Acc: 98.44%\n",
      "Epoch 2 [827/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [828/938]  Loss: 0.1699  Acc: 96.88%\n",
      "Epoch 2 [829/938]  Loss: 0.1442  Acc: 95.31%\n",
      "Epoch 2 [830/938]  Loss: 0.0263  Acc: 100.00%\n",
      "Epoch 2 [831/938]  Loss: 0.0881  Acc: 95.31%\n",
      "Epoch 2 [832/938]  Loss: 0.1203  Acc: 96.88%\n",
      "Epoch 2 [833/938]  Loss: 0.0956  Acc: 95.31%\n",
      "Epoch 2 [834/938]  Loss: 0.0754  Acc: 96.88%\n",
      "Epoch 2 [835/938]  Loss: 0.0998  Acc: 96.88%\n",
      "Epoch 2 [836/938]  Loss: 0.0935  Acc: 96.88%\n",
      "Epoch 2 [837/938]  Loss: 0.1109  Acc: 96.88%\n",
      "Epoch 2 [838/938]  Loss: 0.1562  Acc: 96.88%\n",
      "Epoch 2 [839/938]  Loss: 0.2315  Acc: 90.62%\n",
      "Epoch 2 [840/938]  Loss: 0.2580  Acc: 92.19%\n",
      "Epoch 2 [841/938]  Loss: 0.0379  Acc: 98.44%\n",
      "Epoch 2 [842/938]  Loss: 0.0366  Acc: 100.00%\n",
      "Epoch 2 [843/938]  Loss: 0.0468  Acc: 100.00%\n",
      "Epoch 2 [844/938]  Loss: 0.0704  Acc: 98.44%\n",
      "Epoch 2 [845/938]  Loss: 0.0828  Acc: 96.88%\n",
      "Epoch 2 [846/938]  Loss: 0.1643  Acc: 93.75%\n",
      "Epoch 2 [847/938]  Loss: 0.1779  Acc: 96.88%\n",
      "Epoch 2 [848/938]  Loss: 0.1725  Acc: 93.75%\n",
      "Epoch 2 [849/938]  Loss: 0.0905  Acc: 95.31%\n",
      "Epoch 2 [850/938]  Loss: 0.0462  Acc: 98.44%\n",
      "Epoch 2 [851/938]  Loss: 0.0970  Acc: 93.75%\n",
      "Epoch 2 [852/938]  Loss: 0.0923  Acc: 96.88%\n",
      "Epoch 2 [853/938]  Loss: 0.0332  Acc: 98.44%\n",
      "Epoch 2 [854/938]  Loss: 0.0443  Acc: 98.44%\n",
      "Epoch 2 [855/938]  Loss: 0.1190  Acc: 95.31%\n",
      "Epoch 2 [856/938]  Loss: 0.0721  Acc: 98.44%\n",
      "Epoch 2 [857/938]  Loss: 0.0854  Acc: 96.88%\n",
      "Epoch 2 [858/938]  Loss: 0.1384  Acc: 93.75%\n",
      "Epoch 2 [859/938]  Loss: 0.2302  Acc: 93.75%\n",
      "Epoch 2 [860/938]  Loss: 0.1703  Acc: 93.75%\n",
      "Epoch 2 [861/938]  Loss: 0.0564  Acc: 98.44%\n",
      "Epoch 2 [862/938]  Loss: 0.1030  Acc: 96.88%\n",
      "Epoch 2 [863/938]  Loss: 0.2667  Acc: 93.75%\n",
      "Epoch 2 [864/938]  Loss: 0.0827  Acc: 95.31%\n",
      "Epoch 2 [865/938]  Loss: 0.1071  Acc: 93.75%\n",
      "Epoch 2 [866/938]  Loss: 0.1629  Acc: 95.31%\n",
      "Epoch 2 [867/938]  Loss: 0.1156  Acc: 96.88%\n",
      "Epoch 2 [868/938]  Loss: 0.1099  Acc: 96.88%\n",
      "Epoch 2 [869/938]  Loss: 0.1347  Acc: 92.19%\n",
      "Epoch 2 [870/938]  Loss: 0.2432  Acc: 93.75%\n",
      "Epoch 2 [871/938]  Loss: 0.0627  Acc: 98.44%\n",
      "Epoch 2 [872/938]  Loss: 0.0920  Acc: 96.88%\n",
      "Epoch 2 [873/938]  Loss: 0.0437  Acc: 98.44%\n",
      "Epoch 2 [874/938]  Loss: 0.0661  Acc: 98.44%\n",
      "Epoch 2 [875/938]  Loss: 0.0994  Acc: 93.75%\n",
      "Epoch 2 [876/938]  Loss: 0.0628  Acc: 98.44%\n",
      "Epoch 2 [877/938]  Loss: 0.0368  Acc: 100.00%\n",
      "Epoch 2 [878/938]  Loss: 0.0938  Acc: 96.88%\n",
      "Epoch 2 [879/938]  Loss: 0.1154  Acc: 98.44%\n",
      "Epoch 2 [880/938]  Loss: 0.1675  Acc: 95.31%\n",
      "Epoch 2 [881/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 2 [882/938]  Loss: 0.1591  Acc: 95.31%\n",
      "Epoch 2 [883/938]  Loss: 0.0925  Acc: 95.31%\n",
      "Epoch 2 [884/938]  Loss: 0.1069  Acc: 95.31%\n",
      "Epoch 2 [885/938]  Loss: 0.1012  Acc: 95.31%\n",
      "Epoch 2 [886/938]  Loss: 0.1153  Acc: 96.88%\n",
      "Epoch 2 [820/938]  Loss: 0.1027  Acc: 98.44%\n",
      "Epoch 2 [821/938]  Loss: 0.0675  Acc: 96.88%\n",
      "Epoch 2 [822/938]  Loss: 0.1055  Acc: 95.31%\n",
      "Epoch 2 [823/938]  Loss: 0.0647  Acc: 98.44%\n",
      "Epoch 2 [824/938]  Loss: 0.2691  Acc: 95.31%\n",
      "Epoch 2 [825/938]  Loss: 0.0681  Acc: 98.44%\n",
      "Epoch 2 [826/938]  Loss: 0.0651  Acc: 98.44%\n",
      "Epoch 2 [827/938]  Loss: 0.0631  Acc: 98.44%\n",
      "Epoch 2 [828/938]  Loss: 0.1699  Acc: 96.88%\n",
      "Epoch 2 [829/938]  Loss: 0.1442  Acc: 95.31%\n",
      "Epoch 2 [830/938]  Loss: 0.0263  Acc: 100.00%\n",
      "Epoch 2 [831/938]  Loss: 0.0881  Acc: 95.31%\n",
      "Epoch 2 [832/938]  Loss: 0.1203  Acc: 96.88%\n",
      "Epoch 2 [833/938]  Loss: 0.0956  Acc: 95.31%\n",
      "Epoch 2 [834/938]  Loss: 0.0754  Acc: 96.88%\n",
      "Epoch 2 [835/938]  Loss: 0.0998  Acc: 96.88%\n",
      "Epoch 2 [836/938]  Loss: 0.0935  Acc: 96.88%\n",
      "Epoch 2 [837/938]  Loss: 0.1109  Acc: 96.88%\n",
      "Epoch 2 [838/938]  Loss: 0.1562  Acc: 96.88%\n",
      "Epoch 2 [839/938]  Loss: 0.2315  Acc: 90.62%\n",
      "Epoch 2 [840/938]  Loss: 0.2580  Acc: 92.19%\n",
      "Epoch 2 [841/938]  Loss: 0.0379  Acc: 98.44%\n",
      "Epoch 2 [842/938]  Loss: 0.0366  Acc: 100.00%\n",
      "Epoch 2 [843/938]  Loss: 0.0468  Acc: 100.00%\n",
      "Epoch 2 [844/938]  Loss: 0.0704  Acc: 98.44%\n",
      "Epoch 2 [845/938]  Loss: 0.0828  Acc: 96.88%\n",
      "Epoch 2 [846/938]  Loss: 0.1643  Acc: 93.75%\n",
      "Epoch 2 [847/938]  Loss: 0.1779  Acc: 96.88%\n",
      "Epoch 2 [848/938]  Loss: 0.1725  Acc: 93.75%\n",
      "Epoch 2 [849/938]  Loss: 0.0905  Acc: 95.31%\n",
      "Epoch 2 [850/938]  Loss: 0.0462  Acc: 98.44%\n",
      "Epoch 2 [851/938]  Loss: 0.0970  Acc: 93.75%\n",
      "Epoch 2 [852/938]  Loss: 0.0923  Acc: 96.88%\n",
      "Epoch 2 [853/938]  Loss: 0.0332  Acc: 98.44%\n",
      "Epoch 2 [854/938]  Loss: 0.0443  Acc: 98.44%\n",
      "Epoch 2 [855/938]  Loss: 0.1190  Acc: 95.31%\n",
      "Epoch 2 [856/938]  Loss: 0.0721  Acc: 98.44%\n",
      "Epoch 2 [857/938]  Loss: 0.0854  Acc: 96.88%\n",
      "Epoch 2 [858/938]  Loss: 0.1384  Acc: 93.75%\n",
      "Epoch 2 [859/938]  Loss: 0.2302  Acc: 93.75%\n",
      "Epoch 2 [860/938]  Loss: 0.1703  Acc: 93.75%\n",
      "Epoch 2 [861/938]  Loss: 0.0564  Acc: 98.44%\n",
      "Epoch 2 [862/938]  Loss: 0.1030  Acc: 96.88%\n",
      "Epoch 2 [863/938]  Loss: 0.2667  Acc: 93.75%\n",
      "Epoch 2 [864/938]  Loss: 0.0827  Acc: 95.31%\n",
      "Epoch 2 [865/938]  Loss: 0.1071  Acc: 93.75%\n",
      "Epoch 2 [866/938]  Loss: 0.1629  Acc: 95.31%\n",
      "Epoch 2 [867/938]  Loss: 0.1156  Acc: 96.88%\n",
      "Epoch 2 [868/938]  Loss: 0.1099  Acc: 96.88%\n",
      "Epoch 2 [869/938]  Loss: 0.1347  Acc: 92.19%\n",
      "Epoch 2 [870/938]  Loss: 0.2432  Acc: 93.75%\n",
      "Epoch 2 [871/938]  Loss: 0.0627  Acc: 98.44%\n",
      "Epoch 2 [872/938]  Loss: 0.0920  Acc: 96.88%\n",
      "Epoch 2 [873/938]  Loss: 0.0437  Acc: 98.44%\n",
      "Epoch 2 [874/938]  Loss: 0.0661  Acc: 98.44%\n",
      "Epoch 2 [875/938]  Loss: 0.0994  Acc: 93.75%\n",
      "Epoch 2 [876/938]  Loss: 0.0628  Acc: 98.44%\n",
      "Epoch 2 [877/938]  Loss: 0.0368  Acc: 100.00%\n",
      "Epoch 2 [878/938]  Loss: 0.0938  Acc: 96.88%\n",
      "Epoch 2 [879/938]  Loss: 0.1154  Acc: 98.44%\n",
      "Epoch 2 [880/938]  Loss: 0.1675  Acc: 95.31%\n",
      "Epoch 2 [881/938]  Loss: 0.1500  Acc: 95.31%\n",
      "Epoch 2 [882/938]  Loss: 0.1591  Acc: 95.31%\n",
      "Epoch 2 [883/938]  Loss: 0.0925  Acc: 95.31%\n",
      "Epoch 2 [884/938]  Loss: 0.1069  Acc: 95.31%\n",
      "Epoch 2 [885/938]  Loss: 0.1012  Acc: 95.31%\n",
      "Epoch 2 [886/938]  Loss: 0.1153  Acc: 96.88%\n",
      "Epoch 2 [887/938]  Loss: 0.0767  Acc: 96.88%\n",
      "Epoch 2 [888/938]  Loss: 0.0715  Acc: 98.44%\n",
      "Epoch 2 [889/938]  Loss: 0.0448  Acc: 100.00%\n",
      "Epoch 2 [890/938]  Loss: 0.1100  Acc: 96.88%\n",
      "Epoch 2 [891/938]  Loss: 0.0707  Acc: 96.88%\n",
      "Epoch 2 [892/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [893/938]  Loss: 0.1183  Acc: 92.19%\n",
      "Epoch 2 [894/938]  Loss: 0.0473  Acc: 96.88%\n",
      "Epoch 2 [895/938]  Loss: 0.2686  Acc: 92.19%\n",
      "Epoch 2 [896/938]  Loss: 0.0390  Acc: 100.00%\n",
      "Epoch 2 [897/938]  Loss: 0.0669  Acc: 98.44%\n",
      "Epoch 2 [898/938]  Loss: 0.1563  Acc: 95.31%\n",
      "Epoch 2 [899/938]  Loss: 0.0913  Acc: 96.88%\n",
      "Epoch 2 [900/938]  Loss: 0.0912  Acc: 96.88%\n",
      "Epoch 2 [901/938]  Loss: 0.0648  Acc: 96.88%\n",
      "Epoch 2 [902/938]  Loss: 0.1380  Acc: 90.62%\n",
      "Epoch 2 [903/938]  Loss: 0.2138  Acc: 95.31%\n",
      "Epoch 2 [904/938]  Loss: 0.0676  Acc: 98.44%\n",
      "Epoch 2 [905/938]  Loss: 0.1201  Acc: 96.88%\n",
      "Epoch 2 [906/938]  Loss: 0.1832  Acc: 96.88%\n",
      "Epoch 2 [907/938]  Loss: 0.0455  Acc: 98.44%\n",
      "Epoch 2 [908/938]  Loss: 0.0815  Acc: 96.88%\n",
      "Epoch 2 [909/938]  Loss: 0.0971  Acc: 96.88%\n",
      "Epoch 2 [910/938]  Loss: 0.1256  Acc: 92.19%\n",
      "Epoch 2 [911/938]  Loss: 0.0493  Acc: 98.44%\n",
      "Epoch 2 [912/938]  Loss: 0.0684  Acc: 98.44%\n",
      "Epoch 2 [913/938]  Loss: 0.0341  Acc: 100.00%\n",
      "Epoch 2 [914/938]  Loss: 0.0472  Acc: 100.00%\n",
      "Epoch 2 [915/938]  Loss: 0.0370  Acc: 98.44%\n",
      "Epoch 2 [916/938]  Loss: 0.0666  Acc: 98.44%\n",
      "Epoch 2 [917/938]  Loss: 0.1301  Acc: 95.31%\n",
      "Epoch 2 [918/938]  Loss: 0.0977  Acc: 96.88%\n",
      "Epoch 2 [919/938]  Loss: 0.0878  Acc: 96.88%\n",
      "Epoch 2 [920/938]  Loss: 0.1683  Acc: 95.31%\n",
      "Epoch 2 [921/938]  Loss: 0.0407  Acc: 98.44%\n",
      "Epoch 2 [922/938]  Loss: 0.0797  Acc: 96.88%\n",
      "Epoch 2 [923/938]  Loss: 0.0455  Acc: 98.44%\n",
      "Epoch 2 [924/938]  Loss: 0.2373  Acc: 93.75%\n",
      "Epoch 2 [925/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [926/938]  Loss: 0.0786  Acc: 96.88%\n",
      "Epoch 2 [927/938]  Loss: 0.0891  Acc: 96.88%\n",
      "Epoch 2 [928/938]  Loss: 0.1134  Acc: 96.88%\n",
      "Epoch 2 [929/938]  Loss: 0.1496  Acc: 98.44%\n",
      "Epoch 2 [930/938]  Loss: 0.0309  Acc: 100.00%\n",
      "Epoch 2 [931/938]  Loss: 0.0348  Acc: 100.00%\n",
      "Epoch 2 [932/938]  Loss: 0.0756  Acc: 98.44%\n",
      "Epoch 2 [933/938]  Loss: 0.2651  Acc: 93.75%\n",
      "Epoch 2 [934/938]  Loss: 0.1162  Acc: 93.75%\n",
      "Epoch 2 [935/938]  Loss: 0.0247  Acc: 100.00%\n",
      "Epoch 2 [936/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [937/938]  Loss: 0.1183  Acc: 98.44%\n",
      "Epoch 2 [938/938]  Loss: 0.1093  Acc: 96.88%\n",
      "Epoch 2 [887/938]  Loss: 0.0767  Acc: 96.88%\n",
      "Epoch 2 [888/938]  Loss: 0.0715  Acc: 98.44%\n",
      "Epoch 2 [889/938]  Loss: 0.0448  Acc: 100.00%\n",
      "Epoch 2 [890/938]  Loss: 0.1100  Acc: 96.88%\n",
      "Epoch 2 [891/938]  Loss: 0.0707  Acc: 96.88%\n",
      "Epoch 2 [892/938]  Loss: 0.0860  Acc: 96.88%\n",
      "Epoch 2 [893/938]  Loss: 0.1183  Acc: 92.19%\n",
      "Epoch 2 [894/938]  Loss: 0.0473  Acc: 96.88%\n",
      "Epoch 2 [895/938]  Loss: 0.2686  Acc: 92.19%\n",
      "Epoch 2 [896/938]  Loss: 0.0390  Acc: 100.00%\n",
      "Epoch 2 [897/938]  Loss: 0.0669  Acc: 98.44%\n",
      "Epoch 2 [898/938]  Loss: 0.1563  Acc: 95.31%\n",
      "Epoch 2 [899/938]  Loss: 0.0913  Acc: 96.88%\n",
      "Epoch 2 [900/938]  Loss: 0.0912  Acc: 96.88%\n",
      "Epoch 2 [901/938]  Loss: 0.0648  Acc: 96.88%\n",
      "Epoch 2 [902/938]  Loss: 0.1380  Acc: 90.62%\n",
      "Epoch 2 [903/938]  Loss: 0.2138  Acc: 95.31%\n",
      "Epoch 2 [904/938]  Loss: 0.0676  Acc: 98.44%\n",
      "Epoch 2 [905/938]  Loss: 0.1201  Acc: 96.88%\n",
      "Epoch 2 [906/938]  Loss: 0.1832  Acc: 96.88%\n",
      "Epoch 2 [907/938]  Loss: 0.0455  Acc: 98.44%\n",
      "Epoch 2 [908/938]  Loss: 0.0815  Acc: 96.88%\n",
      "Epoch 2 [909/938]  Loss: 0.0971  Acc: 96.88%\n",
      "Epoch 2 [910/938]  Loss: 0.1256  Acc: 92.19%\n",
      "Epoch 2 [911/938]  Loss: 0.0493  Acc: 98.44%\n",
      "Epoch 2 [912/938]  Loss: 0.0684  Acc: 98.44%\n",
      "Epoch 2 [913/938]  Loss: 0.0341  Acc: 100.00%\n",
      "Epoch 2 [914/938]  Loss: 0.0472  Acc: 100.00%\n",
      "Epoch 2 [915/938]  Loss: 0.0370  Acc: 98.44%\n",
      "Epoch 2 [916/938]  Loss: 0.0666  Acc: 98.44%\n",
      "Epoch 2 [917/938]  Loss: 0.1301  Acc: 95.31%\n",
      "Epoch 2 [918/938]  Loss: 0.0977  Acc: 96.88%\n",
      "Epoch 2 [919/938]  Loss: 0.0878  Acc: 96.88%\n",
      "Epoch 2 [920/938]  Loss: 0.1683  Acc: 95.31%\n",
      "Epoch 2 [921/938]  Loss: 0.0407  Acc: 98.44%\n",
      "Epoch 2 [922/938]  Loss: 0.0797  Acc: 96.88%\n",
      "Epoch 2 [923/938]  Loss: 0.0455  Acc: 98.44%\n",
      "Epoch 2 [924/938]  Loss: 0.2373  Acc: 93.75%\n",
      "Epoch 2 [925/938]  Loss: 0.0992  Acc: 96.88%\n",
      "Epoch 2 [926/938]  Loss: 0.0786  Acc: 96.88%\n",
      "Epoch 2 [927/938]  Loss: 0.0891  Acc: 96.88%\n",
      "Epoch 2 [928/938]  Loss: 0.1134  Acc: 96.88%\n",
      "Epoch 2 [929/938]  Loss: 0.1496  Acc: 98.44%\n",
      "Epoch 2 [930/938]  Loss: 0.0309  Acc: 100.00%\n",
      "Epoch 2 [931/938]  Loss: 0.0348  Acc: 100.00%\n",
      "Epoch 2 [932/938]  Loss: 0.0756  Acc: 98.44%\n",
      "Epoch 2 [933/938]  Loss: 0.2651  Acc: 93.75%\n",
      "Epoch 2 [934/938]  Loss: 0.1162  Acc: 93.75%\n",
      "Epoch 2 [935/938]  Loss: 0.0247  Acc: 100.00%\n",
      "Epoch 2 [936/938]  Loss: 0.0448  Acc: 98.44%\n",
      "Epoch 2 [937/938]  Loss: 0.1183  Acc: 98.44%\n",
      "Epoch 2 [938/938]  Loss: 0.1093  Acc: 96.88%\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "writer = SummaryWriter(\"./runs/lenet_mnist\")\n",
    "\n",
    "for epoch in range(1, 1 + EPOCHS):\n",
    "    t0 = time.time()\n",
    "    train(model, DEVICE, train_loader, optimizer, loss_function, epoch, writer)\n",
    "    test(model, DEVICE, test_loader, loss_function, epoch, writer)\n",
    "    print(f'Epoch {epoch} finished in {time.time() - t0:.1f}s')\n",
    "\n",
    "model_path = './lenet_mnist.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model saved to', model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e178ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例：加载保存的模型并可视化若干预测结果\n",
    "# 加载模型\n",
    "model = LeNet5()\n",
    "model.load_state_dict(torch.load('./lenet_mnist.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# 取几张测试图像并预测\n",
    "examples = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, target) in enumerate(test_loader):\n",
    "        if i >= 1:\n",
    "            break\n",
    "        outputs = model(data)\n",
    "        preds = outputs.argmax(dim=1).numpy()\n",
    "        for j in range(min(8, data.size(0))):\n",
    "            img = data[j].squeeze().numpy()\n",
    "            examples.append(img)\n",
    "            labels.append((int(target[j].item()), int(preds[j].item())))\n",
    "\n",
    "# 绘制\n",
    "plt.figure(figsize=(12, 6))\n",
    "for idx, img in enumerate(examples):\n",
    "    plt.subplot(2, 4, idx+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    gt, pr = labels[idx]\n",
    "    plt.title(f'GT:{gt} Pred:{pr}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd0fe26",
   "metadata": {},
   "source": [
    "## 本地手写窗口（Tkinter）\n",
    "\n",
    "- 运行下一个单元将打开一个本地窗口。\n",
    "- 操作：按住左键在白板上书写；点击“识别”进行推断；“清空”重置画布；“退出”关闭窗口。\n",
    "- 说明：此窗口使用 Tkinter（Windows 通常自带）。若环境未安装 Tk 支持，可能无法启动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35464471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地手写窗口：Tkinter 画布 + LeNet-5 推理\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Tkinter 可能在某些环境不可用\n",
    "try:\n",
    "    import tkinter as tk\n",
    "except Exception as e:\n",
    "    print(\"未能导入 Tkinter：\", e)\n",
    "    raise\n",
    "\n",
    "# 复用已定义的 LeNet5，如果此单元单独运行则做一次定义\n",
    "try:\n",
    "    LeNet5\n",
    "except NameError:\n",
    "    print(\"警告：LeNet-5 模型未定义\")\n",
    "\n",
    "# 加载模型（CPU 推理）\n",
    "_device = torch.device('cpu')\n",
    "_model = LeNet5().to(_device)\n",
    "weights_path = './lenet_mnist.pth'\n",
    "if os.path.exists(weights_path):    \n",
    "    _model.load_state_dict(torch.load(weights_path, map_location=_device))\n",
    "    _model.eval()\n",
    "else:\n",
    "    print('警告：未找到模型权重 ./lenet_mnist.pth，请先运行训练单元保存模型。')\n",
    "\n",
    "_MEAN, _STD = 0.1307, 0.3081\n",
    "\n",
    "\n",
    "def _preprocess_pil(pil_img: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"将 PIL 图像转换为 1×1×32×32 标准化张量（与训练一致）。\"\"\"\n",
    "    if pil_img.mode != 'L':\n",
    "        pil_img = pil_img.convert('L')\n",
    "    pil_img = pil_img.resize((28, 28), Image.NEAREST)\n",
    "    arr = np.array(pil_img).astype(np.float32) / 255.0\n",
    "    arr = 1.0 - arr  # 画布白底黑字 -> MNIST 黑底白字\n",
    "    arr = (arr - _MEAN) / _STD\n",
    "    arr = np.pad(arr, pad_width=((2, 2), (2, 2)), mode='constant', constant_values=0.0)\n",
    "    ten = torch.from_numpy(arr)[None, None, :, :].to(_device)\n",
    "    return ten\n",
    "\n",
    "\n",
    "def _predict_from_pil(pil_img: Image.Image):\n",
    "    if _model is None:\n",
    "        return {str(i): 0.0 for i in range(10)}\n",
    "    x = _preprocess_pil(pil_img)\n",
    "    with torch.no_grad():\n",
    "        logits = _model(x)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    return {str(i): float(probs[i]) for i in range(10)}\n",
    "\n",
    "\n",
    "# === Tkinter 手写窗口 ===\n",
    "CANVAS_SIZE = 280            # 画布像素大小（放大版）\n",
    "BRUSH_WIDTH = 20             # 笔刷粗细\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title('MNIST 手写数字识别 (LeNet-5) - 本地窗口')\n",
    "\n",
    "canvas = tk.Canvas(root, width=CANVAS_SIZE, height=CANVAS_SIZE, bg='white')\n",
    "canvas.pack(padx=8, pady=8)\n",
    "\n",
    "# 用于推理的灰度图缓存（白底）\n",
    "buffer_img = Image.new('L', (CANVAS_SIZE, CANVAS_SIZE), color=255)\n",
    "buffer_draw = ImageDraw.Draw(buffer_img)\n",
    "\n",
    "last_pos = {'x': None, 'y': None}\n",
    "\n",
    "\n",
    "def on_button_press(event):\n",
    "    last_pos['x'], last_pos['y'] = event.x, event.y\n",
    "\n",
    "\n",
    "def on_move(event):\n",
    "    lx, ly = last_pos['x'], last_pos['y']\n",
    "    if lx is None or ly is None:\n",
    "        last_pos['x'], last_pos['y'] = event.x, event.y\n",
    "        return\n",
    "    x, y = event.x, event.y\n",
    "    canvas.create_line(lx, ly, x, y, width=BRUSH_WIDTH, fill='black', capstyle=tk.ROUND, smooth=True)\n",
    "    buffer_draw.line([lx, ly, x, y], fill=0, width=BRUSH_WIDTH)\n",
    "    last_pos['x'], last_pos['y'] = x, y\n",
    "\n",
    "\n",
    "def on_button_release(event):\n",
    "    last_pos['x'], last_pos['y'] = None, None\n",
    "\n",
    "\n",
    "def clear_canvas():\n",
    "    canvas.delete('all')\n",
    "    buffer_draw.rectangle([(0, 0), (CANVAS_SIZE, CANVAS_SIZE)], fill=255)\n",
    "    result_var.set('结果：')\n",
    "\n",
    "\n",
    "def predict_canvas():\n",
    "    probs = _predict_from_pil(buffer_img)\n",
    "    # 取 Top-3 显示\n",
    "    items = sorted([(int(k), v) for k, v in probs.items()], key=lambda kv: kv[1], reverse=True)[:3]\n",
    "    text = '结果：' + '  '.join([f'{k}: {v*100:.2f}%' for k, v in items])\n",
    "    result_var.set(text)\n",
    "\n",
    "\n",
    "btn_frame = tk.Frame(root)\n",
    "btn_frame.pack(fill='x', padx=8, pady=4)\n",
    "\n",
    "tk.Button(btn_frame, text='识别', command=predict_canvas).pack(side='left', padx=4)\n",
    "tk.Button(btn_frame, text='清空', command=clear_canvas).pack(side='left', padx=4)\n",
    "tk.Button(btn_frame, text='退出', command=root.destroy).pack(side='right', padx=4)\n",
    "\n",
    "result_var = tk.StringVar(value='结果：')\n",
    "result_label = tk.Label(root, textvariable=result_var, anchor='w')\n",
    "result_label.pack(fill='x', padx=8, pady=4)\n",
    "\n",
    "canvas.bind('<ButtonPress-1>', on_button_press)\n",
    "canvas.bind('<B1-Motion>', on_move)\n",
    "canvas.bind('<ButtonRelease-1>', on_button_release)\n",
    "\n",
    "# 启动窗口（注意：在某些 Jupyter 环境中主线程阻塞是预期行为）\n",
    "try:\n",
    "    root.mainloop()\n",
    "except Exception as e:\n",
    "    print('Tkinter 主循环启动失败：', e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
