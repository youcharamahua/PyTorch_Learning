{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:09:56.055927Z",
     "start_time": "2025-07-31T08:09:53.011434Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "3fdd24da21bf81c2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:09:56.071069Z",
     "start_time": "2025-07-31T08:09:56.066557Z"
    }
   },
   "cell_type": "code",
   "source": "model_path = \"test.pth\"",
   "id": "3d578dee81522db1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:09:56.225211Z",
     "start_time": "2025-07-31T08:09:56.079081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载权重文件\n",
    "checkpoint = torch.load( model_path,map_location='cpu')\n",
    "\n",
    "# 查看文件结构\n",
    "print(\"Keys in checkpoint:\", checkpoint.keys())\n",
    "\n",
    "# 如果是模型权重，查看权重键名\n",
    "if 'model' in checkpoint:\n",
    "    state_dict = checkpoint['model']\n",
    "    print(\"\\nFirst 10 weight keys:\")\n",
    "    for i, key in enumerate(list(state_dict.keys())):\n",
    "        if i < 10:\n",
    "            print(key)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# 检查权重形状\n",
    "print(\"\\nWeight shapes:\")\n",
    "for key, tensor in state_dict.items():\n",
    "    print(f\"{key}: {tuple(tensor.shape)}\")"
   ],
   "id": "fa9591e3ed458919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in checkpoint: dict_keys(['iteration', 'model'])\n",
      "\n",
      "First 10 weight keys:\n",
      "spectrogram_extractor.stft.conv_real.weight\n",
      "spectrogram_extractor.stft.conv_imag.weight\n",
      "logmel_extractor.melW\n",
      "bn0.weight\n",
      "bn0.bias\n",
      "bn0.running_mean\n",
      "bn0.running_var\n",
      "bn0.num_batches_tracked\n",
      "conv_block1.conv1.weight\n",
      "conv_block1.conv2.weight\n",
      "\n",
      "Weight shapes:\n",
      "spectrogram_extractor.stft.conv_real.weight: (513, 1, 1024)\n",
      "spectrogram_extractor.stft.conv_imag.weight: (513, 1, 1024)\n",
      "logmel_extractor.melW: (513, 64)\n",
      "bn0.weight: (64,)\n",
      "bn0.bias: (64,)\n",
      "bn0.running_mean: (64,)\n",
      "bn0.running_var: (64,)\n",
      "bn0.num_batches_tracked: ()\n",
      "conv_block1.conv1.weight: (64, 1, 3, 3)\n",
      "conv_block1.conv2.weight: (64, 64, 3, 3)\n",
      "conv_block1.bn1.weight: (64,)\n",
      "conv_block1.bn1.bias: (64,)\n",
      "conv_block1.bn1.running_mean: (64,)\n",
      "conv_block1.bn1.running_var: (64,)\n",
      "conv_block1.bn1.num_batches_tracked: ()\n",
      "conv_block1.bn2.weight: (64,)\n",
      "conv_block1.bn2.bias: (64,)\n",
      "conv_block1.bn2.running_mean: (64,)\n",
      "conv_block1.bn2.running_var: (64,)\n",
      "conv_block1.bn2.num_batches_tracked: ()\n",
      "conv_block2.conv1.weight: (128, 64, 3, 3)\n",
      "conv_block2.conv2.weight: (128, 128, 3, 3)\n",
      "conv_block2.bn1.weight: (128,)\n",
      "conv_block2.bn1.bias: (128,)\n",
      "conv_block2.bn1.running_mean: (128,)\n",
      "conv_block2.bn1.running_var: (128,)\n",
      "conv_block2.bn1.num_batches_tracked: ()\n",
      "conv_block2.bn2.weight: (128,)\n",
      "conv_block2.bn2.bias: (128,)\n",
      "conv_block2.bn2.running_mean: (128,)\n",
      "conv_block2.bn2.running_var: (128,)\n",
      "conv_block2.bn2.num_batches_tracked: ()\n",
      "conv_block3.conv1.weight: (256, 128, 3, 3)\n",
      "conv_block3.conv2.weight: (256, 256, 3, 3)\n",
      "conv_block3.bn1.weight: (256,)\n",
      "conv_block3.bn1.bias: (256,)\n",
      "conv_block3.bn1.running_mean: (256,)\n",
      "conv_block3.bn1.running_var: (256,)\n",
      "conv_block3.bn1.num_batches_tracked: ()\n",
      "conv_block3.bn2.weight: (256,)\n",
      "conv_block3.bn2.bias: (256,)\n",
      "conv_block3.bn2.running_mean: (256,)\n",
      "conv_block3.bn2.running_var: (256,)\n",
      "conv_block3.bn2.num_batches_tracked: ()\n",
      "conv_block4.conv1.weight: (512, 256, 3, 3)\n",
      "conv_block4.conv2.weight: (512, 512, 3, 3)\n",
      "conv_block4.bn1.weight: (512,)\n",
      "conv_block4.bn1.bias: (512,)\n",
      "conv_block4.bn1.running_mean: (512,)\n",
      "conv_block4.bn1.running_var: (512,)\n",
      "conv_block4.bn1.num_batches_tracked: ()\n",
      "conv_block4.bn2.weight: (512,)\n",
      "conv_block4.bn2.bias: (512,)\n",
      "conv_block4.bn2.running_mean: (512,)\n",
      "conv_block4.bn2.running_var: (512,)\n",
      "conv_block4.bn2.num_batches_tracked: ()\n",
      "conv_block5.conv1.weight: (1024, 512, 3, 3)\n",
      "conv_block5.conv2.weight: (1024, 1024, 3, 3)\n",
      "conv_block5.bn1.weight: (1024,)\n",
      "conv_block5.bn1.bias: (1024,)\n",
      "conv_block5.bn1.running_mean: (1024,)\n",
      "conv_block5.bn1.running_var: (1024,)\n",
      "conv_block5.bn1.num_batches_tracked: ()\n",
      "conv_block5.bn2.weight: (1024,)\n",
      "conv_block5.bn2.bias: (1024,)\n",
      "conv_block5.bn2.running_mean: (1024,)\n",
      "conv_block5.bn2.running_var: (1024,)\n",
      "conv_block5.bn2.num_batches_tracked: ()\n",
      "conv_block6.conv1.weight: (2048, 1024, 3, 3)\n",
      "conv_block6.conv2.weight: (2048, 2048, 3, 3)\n",
      "conv_block6.bn1.weight: (2048,)\n",
      "conv_block6.bn1.bias: (2048,)\n",
      "conv_block6.bn1.running_mean: (2048,)\n",
      "conv_block6.bn1.running_var: (2048,)\n",
      "conv_block6.bn1.num_batches_tracked: ()\n",
      "conv_block6.bn2.weight: (2048,)\n",
      "conv_block6.bn2.bias: (2048,)\n",
      "conv_block6.bn2.running_mean: (2048,)\n",
      "conv_block6.bn2.running_var: (2048,)\n",
      "conv_block6.bn2.num_batches_tracked: ()\n",
      "fc1.weight: (2048, 2048)\n",
      "fc1.bias: (2048,)\n",
      "fc_audioset.weight: (527, 2048)\n",
      "fc_audioset.bias: (527,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T08:13:09.197277Z",
     "start_time": "2025-07-31T08:13:07.662714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import re\n",
    "\n",
    "class ReconstructedCNN14(nn.Module):\n",
    "    def __init__(self, state_dict):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleDict()\n",
    "\n",
    "        # 自动解析权重结构\n",
    "        conv_pattern = re.compile(r'conv_block(\\d+)\\.(\\d+)\\.(weight|bias)')\n",
    "        linear_pattern = re.compile(r'fc\\.(weight|bias)')\n",
    "\n",
    "        # 识别卷积块\n",
    "        conv_blocks = {}\n",
    "        for key in state_dict:\n",
    "            if conv_match := conv_pattern.match(key):\n",
    "                block_idx, layer_idx, param_type = conv_match.groups()\n",
    "                block_idx = int(block_idx)\n",
    "\n",
    "                if block_idx not in conv_blocks:\n",
    "                    conv_blocks[block_idx] = []\n",
    "\n",
    "                # 获取输入/输出通道数\n",
    "                if param_type == 'weight':\n",
    "                    out_channels, in_channels = state_dict[key].shape[:2]\n",
    "                    conv_blocks[block_idx].append((in_channels, out_channels))\n",
    "\n",
    "        # 构建卷积块\n",
    "        for block_idx, channels in conv_blocks.items():\n",
    "            block = nn.Sequential()\n",
    "            for i, (in_ch, out_ch) in enumerate(channels):\n",
    "                # 每对通道数对应一个卷积层\n",
    "                block.add_module(f\"conv{i*2}\", nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1))\n",
    "                block.add_module(f\"bn{i*2+1}\", nn.BatchNorm2d(out_ch))\n",
    "                block.add_module(f\"relu{i*2+2}\", nn.ReLU())\n",
    "\n",
    "            # 添加池化层（除了最后一个块）\n",
    "            if block_idx < max(conv_blocks.keys()):\n",
    "                block.add_module(\"pool\", nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            self.layers[f\"conv_block{block_idx}\"] = block\n",
    "\n",
    "        # 构建全局池化和分类器\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # 识别全连接层\n",
    "        fc_in_features = None\n",
    "        for key in state_dict:\n",
    "            if linear_pattern.match(key) and 'weight' in key:\n",
    "                fc_in_features = state_dict[key].shape[1]\n",
    "                num_classes = state_dict[key].shape[0]\n",
    "                break\n",
    "\n",
    "        if fc_in_features:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc = nn.Linear(fc_in_features, num_classes)\n",
    "        else:\n",
    "            raise ValueError(\"FC layer weights not found\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 按顺序执行所有卷积块\n",
    "        for i in range(1, len(self.layers) + 1):\n",
    "            x = self.layers[f\"conv_block{i}\"](x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ],
   "id": "72315a1af5b49ac1",
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
